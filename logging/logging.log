[2024-12-06 13:31:43,946, 4287805165, INFO, Establising Connection With SQL Database ]
[2024-12-06 13:31:43,949, 4287805165, INFO, Successfully connected to the SQLite database. ]
[2024-12-06 13:31:43,951, 4287805165, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-06 13:31:44,339, 4287805165, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-06 17:40:36,339, 1589442515, INFO, Establising Connection With SQL Database ]
[2024-12-06 17:40:36,343, 1589442515, INFO, Successfully connected to the SQLite database. ]
[2024-12-06 17:40:36,344, 1589442515, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-06 17:40:37,059, 1589442515, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-06 19:54:45,958, 684587357, INFO, Initiating data ingestion ]
[2024-12-06 19:54:45,960, 1589442515, INFO, Establising Connection With SQL Database ]
[2024-12-06 19:54:45,961, 1589442515, INFO, Successfully connected to the SQLite database. ]
[2024-12-06 19:54:45,962, 1589442515, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-06 19:54:46,397, 1589442515, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-06 19:57:53,523, 1281613317, INFO, Initiating data ingestion ]
[2024-12-06 19:57:53,525, 1589442515, INFO, Establising Connection With SQL Database ]
[2024-12-06 19:57:53,527, 1589442515, INFO, Successfully connected to the SQLite database. ]
[2024-12-06 19:57:53,528, 1589442515, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-06 19:57:53,918, 1589442515, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-06 19:58:06,928, 3482073804, INFO, Initiating data ingestion ]
[2024-12-06 19:58:06,930, 1589442515, INFO, Establising Connection With SQL Database ]
[2024-12-06 19:58:06,931, 1589442515, INFO, Successfully connected to the SQLite database. ]
[2024-12-06 19:58:06,933, 1589442515, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-06 19:58:07,327, 1589442515, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-06 19:58:59,157, 3482073804, INFO, Initiating data ingestion ]
[2024-12-06 19:58:59,159, 1589442515, INFO, Establising Connection With SQL Database ]
[2024-12-06 19:58:59,160, 1589442515, INFO, Successfully connected to the SQLite database. ]
[2024-12-06 19:58:59,161, 1589442515, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-06 19:58:59,540, 1589442515, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-06 20:00:12,450, 1302022090, INFO, Initiating data ingestion ]
[2024-12-06 20:00:12,452, 1589442515, INFO, Establising Connection With SQL Database ]
[2024-12-06 20:00:12,454, 1589442515, INFO, Successfully connected to the SQLite database. ]
[2024-12-06 20:00:12,455, 1589442515, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-06 20:00:12,894, 1589442515, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-06 20:00:14,080, 1302022090, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-06 20:00:14,081, 1302022090, INFO, Initiating train test split ]
[2024-12-06 20:00:15,357, 1302022090, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-11 18:10:33,698, word2vec, INFO, collecting all words and their counts ]
[2024-12-11 18:10:33,700, word2vec, INFO, PROGRESS: at sentence #0, processed 0 words, keeping 0 word types ]
[2024-12-11 18:10:33,820, word2vec, INFO, PROGRESS: at sentence #10000, processed 407873 words, keeping 45074 word types ]
[2024-12-11 18:10:33,932, word2vec, INFO, PROGRESS: at sentence #20000, processed 808292 words, keeping 69250 word types ]
[2024-12-11 18:10:34,062, word2vec, INFO, PROGRESS: at sentence #30000, processed 1216627 words, keeping 90083 word types ]
[2024-12-11 18:10:34,185, word2vec, INFO, PROGRESS: at sentence #40000, processed 1621499 words, keeping 108581 word types ]
[2024-12-11 18:10:34,294, word2vec, INFO, PROGRESS: at sentence #50000, processed 2025370 words, keeping 125156 word types ]
[2024-12-11 18:10:34,403, word2vec, INFO, PROGRESS: at sentence #60000, processed 2428035 words, keeping 140773 word types ]
[2024-12-11 18:10:34,504, word2vec, INFO, PROGRESS: at sentence #70000, processed 2828048 words, keeping 155388 word types ]
[2024-12-11 18:10:34,610, word2vec, INFO, PROGRESS: at sentence #80000, processed 3240046 words, keeping 170201 word types ]
[2024-12-11 18:10:34,716, word2vec, INFO, PROGRESS: at sentence #90000, processed 3644180 words, keeping 184495 word types ]
[2024-12-11 18:10:34,819, word2vec, INFO, PROGRESS: at sentence #100000, processed 4040927 words, keeping 197609 word types ]
[2024-12-11 18:10:34,855, word2vec, INFO, collected 201843 word types from a corpus of 4170053 raw words and 103304 sentences ]
[2024-12-11 18:10:34,856, word2vec, INFO, Creating a fresh vocabulary ]
[2024-12-11 18:10:35,849, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 retains 201843 unique words (100.00% of original 201843, drops 0)', 'datetime': '2024-12-11T18:10:35.849347', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-11 18:10:35,850, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 leaves 4170053 word corpus (100.00% of original 4170053, drops 0)', 'datetime': '2024-12-11T18:10:35.850340', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-11 18:10:37,476, word2vec, INFO, deleting the raw counts dictionary of 201843 items ]
[2024-12-11 18:10:37,481, word2vec, INFO, sample=0.001 downsamples 29 most-common words ]
[2024-12-11 18:10:37,496, utils, INFO, FastText lifecycle event {'msg': 'downsampling leaves estimated 3937826.8948733485 word corpus (94.4%% of prior 4170053)', 'datetime': '2024-12-11T18:10:37.496898', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-11 18:10:42,033, fasttext, INFO, estimated required memory for 201843 words, 2000000 buckets and 500 dimensions: 4951844772 bytes ]
[2024-12-11 18:10:42,034, word2vec, INFO, resetting layer weights ]
[2024-12-11 18:11:01,699, utils, INFO, FastText lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-12-11T18:11:01.699734', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'} ]
[2024-12-11 18:11:01,701, utils, INFO, FastText lifecycle event {'msg': 'training model with 3 workers on 201843 vocabulary and 500 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-12-11T18:11:01.701732', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'} ]
[2024-12-11 18:11:02,908, word2vec, INFO, EPOCH 0 - PROGRESS: at 0.91% examples, 31329 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:03,912, word2vec, INFO, EPOCH 0 - PROGRESS: at 2.79% examples, 51053 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:04,913, word2vec, INFO, EPOCH 0 - PROGRESS: at 4.05% examples, 49753 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:06,362, word2vec, INFO, EPOCH 0 - PROGRESS: at 5.93% examples, 50402 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:07,368, word2vec, INFO, EPOCH 0 - PROGRESS: at 7.73% examples, 54748 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:08,771, word2vec, INFO, EPOCH 0 - PROGRESS: at 9.43% examples, 53159 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:10,189, word2vec, INFO, EPOCH 0 - PROGRESS: at 11.56% examples, 54259 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:11,209, word2vec, INFO, EPOCH 0 - PROGRESS: at 13.33% examples, 55374 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:12,662, word2vec, INFO, EPOCH 0 - PROGRESS: at 15.28% examples, 54910 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:13,697, word2vec, INFO, EPOCH 0 - PROGRESS: at 16.68% examples, 54887 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:14,789, word2vec, INFO, EPOCH 0 - PROGRESS: at 18.12% examples, 54614 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:15,832, word2vec, INFO, EPOCH 0 - PROGRESS: at 19.57% examples, 54566 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:16,853, word2vec, INFO, EPOCH 0 - PROGRESS: at 21.00% examples, 54623 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:17,959, word2vec, INFO, EPOCH 0 - PROGRESS: at 22.87% examples, 55540 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:19,257, word2vec, INFO, EPOCH 0 - PROGRESS: at 24.51% examples, 55178 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:20,277, word2vec, INFO, EPOCH 0 - PROGRESS: at 25.89% examples, 55191 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:21,413, word2vec, INFO, EPOCH 0 - PROGRESS: at 27.83% examples, 55836 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:22,683, word2vec, INFO, EPOCH 0 - PROGRESS: at 29.49% examples, 55591 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:23,766, word2vec, INFO, EPOCH 0 - PROGRESS: at 31.11% examples, 55853 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:24,806, word2vec, INFO, EPOCH 0 - PROGRESS: at 32.81% examples, 56182 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:26,082, word2vec, INFO, EPOCH 0 - PROGRESS: at 34.44% examples, 55932 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:27,083, word2vec, INFO, EPOCH 0 - PROGRESS: at 35.87% examples, 55939 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:28,118, word2vec, INFO, EPOCH 0 - PROGRESS: at 37.74% examples, 56603 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:29,419, word2vec, INFO, EPOCH 0 - PROGRESS: at 39.48% examples, 56317 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:30,464, word2vec, INFO, EPOCH 0 - PROGRESS: at 41.03% examples, 56567 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:31,789, word2vec, INFO, EPOCH 0 - PROGRESS: at 42.91% examples, 56577 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:32,810, word2vec, INFO, EPOCH 0 - PROGRESS: at 44.64% examples, 56819 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:34,084, word2vec, INFO, EPOCH 0 - PROGRESS: at 46.64% examples, 56911 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:35,173, word2vec, INFO, EPOCH 0 - PROGRESS: at 48.31% examples, 57028 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:36,448, word2vec, INFO, EPOCH 0 - PROGRESS: at 50.29% examples, 57099 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:37,565, word2vec, INFO, EPOCH 0 - PROGRESS: at 51.95% examples, 57152 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:38,862, word2vec, INFO, EPOCH 0 - PROGRESS: at 53.83% examples, 57189 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:39,943, word2vec, INFO, EPOCH 0 - PROGRESS: at 55.50% examples, 57299 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:41,219, word2vec, INFO, EPOCH 0 - PROGRESS: at 57.36% examples, 57352 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:42,301, word2vec, INFO, EPOCH 0 - PROGRESS: at 59.11% examples, 57446 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:43,628, word2vec, INFO, EPOCH 0 - PROGRESS: at 60.99% examples, 57409 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:45,034, word2vec, INFO, EPOCH 0 - PROGRESS: at 63.20% examples, 57499 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:46,487, word2vec, INFO, EPOCH 0 - PROGRESS: at 65.38% examples, 57514 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:47,896, word2vec, INFO, EPOCH 0 - PROGRESS: at 67.48% examples, 57589 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:48,900, word2vec, INFO, EPOCH 0 - PROGRESS: at 69.36% examples, 57963 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:50,201, word2vec, INFO, EPOCH 0 - PROGRESS: at 70.99% examples, 57768 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:51,253, word2vec, INFO, EPOCH 0 - PROGRESS: at 72.92% examples, 58057 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:52,618, word2vec, INFO, EPOCH 0 - PROGRESS: at 74.57% examples, 57791 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:53,648, word2vec, INFO, EPOCH 0 - PROGRESS: at 76.39% examples, 58097 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:54,950, word2vec, INFO, EPOCH 0 - PROGRESS: at 78.06% examples, 57912 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:56,092, word2vec, INFO, EPOCH 0 - PROGRESS: at 79.94% examples, 58087 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:57,339, word2vec, INFO, EPOCH 0 - PROGRESS: at 81.54% examples, 57959 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:11:58,534, word2vec, INFO, EPOCH 0 - PROGRESS: at 83.44% examples, 58062 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:11:59,649, word2vec, INFO, EPOCH 0 - PROGRESS: at 85.16% examples, 58079 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:00,716, word2vec, INFO, EPOCH 0 - PROGRESS: at 86.87% examples, 58144 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:01,721, word2vec, INFO, EPOCH 0 - PROGRESS: at 88.37% examples, 58110 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:02,853, word2vec, INFO, EPOCH 0 - PROGRESS: at 90.12% examples, 58110 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:03,946, word2vec, INFO, EPOCH 0 - PROGRESS: at 91.75% examples, 58146 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:05,075, word2vec, INFO, EPOCH 0 - PROGRESS: at 93.47% examples, 58149 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:06,223, word2vec, INFO, EPOCH 0 - PROGRESS: at 95.10% examples, 58137 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:07,299, word2vec, INFO, EPOCH 0 - PROGRESS: at 96.82% examples, 58184 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:08,407, word2vec, INFO, EPOCH 0 - PROGRESS: at 98.56% examples, 58205 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:09,278, word2vec, INFO, EPOCH 0: training on 4170053 raw words (3937516 effective words) took 67.6s, 58273 effective words/s ]
[2024-12-11 18:12:10,289, word2vec, INFO, EPOCH 1 - PROGRESS: at 1.38% examples, 56142 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:11,662, word2vec, INFO, EPOCH 1 - PROGRESS: at 3.04% examples, 51273 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:12,666, word2vec, INFO, EPOCH 1 - PROGRESS: at 4.95% examples, 58339 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:13,969, word2vec, INFO, EPOCH 1 - PROGRESS: at 6.59% examples, 56097 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:15,007, word2vec, INFO, EPOCH 1 - PROGRESS: at 8.45% examples, 59087 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:16,340, word2vec, INFO, EPOCH 1 - PROGRESS: at 10.10% examples, 57248 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:17,347, word2vec, INFO, EPOCH 1 - PROGRESS: at 11.82% examples, 58261 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:18,364, word2vec, INFO, EPOCH 1 - PROGRESS: at 13.56% examples, 58999 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:19,668, word2vec, INFO, EPOCH 1 - PROGRESS: at 15.28% examples, 57928 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:20,698, word2vec, INFO, EPOCH 1 - PROGRESS: at 16.92% examples, 58473 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:21,770, word2vec, INFO, EPOCH 1 - PROGRESS: at 18.60% examples, 58734 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:23,057, word2vec, INFO, EPOCH 1 - PROGRESS: at 20.30% examples, 58019 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:24,092, word2vec, INFO, EPOCH 1 - PROGRESS: at 21.91% examples, 58430 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:25,200, word2vec, INFO, EPOCH 1 - PROGRESS: at 23.58% examples, 58493 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:26,539, word2vec, INFO, EPOCH 1 - PROGRESS: at 25.25% examples, 57751 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:27,560, word2vec, INFO, EPOCH 1 - PROGRESS: at 26.88% examples, 58142 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:28,616, word2vec, INFO, EPOCH 1 - PROGRESS: at 28.30% examples, 57890 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:29,722, word2vec, INFO, EPOCH 1 - PROGRESS: at 29.97% examples, 57981 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:30,901, word2vec, INFO, EPOCH 1 - PROGRESS: at 31.63% examples, 57872 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:32,046, word2vec, INFO, EPOCH 1 - PROGRESS: at 33.30% examples, 57841 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:33,105, word2vec, INFO, EPOCH 1 - PROGRESS: at 34.92% examples, 58026 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:34,274, word2vec, INFO, EPOCH 1 - PROGRESS: at 36.58% examples, 57937 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:35,383, word2vec, INFO, EPOCH 1 - PROGRESS: at 38.27% examples, 57998 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:36,559, word2vec, INFO, EPOCH 1 - PROGRESS: at 39.91% examples, 57920 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:37,560, word2vec, INFO, EPOCH 1 - PROGRESS: at 41.26% examples, 57871 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:38,773, word2vec, INFO, EPOCH 1 - PROGRESS: at 42.91% examples, 57721 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:39,801, word2vec, INFO, EPOCH 1 - PROGRESS: at 44.64% examples, 57920 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:40,953, word2vec, INFO, EPOCH 1 - PROGRESS: at 46.39% examples, 57890 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:42,092, word2vec, INFO, EPOCH 1 - PROGRESS: at 48.09% examples, 57889 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:43,178, word2vec, INFO, EPOCH 1 - PROGRESS: at 49.77% examples, 57977 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:44,297, word2vec, INFO, EPOCH 1 - PROGRESS: at 51.45% examples, 58003 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:45,460, word2vec, INFO, EPOCH 1 - PROGRESS: at 53.14% examples, 57957 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:46,487, word2vec, INFO, EPOCH 1 - PROGRESS: at 54.10% examples, 57370 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:47,606, word2vec, INFO, EPOCH 1 - PROGRESS: at 54.57% examples, 56187 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:48,736, word2vec, INFO, EPOCH 1 - PROGRESS: at 55.73% examples, 55774 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:49,806, word2vec, INFO, EPOCH 1 - PROGRESS: at 57.36% examples, 55923 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:50,964, word2vec, INFO, EPOCH 1 - PROGRESS: at 59.11% examples, 55950 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:52,092, word2vec, INFO, EPOCH 1 - PROGRESS: at 60.76% examples, 56002 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:53,154, word2vec, INFO, EPOCH 1 - PROGRESS: at 62.44% examples, 56149 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:54,262, word2vec, INFO, EPOCH 1 - PROGRESS: at 64.20% examples, 56225 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:55,403, word2vec, INFO, EPOCH 1 - PROGRESS: at 65.85% examples, 56255 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:12:56,443, word2vec, INFO, EPOCH 1 - PROGRESS: at 67.48% examples, 56408 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:57,588, word2vec, INFO, EPOCH 1 - PROGRESS: at 69.11% examples, 56438 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:58,626, word2vec, INFO, EPOCH 1 - PROGRESS: at 70.53% examples, 56396 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:12:59,758, word2vec, INFO, EPOCH 1 - PROGRESS: at 71.94% examples, 56249 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:00,810, word2vec, INFO, EPOCH 1 - PROGRESS: at 73.38% examples, 56191 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:02,144, word2vec, INFO, EPOCH 1 - PROGRESS: at 74.08% examples, 55308 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:03,225, word2vec, INFO, EPOCH 1 - PROGRESS: at 74.57% examples, 54549 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:04,267, word2vec, INFO, EPOCH 1 - PROGRESS: at 75.93% examples, 54543 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:05,508, word2vec, INFO, EPOCH 1 - PROGRESS: at 77.59% examples, 54509 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:06,626, word2vec, INFO, EPOCH 1 - PROGRESS: at 79.22% examples, 54599 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:07,649, word2vec, INFO, EPOCH 1 - PROGRESS: at 80.86% examples, 54764 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:08,691, word2vec, INFO, EPOCH 1 - PROGRESS: at 82.25% examples, 54753 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:09,770, word2vec, INFO, EPOCH 1 - PROGRESS: at 83.69% examples, 54706 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:10,826, word2vec, INFO, EPOCH 1 - PROGRESS: at 85.16% examples, 54683 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:11,918, word2vec, INFO, EPOCH 1 - PROGRESS: at 86.65% examples, 54628 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:12,941, word2vec, INFO, EPOCH 1 - PROGRESS: at 87.84% examples, 54492 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:14,006, word2vec, INFO, EPOCH 1 - PROGRESS: at 89.60% examples, 54613 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:15,196, word2vec, INFO, EPOCH 1 - PROGRESS: at 91.30% examples, 54624 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:16,294, word2vec, INFO, EPOCH 1 - PROGRESS: at 92.95% examples, 54711 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:17,492, word2vec, INFO, EPOCH 1 - PROGRESS: at 94.63% examples, 54718 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:18,701, word2vec, INFO, EPOCH 1 - PROGRESS: at 96.36% examples, 54710 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:19,914, word2vec, INFO, EPOCH 1 - PROGRESS: at 98.30% examples, 54836 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:20,974, word2vec, INFO, EPOCH 1 - PROGRESS: at 100.00% examples, 54927 words/s, in_qsize 0, out_qsize 1 ]
[2024-12-11 18:13:20,975, word2vec, INFO, EPOCH 1: training on 4170053 raw words (3937749 effective words) took 71.7s, 54927 effective words/s ]
[2024-12-11 18:13:22,014, word2vec, INFO, EPOCH 2 - PROGRESS: at 0.91% examples, 36352 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:23,020, word2vec, INFO, EPOCH 2 - PROGRESS: at 2.57% examples, 50566 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:24,352, word2vec, INFO, EPOCH 2 - PROGRESS: at 4.49% examples, 52915 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:25,500, word2vec, INFO, EPOCH 2 - PROGRESS: at 5.93% examples, 51913 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:26,723, word2vec, INFO, EPOCH 2 - PROGRESS: at 6.59% examples, 45764 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:27,880, word2vec, INFO, EPOCH 2 - PROGRESS: at 7.97% examples, 46287 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:29,032, word2vec, INFO, EPOCH 2 - PROGRESS: at 9.87% examples, 49011 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:30,314, word2vec, INFO, EPOCH 2 - PROGRESS: at 11.56% examples, 49338 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:31,505, word2vec, INFO, EPOCH 2 - PROGRESS: at 13.56% examples, 50907 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:32,680, word2vec, INFO, EPOCH 2 - PROGRESS: at 15.28% examples, 51433 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:34,070, word2vec, INFO, EPOCH 2 - PROGRESS: at 16.02% examples, 48129 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:35,379, word2vec, INFO, EPOCH 2 - PROGRESS: at 16.68% examples, 45718 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:36,561, word2vec, INFO, EPOCH 2 - PROGRESS: at 18.60% examples, 47074 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:37,768, word2vec, INFO, EPOCH 2 - PROGRESS: at 20.30% examples, 47594 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:38,783, word2vec, INFO, EPOCH 2 - PROGRESS: at 21.91% examples, 48601 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:39,945, word2vec, INFO, EPOCH 2 - PROGRESS: at 23.58% examples, 49085 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:41,174, word2vec, INFO, EPOCH 2 - PROGRESS: at 25.25% examples, 49345 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:42,365, word2vec, INFO, EPOCH 2 - PROGRESS: at 27.09% examples, 50131 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:43,545, word2vec, INFO, EPOCH 2 - PROGRESS: at 28.76% examples, 50429 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:44,602, word2vec, INFO, EPOCH 2 - PROGRESS: at 30.41% examples, 50960 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:45,830, word2vec, INFO, EPOCH 2 - PROGRESS: at 32.10% examples, 51089 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:46,861, word2vec, INFO, EPOCH 2 - PROGRESS: at 33.75% examples, 51596 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:47,862, word2vec, INFO, EPOCH 2 - PROGRESS: at 35.41% examples, 52115 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:49,011, word2vec, INFO, EPOCH 2 - PROGRESS: at 37.05% examples, 52321 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:50,123, word2vec, INFO, EPOCH 2 - PROGRESS: at 38.74% examples, 52583 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:51,168, word2vec, INFO, EPOCH 2 - PROGRESS: at 40.34% examples, 52949 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:52,277, word2vec, INFO, EPOCH 2 - PROGRESS: at 41.95% examples, 53180 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:53,403, word2vec, INFO, EPOCH 2 - PROGRESS: at 43.64% examples, 53361 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:54,611, word2vec, INFO, EPOCH 2 - PROGRESS: at 45.35% examples, 53390 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:55,653, word2vec, INFO, EPOCH 2 - PROGRESS: at 47.14% examples, 53682 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:13:56,770, word2vec, INFO, EPOCH 2 - PROGRESS: at 48.82% examples, 53846 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:57,934, word2vec, INFO, EPOCH 2 - PROGRESS: at 50.53% examples, 53933 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:13:58,953, word2vec, INFO, EPOCH 2 - PROGRESS: at 52.19% examples, 54219 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:00,057, word2vec, INFO, EPOCH 2 - PROGRESS: at 53.83% examples, 54373 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:01,213, word2vec, INFO, EPOCH 2 - PROGRESS: at 55.50% examples, 54450 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:02,275, word2vec, INFO, EPOCH 2 - PROGRESS: at 57.13% examples, 54642 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:03,373, word2vec, INFO, EPOCH 2 - PROGRESS: at 58.86% examples, 54783 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:04,373, word2vec, INFO, EPOCH 2 - PROGRESS: at 60.30% examples, 54819 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:05,616, word2vec, INFO, EPOCH 2 - PROGRESS: at 61.97% examples, 54757 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:06,831, word2vec, INFO, EPOCH 2 - PROGRESS: at 63.94% examples, 54944 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:08,002, word2vec, INFO, EPOCH 2 - PROGRESS: at 65.60% examples, 54966 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:09,253, word2vec, INFO, EPOCH 2 - PROGRESS: at 67.48% examples, 55101 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:10,284, word2vec, INFO, EPOCH 2 - PROGRESS: at 68.89% examples, 55098 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:11,418, word2vec, INFO, EPOCH 2 - PROGRESS: at 70.53% examples, 55167 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:12,441, word2vec, INFO, EPOCH 2 - PROGRESS: at 72.20% examples, 55353 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:13,606, word2vec, INFO, EPOCH 2 - PROGRESS: at 73.84% examples, 55374 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:14,774, word2vec, INFO, EPOCH 2 - PROGRESS: at 75.44% examples, 55400 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:16,047, word2vec, INFO, EPOCH 2 - PROGRESS: at 76.13% examples, 54634 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:17,811, word2vec, INFO, EPOCH 2 - PROGRESS: at 76.87% examples, 53432 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:18,933, word2vec, INFO, EPOCH 2 - PROGRESS: at 78.77% examples, 53699 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:20,228, word2vec, INFO, EPOCH 2 - PROGRESS: at 80.39% examples, 53640 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:21,409, word2vec, INFO, EPOCH 2 - PROGRESS: at 82.25% examples, 53826 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:22,582, word2vec, INFO, EPOCH 2 - PROGRESS: at 83.95% examples, 53869 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:23,764, word2vec, INFO, EPOCH 2 - PROGRESS: at 85.90% examples, 54052 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:24,982, word2vec, INFO, EPOCH 2 - PROGRESS: at 87.61% examples, 54052 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:26,196, word2vec, INFO, EPOCH 2 - PROGRESS: at 89.60% examples, 54201 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:27,327, word2vec, INFO, EPOCH 2 - PROGRESS: at 91.30% examples, 54268 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:28,517, word2vec, INFO, EPOCH 2 - PROGRESS: at 93.21% examples, 54425 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:29,692, word2vec, INFO, EPOCH 2 - PROGRESS: at 94.85% examples, 54454 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:30,693, word2vec, INFO, EPOCH 2 - PROGRESS: at 96.57% examples, 54614 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:31,816, word2vec, INFO, EPOCH 2 - PROGRESS: at 98.30% examples, 54676 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:32,810, word2vec, INFO, EPOCH 2: training on 4170053 raw words (3937789 effective words) took 71.8s, 54821 effective words/s ]
[2024-12-11 18:14:34,246, word2vec, INFO, EPOCH 3 - PROGRESS: at 1.64% examples, 46032 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:35,641, word2vec, INFO, EPOCH 3 - PROGRESS: at 3.74% examples, 53228 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:36,998, word2vec, INFO, EPOCH 3 - PROGRESS: at 5.93% examples, 56144 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:38,005, word2vec, INFO, EPOCH 3 - PROGRESS: at 7.73% examples, 59759 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:39,298, word2vec, INFO, EPOCH 3 - PROGRESS: at 9.43% examples, 57974 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:40,349, word2vec, INFO, EPOCH 3 - PROGRESS: at 10.80% examples, 57396 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:41,368, word2vec, INFO, EPOCH 3 - PROGRESS: at 12.53% examples, 58249 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:42,732, word2vec, INFO, EPOCH 3 - PROGRESS: at 14.57% examples, 57837 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:43,775, word2vec, INFO, EPOCH 3 - PROGRESS: at 16.46% examples, 59206 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:45,068, word2vec, INFO, EPOCH 3 - PROGRESS: at 18.12% examples, 58334 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:46,277, word2vec, INFO, EPOCH 3 - PROGRESS: at 18.85% examples, 55189 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:47,943, word2vec, INFO, EPOCH 3 - PROGRESS: at 19.58% examples, 50970 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:48,997, word2vec, INFO, EPOCH 3 - PROGRESS: at 21.00% examples, 51141 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:50,038, word2vec, INFO, EPOCH 3 - PROGRESS: at 22.64% examples, 51879 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:51,082, word2vec, INFO, EPOCH 3 - PROGRESS: at 24.25% examples, 52507 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:52,342, word2vec, INFO, EPOCH 3 - PROGRESS: at 25.89% examples, 52500 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:53,447, word2vec, INFO, EPOCH 3 - PROGRESS: at 27.83% examples, 53342 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:54,677, word2vec, INFO, EPOCH 3 - PROGRESS: at 29.49% examples, 53348 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:55,690, word2vec, INFO, EPOCH 3 - PROGRESS: at 31.11% examples, 53874 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:56,768, word2vec, INFO, EPOCH 3 - PROGRESS: at 32.81% examples, 54196 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:14:58,059, word2vec, INFO, EPOCH 3 - PROGRESS: at 34.44% examples, 54019 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:14:59,084, word2vec, INFO, EPOCH 3 - PROGRESS: at 36.35% examples, 54769 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:00,377, word2vec, INFO, EPOCH 3 - PROGRESS: at 37.99% examples, 54593 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:01,606, word2vec, INFO, EPOCH 3 - PROGRESS: at 39.91% examples, 54878 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:02,760, word2vec, INFO, EPOCH 3 - PROGRESS: at 41.50% examples, 54967 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:03,939, word2vec, INFO, EPOCH 3 - PROGRESS: at 43.39% examples, 55301 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:04,978, word2vec, INFO, EPOCH 3 - PROGRESS: at 44.87% examples, 55255 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:06,050, word2vec, INFO, EPOCH 3 - PROGRESS: at 45.61% examples, 54323 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:07,060, word2vec, INFO, EPOCH 3 - PROGRESS: at 45.88% examples, 52991 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:08,254, word2vec, INFO, EPOCH 3 - PROGRESS: at 46.64% examples, 52002 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:09,515, word2vec, INFO, EPOCH 3 - PROGRESS: at 48.56% examples, 52268 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:10,718, word2vec, INFO, EPOCH 3 - PROGRESS: at 50.29% examples, 52343 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:11,727, word2vec, INFO, EPOCH 3 - PROGRESS: at 51.95% examples, 52676 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:12,761, word2vec, INFO, EPOCH 3 - PROGRESS: at 53.40% examples, 52728 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:13,876, word2vec, INFO, EPOCH 3 - PROGRESS: at 54.57% examples, 52447 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:15,028, word2vec, INFO, EPOCH 3 - PROGRESS: at 55.73% examples, 52133 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:16,264, word2vec, INFO, EPOCH 3 - PROGRESS: at 57.13% examples, 51946 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:17,313, word2vec, INFO, EPOCH 3 - PROGRESS: at 58.61% examples, 51989 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:18,359, word2vec, INFO, EPOCH 3 - PROGRESS: at 60.08% examples, 52034 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:19,530, word2vec, INFO, EPOCH 3 - PROGRESS: at 60.99% examples, 51525 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:20,655, word2vec, INFO, EPOCH 3 - PROGRESS: at 61.50% examples, 50706 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:21,813, word2vec, INFO, EPOCH 3 - PROGRESS: at 62.22% examples, 50087 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:22,981, word2vec, INFO, EPOCH 3 - PROGRESS: at 63.94% examples, 50229 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:23,982, word2vec, INFO, EPOCH 3 - PROGRESS: at 65.63% examples, 50529 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:25,180, word2vec, INFO, EPOCH 3 - PROGRESS: at 67.28% examples, 50627 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:26,330, word2vec, INFO, EPOCH 3 - PROGRESS: at 68.89% examples, 50775 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:27,444, word2vec, INFO, EPOCH 3 - PROGRESS: at 70.29% examples, 50774 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:28,447, word2vec, INFO, EPOCH 3 - PROGRESS: at 71.70% examples, 50873 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:29,582, word2vec, INFO, EPOCH 3 - PROGRESS: at 72.92% examples, 50681 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:30,624, word2vec, INFO, EPOCH 3 - PROGRESS: at 74.32% examples, 50745 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:31,649, word2vec, INFO, EPOCH 3 - PROGRESS: at 75.67% examples, 50820 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:32,687, word2vec, INFO, EPOCH 3 - PROGRESS: at 77.32% examples, 51039 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:33,707, word2vec, INFO, EPOCH 3 - PROGRESS: at 79.01% examples, 51268 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:34,964, word2vec, INFO, EPOCH 3 - PROGRESS: at 80.62% examples, 51291 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:35,972, word2vec, INFO, EPOCH 3 - PROGRESS: at 82.25% examples, 51510 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:37,265, word2vec, INFO, EPOCH 3 - PROGRESS: at 84.20% examples, 51642 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:38,293, word2vec, INFO, EPOCH 3 - PROGRESS: at 85.91% examples, 51833 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:39,646, word2vec, INFO, EPOCH 3 - PROGRESS: at 87.84% examples, 51911 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:40,650, word2vec, INFO, EPOCH 3 - PROGRESS: at 89.84% examples, 52251 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:41,978, word2vec, INFO, EPOCH 3 - PROGRESS: at 91.51% examples, 52199 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:43,029, word2vec, INFO, EPOCH 3 - PROGRESS: at 93.47% examples, 52487 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:44,035, word2vec, INFO, EPOCH 3 - PROGRESS: at 94.85% examples, 52540 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:45,206, word2vec, INFO, EPOCH 3 - PROGRESS: at 96.57% examples, 52598 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:46,441, word2vec, INFO, EPOCH 3 - PROGRESS: at 98.56% examples, 52736 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:47,302, word2vec, INFO, EPOCH 3: training on 4170053 raw words (3938043 effective words) took 74.5s, 52869 effective words/s ]
[2024-12-11 18:15:48,344, word2vec, INFO, EPOCH 4 - PROGRESS: at 1.38% examples, 54424 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:49,365, word2vec, INFO, EPOCH 4 - PROGRESS: at 2.79% examples, 54676 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:50,863, word2vec, INFO, EPOCH 4 - PROGRESS: at 4.51% examples, 50187 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:52,301, word2vec, INFO, EPOCH 4 - PROGRESS: at 6.59% examples, 52633 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:53,709, word2vec, INFO, EPOCH 4 - PROGRESS: at 8.70% examples, 54280 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:54,737, word2vec, INFO, EPOCH 4 - PROGRESS: at 10.57% examples, 56895 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:56,176, word2vec, INFO, EPOCH 4 - PROGRESS: at 12.31% examples, 55100 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:15:57,655, word2vec, INFO, EPOCH 4 - PROGRESS: at 14.57% examples, 55422 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:15:59,078, word2vec, INFO, EPOCH 4 - PROGRESS: at 16.68% examples, 55915 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:00,116, word2vec, INFO, EPOCH 4 - PROGRESS: at 18.60% examples, 57263 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:01,215, word2vec, INFO, EPOCH 4 - PROGRESS: at 20.06% examples, 56781 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:02,231, word2vec, INFO, EPOCH 4 - PROGRESS: at 21.00% examples, 55442 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:03,259, word2vec, INFO, EPOCH 4 - PROGRESS: at 22.39% examples, 55418 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:04,378, word2vec, INFO, EPOCH 4 - PROGRESS: at 23.81% examples, 55100 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:05,435, word2vec, INFO, EPOCH 4 - PROGRESS: at 25.25% examples, 54981 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:06,505, word2vec, INFO, EPOCH 4 - PROGRESS: at 26.88% examples, 55357 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:08,474, word2vec, INFO, EPOCH 4 - PROGRESS: at 28.76% examples, 53769 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:10,001, word2vec, INFO, EPOCH 4 - PROGRESS: at 29.49% examples, 51389 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:11,215, word2vec, INFO, EPOCH 4 - PROGRESS: at 30.87% examples, 51142 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:12,279, word2vec, INFO, EPOCH 4 - PROGRESS: at 32.60% examples, 51593 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:13,287, word2vec, INFO, EPOCH 4 - PROGRESS: at 34.23% examples, 52111 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:14,546, word2vec, INFO, EPOCH 4 - PROGRESS: at 35.87% examples, 52112 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:15,638, word2vec, INFO, EPOCH 4 - PROGRESS: at 37.50% examples, 52431 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:16,654, word2vec, INFO, EPOCH 4 - PROGRESS: at 39.25% examples, 52859 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:17,846, word2vec, INFO, EPOCH 4 - PROGRESS: at 40.80% examples, 52960 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:18,969, word2vec, INFO, EPOCH 4 - PROGRESS: at 42.45% examples, 53162 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:20,224, word2vec, INFO, EPOCH 4 - PROGRESS: at 44.37% examples, 53406 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:21,263, word2vec, INFO, EPOCH 4 - PROGRESS: at 46.14% examples, 53706 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:22,267, word2vec, INFO, EPOCH 4 - PROGRESS: at 47.61% examples, 53780 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:23,272, word2vec, INFO, EPOCH 4 - PROGRESS: at 49.06% examples, 53849 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:24,475, word2vec, INFO, EPOCH 4 - PROGRESS: at 50.74% examples, 53879 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:25,497, word2vec, INFO, EPOCH 4 - PROGRESS: at 52.19% examples, 53908 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:26,549, word2vec, INFO, EPOCH 4 - PROGRESS: at 53.64% examples, 53901 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:27,723, word2vec, INFO, EPOCH 4 - PROGRESS: at 55.26% examples, 53971 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:28,867, word2vec, INFO, EPOCH 4 - PROGRESS: at 56.90% examples, 54068 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:30,097, word2vec, INFO, EPOCH 4 - PROGRESS: at 58.12% examples, 53614 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:31,697, word2vec, INFO, EPOCH 4 - PROGRESS: at 58.86% examples, 52319 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:32,711, word2vec, INFO, EPOCH 4 - PROGRESS: at 60.54% examples, 52600 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:34,010, word2vec, INFO, EPOCH 4 - PROGRESS: at 62.44% examples, 52736 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:35,086, word2vec, INFO, EPOCH 4 - PROGRESS: at 64.20% examples, 52922 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:36,433, word2vec, INFO, EPOCH 4 - PROGRESS: at 66.06% examples, 52999 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:37,449, word2vec, INFO, EPOCH 4 - PROGRESS: at 67.73% examples, 53235 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:38,778, word2vec, INFO, EPOCH 4 - PROGRESS: at 69.58% examples, 53328 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:39,819, word2vec, INFO, EPOCH 4 - PROGRESS: at 71.46% examples, 53704 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:41,086, word2vec, INFO, EPOCH 4 - PROGRESS: at 73.16% examples, 53661 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:42,176, word2vec, INFO, EPOCH 4 - PROGRESS: at 74.76% examples, 53799 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:43,527, word2vec, INFO, EPOCH 4 - PROGRESS: at 76.64% examples, 53845 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:44,537, word2vec, INFO, EPOCH 4 - PROGRESS: at 78.53% examples, 54210 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:45,809, word2vec, INFO, EPOCH 4 - PROGRESS: at 80.16% examples, 54161 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:46,900, word2vec, INFO, EPOCH 4 - PROGRESS: at 81.77% examples, 54265 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:48,163, word2vec, INFO, EPOCH 4 - PROGRESS: at 83.69% examples, 54374 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:49,216, word2vec, INFO, EPOCH 4 - PROGRESS: at 85.42% examples, 54511 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:50,555, word2vec, INFO, EPOCH 4 - PROGRESS: at 87.36% examples, 54546 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:51,571, word2vec, INFO, EPOCH 4 - PROGRESS: at 89.12% examples, 54708 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:52,831, word2vec, INFO, EPOCH 4 - PROGRESS: at 91.07% examples, 54805 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:53,919, word2vec, INFO, EPOCH 4 - PROGRESS: at 92.70% examples, 54897 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:55,290, word2vec, INFO, EPOCH 4 - PROGRESS: at 94.15% examples, 54620 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:56,482, word2vec, INFO, EPOCH 4 - PROGRESS: at 94.63% examples, 53952 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:57,636, word2vec, INFO, EPOCH 4 - PROGRESS: at 95.38% examples, 53466 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:16:58,850, word2vec, INFO, EPOCH 4 - PROGRESS: at 97.31% examples, 53608 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:16:59,993, word2vec, INFO, EPOCH 4 - PROGRESS: at 99.02% examples, 53672 words/s, in_qsize 4, out_qsize 0 ]
[2024-12-11 18:17:00,522, word2vec, INFO, EPOCH 4: training on 4170053 raw words (3937731 effective words) took 73.2s, 53783 effective words/s ]
[2024-12-11 18:17:01,949, word2vec, INFO, EPOCH 5 - PROGRESS: at 1.64% examples, 46314 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:03,308, word2vec, INFO, EPOCH 5 - PROGRESS: at 3.74% examples, 53991 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:04,732, word2vec, INFO, EPOCH 5 - PROGRESS: at 5.93% examples, 55787 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:06,329, word2vec, INFO, EPOCH 5 - PROGRESS: at 6.59% examples, 45292 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:07,486, word2vec, INFO, EPOCH 5 - PROGRESS: at 7.97% examples, 45872 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:08,502, word2vec, INFO, EPOCH 5 - PROGRESS: at 9.68% examples, 48285 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:09,962, word2vec, INFO, EPOCH 5 - PROGRESS: at 11.56% examples, 48788 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:11,447, word2vec, INFO, EPOCH 5 - PROGRESS: at 13.81% examples, 49910 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:13,125, word2vec, INFO, EPOCH 5 - PROGRESS: at 14.54% examples, 45499 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:14,317, word2vec, INFO, EPOCH 5 - PROGRESS: at 15.28% examples, 43616 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:15,769, word2vec, INFO, EPOCH 5 - PROGRESS: at 17.41% examples, 45024 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:17,175, word2vec, INFO, EPOCH 5 - PROGRESS: at 19.58% examples, 46300 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:18,181, word2vec, INFO, EPOCH 5 - PROGRESS: at 21.44% examples, 47939 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:19,310, word2vec, INFO, EPOCH 5 - PROGRESS: at 21.68% examples, 45562 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:20,482, word2vec, INFO, EPOCH 5 - PROGRESS: at 22.39% examples, 44295 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:21,499, word2vec, INFO, EPOCH 5 - PROGRESS: at 24.25% examples, 45726 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:22,858, word2vec, INFO, EPOCH 5 - PROGRESS: at 25.89% examples, 45893 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:23,863, word2vec, INFO, EPOCH 5 - PROGRESS: at 27.58% examples, 46745 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:24,873, word2vec, INFO, EPOCH 5 - PROGRESS: at 29.22% examples, 47511 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:26,144, word2vec, INFO, EPOCH 5 - PROGRESS: at 30.87% examples, 47727 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:27,188, word2vec, INFO, EPOCH 5 - PROGRESS: at 32.81% examples, 48675 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:28,555, word2vec, INFO, EPOCH 5 - PROGRESS: at 34.44% examples, 48638 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:29,567, word2vec, INFO, EPOCH 5 - PROGRESS: at 36.35% examples, 49523 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:30,964, word2vec, INFO, EPOCH 5 - PROGRESS: at 37.99% examples, 49415 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:32,352, word2vec, INFO, EPOCH 5 - PROGRESS: at 40.14% examples, 49922 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:33,392, word2vec, INFO, EPOCH 5 - PROGRESS: at 41.70% examples, 50350 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:34,408, word2vec, INFO, EPOCH 5 - PROGRESS: at 43.39% examples, 50780 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:35,629, word2vec, INFO, EPOCH 5 - PROGRESS: at 45.09% examples, 50874 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:36,715, word2vec, INFO, EPOCH 5 - PROGRESS: at 46.88% examples, 51166 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:37,946, word2vec, INFO, EPOCH 5 - PROGRESS: at 48.82% examples, 51496 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:39,098, word2vec, INFO, EPOCH 5 - PROGRESS: at 50.53% examples, 51663 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:40,360, word2vec, INFO, EPOCH 5 - PROGRESS: at 52.42% examples, 51913 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:41,469, word2vec, INFO, EPOCH 5 - PROGRESS: at 54.10% examples, 52118 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:42,547, word2vec, INFO, EPOCH 5 - PROGRESS: at 55.73% examples, 52352 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:44,009, word2vec, INFO, EPOCH 5 - PROGRESS: at 57.36% examples, 52105 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:45,021, word2vec, INFO, EPOCH 5 - PROGRESS: at 57.87% examples, 51343 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:46,188, word2vec, INFO, EPOCH 5 - PROGRESS: at 58.36% examples, 50442 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:47,209, word2vec, INFO, EPOCH 5 - PROGRESS: at 60.08% examples, 50749 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:48,374, word2vec, INFO, EPOCH 5 - PROGRESS: at 61.73% examples, 50880 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:49,433, word2vec, INFO, EPOCH 5 - PROGRESS: at 63.48% examples, 51123 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:50,633, word2vec, INFO, EPOCH 5 - PROGRESS: at 65.16% examples, 51209 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:51,752, word2vec, INFO, EPOCH 5 - PROGRESS: at 66.80% examples, 51371 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:52,787, word2vec, INFO, EPOCH 5 - PROGRESS: at 68.42% examples, 51616 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:54,029, word2vec, INFO, EPOCH 5 - PROGRESS: at 70.05% examples, 51654 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:55,153, word2vec, INFO, EPOCH 5 - PROGRESS: at 71.70% examples, 51794 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:56,470, word2vec, INFO, EPOCH 5 - PROGRESS: at 73.60% examples, 51915 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:17:57,637, word2vec, INFO, EPOCH 5 - PROGRESS: at 75.21% examples, 52012 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:17:58,859, word2vec, INFO, EPOCH 5 - PROGRESS: at 77.09% examples, 52212 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:00,045, word2vec, INFO, EPOCH 5 - PROGRESS: at 78.77% examples, 52280 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:01,066, word2vec, INFO, EPOCH 5 - PROGRESS: at 80.39% examples, 52490 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:02,217, word2vec, INFO, EPOCH 5 - PROGRESS: at 82.00% examples, 52568 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:03,438, word2vec, INFO, EPOCH 5 - PROGRESS: at 83.69% examples, 52595 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:04,677, word2vec, INFO, EPOCH 5 - PROGRESS: at 85.65% examples, 52751 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:05,920, word2vec, INFO, EPOCH 5 - PROGRESS: at 87.36% examples, 52754 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:06,941, word2vec, INFO, EPOCH 5 - PROGRESS: at 89.12% examples, 52934 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:08,094, word2vec, INFO, EPOCH 5 - PROGRESS: at 90.85% examples, 53003 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:09,143, word2vec, INFO, EPOCH 5 - PROGRESS: at 92.22% examples, 53014 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:10,346, word2vec, INFO, EPOCH 5 - PROGRESS: at 93.92% examples, 53046 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:11,428, word2vec, INFO, EPOCH 5 - PROGRESS: at 95.63% examples, 53165 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:12,587, word2vec, INFO, EPOCH 5 - PROGRESS: at 97.31% examples, 53219 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:13,731, word2vec, INFO, EPOCH 5 - PROGRESS: at 99.02% examples, 53289 words/s, in_qsize 4, out_qsize 0 ]
[2024-12-11 18:18:14,295, word2vec, INFO, EPOCH 5: training on 4170053 raw words (3937384 effective words) took 73.8s, 53376 effective words/s ]
[2024-12-11 18:18:15,690, word2vec, INFO, EPOCH 6 - PROGRESS: at 1.61% examples, 47352 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:17,141, word2vec, INFO, EPOCH 6 - PROGRESS: at 3.74% examples, 52900 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:18,512, word2vec, INFO, EPOCH 6 - PROGRESS: at 5.93% examples, 55727 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:19,902, word2vec, INFO, EPOCH 6 - PROGRESS: at 7.97% examples, 57016 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:20,934, word2vec, INFO, EPOCH 6 - PROGRESS: at 9.87% examples, 59485 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:22,289, word2vec, INFO, EPOCH 6 - PROGRESS: at 11.56% examples, 57639 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:23,321, word2vec, INFO, EPOCH 6 - PROGRESS: at 13.56% examples, 59399 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:24,660, word2vec, INFO, EPOCH 6 - PROGRESS: at 15.28% examples, 58078 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:25,759, word2vec, INFO, EPOCH 6 - PROGRESS: at 17.17% examples, 59077 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:26,988, word2vec, INFO, EPOCH 6 - PROGRESS: at 18.85% examples, 58547 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:28,029, word2vec, INFO, EPOCH 6 - PROGRESS: at 20.53% examples, 58894 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:29,134, word2vec, INFO, EPOCH 6 - PROGRESS: at 22.14% examples, 58960 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:30,416, word2vec, INFO, EPOCH 6 - PROGRESS: at 23.81% examples, 58365 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:31,478, word2vec, INFO, EPOCH 6 - PROGRESS: at 25.47% examples, 58579 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:32,687, word2vec, INFO, EPOCH 6 - PROGRESS: at 26.61% examples, 57292 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:33,755, word2vec, INFO, EPOCH 6 - PROGRESS: at 28.07% examples, 57052 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:34,795, word2vec, INFO, EPOCH 6 - PROGRESS: at 29.49% examples, 56905 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:35,834, word2vec, INFO, EPOCH 6 - PROGRESS: at 31.11% examples, 57226 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:37,005, word2vec, INFO, EPOCH 6 - PROGRESS: at 32.81% examples, 57173 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:38,135, word2vec, INFO, EPOCH 6 - PROGRESS: at 34.44% examples, 57208 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:39,181, word2vec, INFO, EPOCH 6 - PROGRESS: at 36.11% examples, 57438 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:40,333, word2vec, INFO, EPOCH 6 - PROGRESS: at 37.74% examples, 57433 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:41,651, word2vec, INFO, EPOCH 6 - PROGRESS: at 38.74% examples, 56036 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:42,667, word2vec, INFO, EPOCH 6 - PROGRESS: at 39.48% examples, 55028 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:43,689, word2vec, INFO, EPOCH 6 - PROGRESS: at 41.03% examples, 55359 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:44,780, word2vec, INFO, EPOCH 6 - PROGRESS: at 42.68% examples, 55537 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:45,967, word2vec, INFO, EPOCH 6 - PROGRESS: at 44.37% examples, 55519 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:47,082, word2vec, INFO, EPOCH 6 - PROGRESS: at 46.14% examples, 55640 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:48,123, word2vec, INFO, EPOCH 6 - PROGRESS: at 47.85% examples, 55875 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:49,239, word2vec, INFO, EPOCH 6 - PROGRESS: at 49.52% examples, 55976 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:50,431, word2vec, INFO, EPOCH 6 - PROGRESS: at 51.22% examples, 55954 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:51,438, word2vec, INFO, EPOCH 6 - PROGRESS: at 52.91% examples, 56208 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:52,475, word2vec, INFO, EPOCH 6 - PROGRESS: at 54.57% examples, 56410 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:53,735, word2vec, INFO, EPOCH 6 - PROGRESS: at 56.22% examples, 56280 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:18:54,846, word2vec, INFO, EPOCH 6 - PROGRESS: at 57.87% examples, 56362 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:56,064, word2vec, INFO, EPOCH 6 - PROGRESS: at 59.84% examples, 56519 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:57,143, word2vec, INFO, EPOCH 6 - PROGRESS: at 61.50% examples, 56622 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:58,172, word2vec, INFO, EPOCH 6 - PROGRESS: at 63.20% examples, 56794 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:18:59,302, word2vec, INFO, EPOCH 6 - PROGRESS: at 64.90% examples, 56825 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:00,378, word2vec, INFO, EPOCH 6 - PROGRESS: at 66.56% examples, 56923 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:01,431, word2vec, INFO, EPOCH 6 - PROGRESS: at 68.18% examples, 57050 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:02,682, word2vec, INFO, EPOCH 6 - PROGRESS: at 69.83% examples, 56940 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:03,705, word2vec, INFO, EPOCH 6 - PROGRESS: at 71.46% examples, 57095 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:04,734, word2vec, INFO, EPOCH 6 - PROGRESS: at 72.92% examples, 57048 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:05,750, word2vec, INFO, EPOCH 6 - PROGRESS: at 74.57% examples, 57202 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:07,001, word2vec, INFO, EPOCH 6 - PROGRESS: at 76.13% examples, 57096 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:08,031, word2vec, INFO, EPOCH 6 - PROGRESS: at 77.81% examples, 57226 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:09,069, word2vec, INFO, EPOCH 6 - PROGRESS: at 79.22% examples, 57177 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:10,075, word2vec, INFO, EPOCH 6 - PROGRESS: at 80.86% examples, 57322 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:11,227, word2vec, INFO, EPOCH 6 - PROGRESS: at 82.25% examples, 57151 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:12,297, word2vec, INFO, EPOCH 6 - PROGRESS: at 82.51% examples, 56259 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:13,334, word2vec, INFO, EPOCH 6 - PROGRESS: at 83.44% examples, 55908 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:14,354, word2vec, INFO, EPOCH 6 - PROGRESS: at 85.16% examples, 56051 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:15,495, word2vec, INFO, EPOCH 6 - PROGRESS: at 86.87% examples, 56083 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:16,638, word2vec, INFO, EPOCH 6 - PROGRESS: at 88.60% examples, 56111 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:17,678, word2vec, INFO, EPOCH 6 - PROGRESS: at 90.37% examples, 56227 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:18,894, word2vec, INFO, EPOCH 6 - PROGRESS: at 91.97% examples, 56191 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:20,101, word2vec, INFO, EPOCH 6 - PROGRESS: at 93.72% examples, 56159 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:21,157, word2vec, INFO, EPOCH 6 - PROGRESS: at 95.10% examples, 56117 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:22,207, word2vec, INFO, EPOCH 6 - PROGRESS: at 96.82% examples, 56217 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:23,446, word2vec, INFO, EPOCH 6 - PROGRESS: at 98.56% examples, 56162 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:24,301, word2vec, INFO, EPOCH 6: training on 4170053 raw words (3938776 effective words) took 70.0s, 56268 effective words/s ]
[2024-12-11 18:19:25,701, word2vec, INFO, EPOCH 7 - PROGRESS: at 1.62% examples, 47230 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:26,712, word2vec, INFO, EPOCH 7 - PROGRESS: at 3.53% examples, 58557 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:27,715, word2vec, INFO, EPOCH 7 - PROGRESS: at 4.95% examples, 57964 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:28,781, word2vec, INFO, EPOCH 7 - PROGRESS: at 5.93% examples, 52472 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:29,851, word2vec, INFO, EPOCH 7 - PROGRESS: at 7.28% examples, 52537 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:30,854, word2vec, INFO, EPOCH 7 - PROGRESS: at 8.70% examples, 53110 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:31,858, word2vec, INFO, EPOCH 7 - PROGRESS: at 10.32% examples, 54776 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:33,219, word2vec, INFO, EPOCH 7 - PROGRESS: at 12.31% examples, 54855 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:34,236, word2vec, INFO, EPOCH 7 - PROGRESS: at 14.04% examples, 55872 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:35,280, word2vec, INFO, EPOCH 7 - PROGRESS: at 15.76% examples, 56567 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:36,530, word2vec, INFO, EPOCH 7 - PROGRESS: at 17.41% examples, 56173 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:37,586, word2vec, INFO, EPOCH 7 - PROGRESS: at 19.32% examples, 57369 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:39,035, word2vec, INFO, EPOCH 7 - PROGRESS: at 21.00% examples, 56196 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:40,483, word2vec, INFO, EPOCH 7 - PROGRESS: at 23.12% examples, 56413 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:41,877, word2vec, INFO, EPOCH 7 - PROGRESS: at 25.25% examples, 56740 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:42,928, word2vec, INFO, EPOCH 7 - PROGRESS: at 27.09% examples, 57594 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:44,298, word2vec, INFO, EPOCH 7 - PROGRESS: at 28.76% examples, 56945 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:45,368, word2vec, INFO, EPOCH 7 - PROGRESS: at 30.64% examples, 57628 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:46,400, word2vec, INFO, EPOCH 7 - PROGRESS: at 32.10% examples, 57488 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:47,626, word2vec, INFO, EPOCH 7 - PROGRESS: at 32.35% examples, 54868 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:49,159, word2vec, INFO, EPOCH 7 - PROGRESS: at 33.07% examples, 52612 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:50,289, word2vec, INFO, EPOCH 7 - PROGRESS: at 34.48% examples, 52487 words/s, in_qsize 6, out_qsize 1 ]
[2024-12-11 18:19:51,309, word2vec, INFO, EPOCH 7 - PROGRESS: at 36.35% examples, 53287 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:52,670, word2vec, INFO, EPOCH 7 - PROGRESS: at 37.99% examples, 53055 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:53,685, word2vec, INFO, EPOCH 7 - PROGRESS: at 39.68% examples, 53464 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:54,736, word2vec, INFO, EPOCH 7 - PROGRESS: at 40.80% examples, 53169 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:19:55,809, word2vec, INFO, EPOCH 7 - PROGRESS: at 42.45% examples, 53450 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:56,879, word2vec, INFO, EPOCH 7 - PROGRESS: at 43.39% examples, 52849 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:58,199, word2vec, INFO, EPOCH 7 - PROGRESS: at 43.91% examples, 51342 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:19:59,294, word2vec, INFO, EPOCH 7 - PROGRESS: at 44.64% examples, 50531 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:00,315, word2vec, INFO, EPOCH 7 - PROGRESS: at 45.88% examples, 50403 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:01,319, word2vec, INFO, EPOCH 7 - PROGRESS: at 47.37% examples, 50561 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:02,537, word2vec, INFO, EPOCH 7 - PROGRESS: at 49.06% examples, 50674 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:03,655, word2vec, INFO, EPOCH 7 - PROGRESS: at 50.74% examples, 50909 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:04,770, word2vec, INFO, EPOCH 7 - PROGRESS: at 52.19% examples, 50897 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:05,846, word2vec, INFO, EPOCH 7 - PROGRESS: at 53.64% examples, 50936 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:07,019, word2vec, INFO, EPOCH 7 - PROGRESS: at 55.26% examples, 51084 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:08,184, word2vec, INFO, EPOCH 7 - PROGRESS: at 56.90% examples, 51223 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:09,432, word2vec, INFO, EPOCH 7 - PROGRESS: at 57.36% examples, 50225 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:10,766, word2vec, INFO, EPOCH 7 - PROGRESS: at 58.12% examples, 49392 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:12,282, word2vec, INFO, EPOCH 7 - PROGRESS: at 59.58% examples, 49009 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:13,731, word2vec, INFO, EPOCH 7 - PROGRESS: at 60.30% examples, 48144 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:14,808, word2vec, INFO, EPOCH 7 - PROGRESS: at 61.73% examples, 48224 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:16,737, word2vec, INFO, EPOCH 7 - PROGRESS: at 62.44% examples, 46987 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:17,810, word2vec, INFO, EPOCH 7 - PROGRESS: at 63.98% examples, 47097 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:18,841, word2vec, INFO, EPOCH 7 - PROGRESS: at 65.38% examples, 47238 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:19,999, word2vec, INFO, EPOCH 7 - PROGRESS: at 67.28% examples, 47603 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:21,373, word2vec, INFO, EPOCH 7 - PROGRESS: at 68.89% examples, 47615 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:22,536, word2vec, INFO, EPOCH 7 - PROGRESS: at 70.29% examples, 47635 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:23,607, word2vec, INFO, EPOCH 7 - PROGRESS: at 71.70% examples, 47727 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:24,689, word2vec, INFO, EPOCH 7 - PROGRESS: at 73.16% examples, 47805 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:25,890, word2vec, INFO, EPOCH 7 - PROGRESS: at 74.08% examples, 47483 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:27,486, word2vec, INFO, EPOCH 7 - PROGRESS: at 74.57% examples, 46581 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:28,495, word2vec, INFO, EPOCH 7 - PROGRESS: at 75.93% examples, 46730 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:29,571, word2vec, INFO, EPOCH 7 - PROGRESS: at 77.59% examples, 46967 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:30,580, word2vec, INFO, EPOCH 7 - PROGRESS: at 79.01% examples, 47106 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:31,623, word2vec, INFO, EPOCH 7 - PROGRESS: at 80.39% examples, 47218 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:32,722, word2vec, INFO, EPOCH 7 - PROGRESS: at 82.00% examples, 47412 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:33,981, word2vec, INFO, EPOCH 7 - PROGRESS: at 83.44% examples, 47365 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:35,102, word2vec, INFO, EPOCH 7 - PROGRESS: at 83.69% examples, 46749 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:36,833, word2vec, INFO, EPOCH 7 - PROGRESS: at 84.41% examples, 46023 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:37,908, word2vec, INFO, EPOCH 7 - PROGRESS: at 85.90% examples, 46116 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:39,066, word2vec, INFO, EPOCH 7 - PROGRESS: at 87.36% examples, 46157 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:40,278, word2vec, INFO, EPOCH 7 - PROGRESS: at 88.86% examples, 46163 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:41,981, word2vec, INFO, EPOCH 7 - PROGRESS: at 89.60% examples, 45515 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:43,200, word2vec, INFO, EPOCH 7 - PROGRESS: at 90.37% examples, 45167 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:44,502, word2vec, INFO, EPOCH 7 - PROGRESS: at 91.75% examples, 45140 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:45,871, word2vec, INFO, EPOCH 7 - PROGRESS: at 93.21% examples, 45073 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:47,023, word2vec, INFO, EPOCH 7 - PROGRESS: at 94.63% examples, 45129 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:48,154, word2vec, INFO, EPOCH 7 - PROGRESS: at 96.13% examples, 45193 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:49,276, word2vec, INFO, EPOCH 7 - PROGRESS: at 97.55% examples, 45257 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:20:50,468, word2vec, INFO, EPOCH 7 - PROGRESS: at 99.02% examples, 45287 words/s, in_qsize 4, out_qsize 0 ]
[2024-12-11 18:20:50,985, word2vec, INFO, EPOCH 7: training on 4170053 raw words (3938464 effective words) took 86.7s, 45438 effective words/s ]
[2024-12-11 18:20:52,010, word2vec, INFO, EPOCH 8 - PROGRESS: at 0.91% examples, 36886 words/s, in_qsize 6, out_qsize 0 ]
[2024-12-11 18:20:53,208, word2vec, INFO, EPOCH 8 - PROGRESS: at 2.36% examples, 42417 words/s, in_qsize 5, out_qsize 0 ]
[2024-12-11 18:21:16,302, word2vec, INFO, collecting all words and their counts ]
[2024-12-11 18:21:16,304, word2vec, INFO, PROGRESS: at sentence #0, processed 0 words, keeping 0 word types ]
[2024-12-11 18:21:16,418, word2vec, INFO, PROGRESS: at sentence #10000, processed 407873 words, keeping 45074 word types ]
[2024-12-11 18:21:16,528, word2vec, INFO, PROGRESS: at sentence #20000, processed 808292 words, keeping 69250 word types ]
[2024-12-11 18:21:16,639, word2vec, INFO, PROGRESS: at sentence #30000, processed 1216627 words, keeping 90083 word types ]
[2024-12-11 18:21:16,753, word2vec, INFO, PROGRESS: at sentence #40000, processed 1621499 words, keeping 108581 word types ]
[2024-12-11 18:21:16,865, word2vec, INFO, PROGRESS: at sentence #50000, processed 2025370 words, keeping 125156 word types ]
[2024-12-11 18:21:16,977, word2vec, INFO, PROGRESS: at sentence #60000, processed 2428035 words, keeping 140773 word types ]
[2024-12-11 18:21:17,086, word2vec, INFO, PROGRESS: at sentence #70000, processed 2828048 words, keeping 155388 word types ]
[2024-12-11 18:21:17,210, word2vec, INFO, PROGRESS: at sentence #80000, processed 3240046 words, keeping 170201 word types ]
[2024-12-11 18:21:17,331, word2vec, INFO, PROGRESS: at sentence #90000, processed 3644180 words, keeping 184495 word types ]
[2024-12-11 18:21:17,445, word2vec, INFO, PROGRESS: at sentence #100000, processed 4040927 words, keeping 197609 word types ]
[2024-12-11 18:21:17,481, word2vec, INFO, collected 201843 word types from a corpus of 4170053 raw words and 103304 sentences ]
[2024-12-11 18:21:17,482, word2vec, INFO, Creating a fresh vocabulary ]
[2024-12-11 18:21:18,499, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 retains 201843 unique words (100.00% of original 201843, drops 0)', 'datetime': '2024-12-11T18:21:18.499707', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-11 18:21:18,500, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 leaves 4170053 word corpus (100.00% of original 4170053, drops 0)', 'datetime': '2024-12-11T18:21:18.500705', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-11 18:21:20,099, word2vec, INFO, deleting the raw counts dictionary of 201843 items ]
[2024-12-11 18:21:20,104, word2vec, INFO, sample=0.001 downsamples 29 most-common words ]
[2024-12-11 18:21:20,106, utils, INFO, FastText lifecycle event {'msg': 'downsampling leaves estimated 3937826.8948733485 word corpus (94.4%% of prior 4170053)', 'datetime': '2024-12-11T18:21:20.106290', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-11 18:21:24,570, fasttext, INFO, estimated required memory for 201843 words, 2000000 buckets and 500 dimensions: 4951844772 bytes ]
[2024-12-11 18:21:24,571, word2vec, INFO, resetting layer weights ]
[2024-12-11 18:21:44,184, utils, INFO, FastText lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-12-11T18:21:44.184887', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'} ]
[2024-12-11 18:21:44,185, utils, INFO, FastText lifecycle event {'msg': 'training model with 8 workers on 201843 vocabulary and 500 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-12-11T18:21:44.185883', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'} ]
[2024-12-11 18:21:45,441, word2vec, INFO, EPOCH 0 - PROGRESS: at 0.23% examples, 7599 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:21:47,240, word2vec, INFO, EPOCH 0 - PROGRESS: at 2.12% examples, 27853 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:21:48,533, word2vec, INFO, EPOCH 0 - PROGRESS: at 4.01% examples, 36827 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:21:49,675, word2vec, INFO, EPOCH 0 - PROGRESS: at 6.38% examples, 46269 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:21:50,860, word2vec, INFO, EPOCH 0 - PROGRESS: at 8.45% examples, 50733 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:21:51,917, word2vec, INFO, EPOCH 0 - PROGRESS: at 10.57% examples, 54767 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:21:52,984, word2vec, INFO, EPOCH 0 - PROGRESS: at 12.81% examples, 57756 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:21:54,000, word2vec, INFO, EPOCH 0 - PROGRESS: at 14.81% examples, 59453 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:21:55,353, word2vec, INFO, EPOCH 0 - PROGRESS: at 17.41% examples, 61516 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:21:57,366, word2vec, INFO, EPOCH 0 - PROGRESS: at 19.32% examples, 57830 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:21:58,643, word2vec, INFO, EPOCH 0 - PROGRESS: at 20.53% examples, 55966 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:21:59,715, word2vec, INFO, EPOCH 0 - PROGRESS: at 21.21% examples, 53929 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:00,811, word2vec, INFO, EPOCH 0 - PROGRESS: at 23.58% examples, 56037 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:01,961, word2vec, INFO, EPOCH 0 - PROGRESS: at 25.69% examples, 57160 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:03,027, word2vec, INFO, EPOCH 0 - PROGRESS: at 27.83% examples, 58432 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:04,074, word2vec, INFO, EPOCH 0 - PROGRESS: at 30.19% examples, 60084 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:05,078, word2vec, INFO, EPOCH 0 - PROGRESS: at 31.62% examples, 59895 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:06,106, word2vec, INFO, EPOCH 0 - PROGRESS: at 33.52% examples, 60503 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:07,133, word2vec, INFO, EPOCH 0 - PROGRESS: at 35.64% examples, 61492 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:08,139, word2vec, INFO, EPOCH 0 - PROGRESS: at 37.99% examples, 62825 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:09,145, word2vec, INFO, EPOCH 0 - PROGRESS: at 40.14% examples, 63689 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:10,259, word2vec, INFO, EPOCH 0 - PROGRESS: at 42.45% examples, 64582 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:11,552, word2vec, INFO, EPOCH 0 - PROGRESS: at 44.64% examples, 64609 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:12,677, word2vec, INFO, EPOCH 0 - PROGRESS: at 47.14% examples, 65356 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:13,694, word2vec, INFO, EPOCH 0 - PROGRESS: at 49.31% examples, 65972 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:14,857, word2vec, INFO, EPOCH 0 - PROGRESS: at 51.45% examples, 66229 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:15,913, word2vec, INFO, EPOCH 0 - PROGRESS: at 53.59% examples, 66698 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:16,965, word2vec, INFO, EPOCH 0 - PROGRESS: at 55.98% examples, 67429 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:18,148, word2vec, INFO, EPOCH 0 - PROGRESS: at 58.12% examples, 67570 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:19,239, word2vec, INFO, EPOCH 0 - PROGRESS: at 60.30% examples, 67883 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:20,288, word2vec, INFO, EPOCH 0 - PROGRESS: at 62.47% examples, 68242 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:21,377, word2vec, INFO, EPOCH 0 - PROGRESS: at 64.43% examples, 68260 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:22,448, word2vec, INFO, EPOCH 0 - PROGRESS: at 66.80% examples, 68801 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:23,532, word2vec, INFO, EPOCH 0 - PROGRESS: at 68.64% examples, 68820 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:24,711, word2vec, INFO, EPOCH 0 - PROGRESS: at 70.78% examples, 68911 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:25,716, word2vec, INFO, EPOCH 0 - PROGRESS: at 72.92% examples, 69282 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:26,749, word2vec, INFO, EPOCH 0 - PROGRESS: at 75.00% examples, 69588 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:27,826, word2vec, INFO, EPOCH 0 - PROGRESS: at 77.32% examples, 70029 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:28,920, word2vec, INFO, EPOCH 0 - PROGRESS: at 79.46% examples, 70218 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:30,018, word2vec, INFO, EPOCH 0 - PROGRESS: at 81.54% examples, 70374 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:31,386, word2vec, INFO, EPOCH 0 - PROGRESS: at 83.69% examples, 70123 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:32,423, word2vec, INFO, EPOCH 0 - PROGRESS: at 85.91% examples, 70365 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:33,438, word2vec, INFO, EPOCH 0 - PROGRESS: at 88.37% examples, 70827 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:34,483, word2vec, INFO, EPOCH 0 - PROGRESS: at 90.60% examples, 71036 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:35,519, word2vec, INFO, EPOCH 0 - PROGRESS: at 92.70% examples, 71252 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:36,768, word2vec, INFO, EPOCH 0 - PROGRESS: at 95.10% examples, 71351 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:38,106, word2vec, INFO, EPOCH 0 - PROGRESS: at 97.31% examples, 71142 words/s, in_qsize 11, out_qsize 0 ]
[2024-12-11 18:22:38,881, word2vec, INFO, EPOCH 0: training on 4170053 raw words (3937679 effective words) took 54.7s, 72007 effective words/s ]
[2024-12-11 18:22:40,707, word2vec, INFO, EPOCH 1 - PROGRESS: at 2.12% examples, 46535 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:41,720, word2vec, INFO, EPOCH 1 - PROGRESS: at 4.50% examples, 63000 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:42,723, word2vec, INFO, EPOCH 1 - PROGRESS: at 6.37% examples, 66064 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:43,808, word2vec, INFO, EPOCH 1 - PROGRESS: at 9.20% examples, 74455 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:45,505, word2vec, INFO, EPOCH 1 - PROGRESS: at 11.56% examples, 69585 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:46,525, word2vec, INFO, EPOCH 1 - PROGRESS: at 13.82% examples, 71386 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 18:22:47,544, word2vec, INFO, EPOCH 1 - PROGRESS: at 16.46% examples, 74959 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:48,659, word2vec, INFO, EPOCH 1 - PROGRESS: at 18.85% examples, 76020 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:49,679, word2vec, INFO, EPOCH 1 - PROGRESS: at 20.77% examples, 75795 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 18:22:50,690, word2vec, INFO, EPOCH 1 - PROGRESS: at 22.87% examples, 76486 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:52,093, word2vec, INFO, EPOCH 1 - PROGRESS: at 25.00% examples, 74755 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:53,243, word2vec, INFO, EPOCH 1 - PROGRESS: at 27.09% examples, 74678 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:54,321, word2vec, INFO, EPOCH 1 - PROGRESS: at 29.27% examples, 74945 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:55,364, word2vec, INFO, EPOCH 1 - PROGRESS: at 30.87% examples, 74207 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:56,485, word2vec, INFO, EPOCH 1 - PROGRESS: at 32.81% examples, 73749 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:22:57,658, word2vec, INFO, EPOCH 1 - PROGRESS: at 34.68% examples, 73125 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:58,855, word2vec, INFO, EPOCH 1 - PROGRESS: at 36.58% examples, 72500 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:22:59,870, word2vec, INFO, EPOCH 1 - PROGRESS: at 39.25% examples, 73931 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 18:23:01,074, word2vec, INFO, EPOCH 1 - PROGRESS: at 41.50% examples, 74163 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:02,090, word2vec, INFO, EPOCH 1 - PROGRESS: at 43.39% examples, 74159 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:03,132, word2vec, INFO, EPOCH 1 - PROGRESS: at 45.62% examples, 74441 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:04,463, word2vec, INFO, EPOCH 1 - PROGRESS: at 48.09% examples, 74248 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:05,538, word2vec, INFO, EPOCH 1 - PROGRESS: at 50.29% examples, 74434 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:06,594, word2vec, INFO, EPOCH 1 - PROGRESS: at 52.42% examples, 74647 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:07,617, word2vec, INFO, EPOCH 1 - PROGRESS: at 54.32% examples, 74613 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:08,822, word2vec, INFO, EPOCH 1 - PROGRESS: at 56.90% examples, 75069 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:09,833, word2vec, INFO, EPOCH 1 - PROGRESS: at 58.86% examples, 75045 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:10,856, word2vec, INFO, EPOCH 1 - PROGRESS: at 60.99% examples, 75272 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:11,858, word2vec, INFO, EPOCH 1 - PROGRESS: at 62.69% examples, 74984 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:13,062, word2vec, INFO, EPOCH 1 - PROGRESS: at 64.90% examples, 74810 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:14,195, word2vec, INFO, EPOCH 1 - PROGRESS: at 66.80% examples, 74534 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:15,265, word2vec, INFO, EPOCH 1 - PROGRESS: at 68.67% examples, 74413 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:16,343, word2vec, INFO, EPOCH 1 - PROGRESS: at 70.78% examples, 74537 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:17,427, word2vec, INFO, EPOCH 1 - PROGRESS: at 72.94% examples, 74632 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:18,458, word2vec, INFO, EPOCH 1 - PROGRESS: at 74.76% examples, 74595 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:19,506, word2vec, INFO, EPOCH 1 - PROGRESS: at 76.39% examples, 74293 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:20,587, word2vec, INFO, EPOCH 1 - PROGRESS: at 78.29% examples, 74170 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:21,680, word2vec, INFO, EPOCH 1 - PROGRESS: at 79.94% examples, 73817 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 18:23:22,819, word2vec, INFO, EPOCH 1 - PROGRESS: at 81.54% examples, 73391 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:23,963, word2vec, INFO, EPOCH 1 - PROGRESS: at 83.21% examples, 72983 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:25,126, word2vec, INFO, EPOCH 1 - PROGRESS: at 85.42% examples, 72974 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:26,387, word2vec, INFO, EPOCH 1 - PROGRESS: at 87.61% examples, 72819 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:27,530, word2vec, INFO, EPOCH 1 - PROGRESS: at 89.60% examples, 72656 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:28,635, word2vec, INFO, EPOCH 1 - PROGRESS: at 91.55% examples, 72555 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:29,655, word2vec, INFO, EPOCH 1 - PROGRESS: at 93.47% examples, 72579 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:30,693, word2vec, INFO, EPOCH 1 - PROGRESS: at 95.62% examples, 72760 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:31,768, word2vec, INFO, EPOCH 1 - PROGRESS: at 97.55% examples, 72698 words/s, in_qsize 10, out_qsize 0 ]
[2024-12-11 18:23:32,748, word2vec, INFO, EPOCH 1: training on 4170053 raw words (3937283 effective words) took 53.9s, 73105 effective words/s ]
[2024-12-11 18:23:33,889, word2vec, INFO, EPOCH 2 - PROGRESS: at 0.20% examples, 8515 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:35,011, word2vec, INFO, EPOCH 2 - PROGRESS: at 2.12% examples, 37836 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:36,214, word2vec, INFO, EPOCH 2 - PROGRESS: at 3.98% examples, 46393 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:37,347, word2vec, INFO, EPOCH 2 - PROGRESS: at 5.93% examples, 51274 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:38,868, word2vec, INFO, EPOCH 2 - PROGRESS: at 7.73% examples, 50848 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:40,264, word2vec, INFO, EPOCH 2 - PROGRESS: at 9.87% examples, 52664 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:41,376, word2vec, INFO, EPOCH 2 - PROGRESS: at 11.56% examples, 53509 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:42,437, word2vec, INFO, EPOCH 2 - PROGRESS: at 13.56% examples, 55425 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:43,625, word2vec, INFO, EPOCH 2 - PROGRESS: at 15.78% examples, 57164 words/s, in_qsize 15, out_qsize 1 ]
[2024-12-11 18:23:44,627, word2vec, INFO, EPOCH 2 - PROGRESS: at 18.35% examples, 61081 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:45,654, word2vec, INFO, EPOCH 2 - PROGRESS: at 20.77% examples, 63497 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:46,668, word2vec, INFO, EPOCH 2 - PROGRESS: at 22.87% examples, 64970 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:48,209, word2vec, INFO, EPOCH 2 - PROGRESS: at 25.00% examples, 63954 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:49,271, word2vec, INFO, EPOCH 2 - PROGRESS: at 27.09% examples, 64978 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:50,281, word2vec, INFO, EPOCH 2 - PROGRESS: at 29.00% examples, 65533 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:51,282, word2vec, INFO, EPOCH 2 - PROGRESS: at 31.14% examples, 66564 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:52,388, word2vec, INFO, EPOCH 2 - PROGRESS: at 33.52% examples, 67598 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:53,412, word2vec, INFO, EPOCH 2 - PROGRESS: at 35.64% examples, 68324 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:54,437, word2vec, INFO, EPOCH 2 - PROGRESS: at 37.74% examples, 69007 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:55,479, word2vec, INFO, EPOCH 2 - PROGRESS: at 39.71% examples, 69158 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:56,838, word2vec, INFO, EPOCH 2 - PROGRESS: at 41.95% examples, 69161 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:57,848, word2vec, INFO, EPOCH 2 - PROGRESS: at 44.14% examples, 69732 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:23:58,929, word2vec, INFO, EPOCH 2 - PROGRESS: at 46.39% examples, 70079 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:23:59,963, word2vec, INFO, EPOCH 2 - PROGRESS: at 48.09% examples, 69835 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:01,094, word2vec, INFO, EPOCH 2 - PROGRESS: at 50.29% examples, 70037 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:02,100, word2vec, INFO, EPOCH 2 - PROGRESS: at 52.19% examples, 70195 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:03,138, word2vec, INFO, EPOCH 2 - PROGRESS: at 54.57% examples, 70904 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:04,227, word2vec, INFO, EPOCH 2 - PROGRESS: at 56.70% examples, 71135 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:05,242, word2vec, INFO, EPOCH 2 - PROGRESS: at 58.61% examples, 71234 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:06,294, word2vec, INFO, EPOCH 2 - PROGRESS: at 60.76% examples, 71501 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:07,445, word2vec, INFO, EPOCH 2 - PROGRESS: at 62.94% examples, 71573 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:08,448, word2vec, INFO, EPOCH 2 - PROGRESS: at 64.90% examples, 71661 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:09,601, word2vec, INFO, EPOCH 2 - PROGRESS: at 67.28% examples, 71966 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:10,653, word2vec, INFO, EPOCH 2 - PROGRESS: at 69.36% examples, 72209 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:11,660, word2vec, INFO, EPOCH 2 - PROGRESS: at 71.21% examples, 72277 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:12,695, word2vec, INFO, EPOCH 2 - PROGRESS: at 73.38% examples, 72516 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:13,727, word2vec, INFO, EPOCH 2 - PROGRESS: at 75.21% examples, 72529 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:14,863, word2vec, INFO, EPOCH 2 - PROGRESS: at 77.32% examples, 72581 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:15,935, word2vec, INFO, EPOCH 2 - PROGRESS: at 79.46% examples, 72745 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:16,940, word2vec, INFO, EPOCH 2 - PROGRESS: at 81.30% examples, 72787 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:18,090, word2vec, INFO, EPOCH 2 - PROGRESS: at 83.44% examples, 72803 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:19,272, word2vec, INFO, EPOCH 2 - PROGRESS: at 85.68% examples, 72768 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:20,298, word2vec, INFO, EPOCH 2 - PROGRESS: at 87.61% examples, 72784 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:21,350, word2vec, INFO, EPOCH 2 - PROGRESS: at 90.37% examples, 73336 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:22,733, word2vec, INFO, EPOCH 2 - PROGRESS: at 92.70% examples, 73188 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:23,957, word2vec, INFO, EPOCH 2 - PROGRESS: at 94.85% examples, 73097 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:25,045, word2vec, INFO, EPOCH 2 - PROGRESS: at 97.05% examples, 73188 words/s, in_qsize 12, out_qsize 0 ]
[2024-12-11 18:24:26,057, word2vec, INFO, EPOCH 2 - PROGRESS: at 99.73% examples, 73719 words/s, in_qsize 1, out_qsize 1 ]
[2024-12-11 18:24:26,091, word2vec, INFO, EPOCH 2: training on 4170053 raw words (3937549 effective words) took 53.3s, 73849 effective words/s ]
[2024-12-11 18:24:27,137, word2vec, INFO, EPOCH 3 - PROGRESS: at 1.14% examples, 45511 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:28,146, word2vec, INFO, EPOCH 3 - PROGRESS: at 3.03% examples, 59647 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:29,850, word2vec, INFO, EPOCH 3 - PROGRESS: at 5.93% examples, 62590 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:30,934, word2vec, INFO, EPOCH 3 - PROGRESS: at 7.97% examples, 66082 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:31,961, word2vec, INFO, EPOCH 3 - PROGRESS: at 9.87% examples, 67323 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 18:24:33,018, word2vec, INFO, EPOCH 3 - PROGRESS: at 12.31% examples, 70641 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:34,022, word2vec, INFO, EPOCH 3 - PROGRESS: at 14.78% examples, 73568 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:35,066, word2vec, INFO, EPOCH 3 - PROGRESS: at 17.17% examples, 75498 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:36,203, word2vec, INFO, EPOCH 3 - PROGRESS: at 19.10% examples, 74442 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:37,360, word2vec, INFO, EPOCH 3 - PROGRESS: at 20.30% examples, 70963 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:38,363, word2vec, INFO, EPOCH 3 - PROGRESS: at 21.91% examples, 70564 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:39,376, word2vec, INFO, EPOCH 3 - PROGRESS: at 23.58% examples, 70134 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:40,394, word2vec, INFO, EPOCH 3 - PROGRESS: at 25.25% examples, 69729 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:41,677, word2vec, INFO, EPOCH 3 - PROGRESS: at 27.09% examples, 68827 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:42,887, word2vec, INFO, EPOCH 3 - PROGRESS: at 28.30% examples, 66673 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:43,976, word2vec, INFO, EPOCH 3 - PROGRESS: at 29.22% examples, 64718 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:44,980, word2vec, INFO, EPOCH 3 - PROGRESS: at 31.12% examples, 65270 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:46,002, word2vec, INFO, EPOCH 3 - PROGRESS: at 33.75% examples, 67111 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:47,203, word2vec, INFO, EPOCH 3 - PROGRESS: at 35.87% examples, 67272 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:48,257, word2vec, INFO, EPOCH 3 - PROGRESS: at 37.99% examples, 67901 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:49,400, word2vec, INFO, EPOCH 3 - PROGRESS: at 40.14% examples, 68208 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:50,599, word2vec, INFO, EPOCH 3 - PROGRESS: at 42.21% examples, 68327 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:51,755, word2vec, INFO, EPOCH 3 - PROGRESS: at 44.37% examples, 68528 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:52,927, word2vec, INFO, EPOCH 3 - PROGRESS: at 46.90% examples, 69036 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:53,963, word2vec, INFO, EPOCH 3 - PROGRESS: at 49.06% examples, 69507 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:55,010, word2vec, INFO, EPOCH 3 - PROGRESS: at 51.22% examples, 69921 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:24:56,041, word2vec, INFO, EPOCH 3 - PROGRESS: at 53.64% examples, 70651 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:57,103, word2vec, INFO, EPOCH 3 - PROGRESS: at 55.50% examples, 70669 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:58,337, word2vec, INFO, EPOCH 3 - PROGRESS: at 57.61% examples, 70589 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:24:59,372, word2vec, INFO, EPOCH 3 - PROGRESS: at 59.81% examples, 70941 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:25:00,373, word2vec, INFO, EPOCH 3 - PROGRESS: at 61.75% examples, 71044 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:01,539, word2vec, INFO, EPOCH 3 - PROGRESS: at 64.20% examples, 71355 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:25:02,656, word2vec, INFO, EPOCH 3 - PROGRESS: at 66.30% examples, 71481 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:03,684, word2vec, INFO, EPOCH 3 - PROGRESS: at 68.64% examples, 72032 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:05,063, word2vec, INFO, EPOCH 3 - PROGRESS: at 70.78% examples, 71657 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:06,127, word2vec, INFO, EPOCH 3 - PROGRESS: at 72.92% examples, 71866 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:07,148, word2vec, INFO, EPOCH 3 - PROGRESS: at 74.81% examples, 71911 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:08,313, word2vec, INFO, EPOCH 3 - PROGRESS: at 77.10% examples, 72161 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:09,336, word2vec, INFO, EPOCH 3 - PROGRESS: at 79.22% examples, 72417 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:25:10,345, word2vec, INFO, EPOCH 3 - PROGRESS: at 81.07% examples, 72461 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:11,381, word2vec, INFO, EPOCH 3 - PROGRESS: at 83.44% examples, 72877 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:12,504, word2vec, INFO, EPOCH 3 - PROGRESS: at 85.65% examples, 72936 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:13,539, word2vec, INFO, EPOCH 3 - PROGRESS: at 87.61% examples, 72930 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:14,725, word2vec, INFO, EPOCH 3 - PROGRESS: at 89.84% examples, 72894 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:25:15,794, word2vec, INFO, EPOCH 3 - PROGRESS: at 91.97% examples, 73028 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:25:16,898, word2vec, INFO, EPOCH 3 - PROGRESS: at 94.15% examples, 73103 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:25:18,230, word2vec, INFO, EPOCH 3 - PROGRESS: at 95.63% examples, 72315 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:19,515, word2vec, INFO, EPOCH 3 - PROGRESS: at 97.55% examples, 71981 words/s, in_qsize 10, out_qsize 0 ]
[2024-12-11 18:25:20,566, word2vec, INFO, EPOCH 3 - PROGRESS: at 99.50% examples, 71957 words/s, in_qsize 2, out_qsize 1 ]
[2024-12-11 18:25:20,580, word2vec, INFO, EPOCH 3: training on 4170053 raw words (3937795 effective words) took 54.5s, 72282 effective words/s ]
[2024-12-11 18:25:21,990, word2vec, INFO, EPOCH 4 - PROGRESS: at 0.23% examples, 6836 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 18:25:23,338, word2vec, INFO, EPOCH 4 - PROGRESS: at 2.12% examples, 31282 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:24,493, word2vec, INFO, EPOCH 4 - PROGRESS: at 4.72% examples, 48629 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:25,665, word2vec, INFO, EPOCH 4 - PROGRESS: at 6.81% examples, 54083 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:26,684, word2vec, INFO, EPOCH 4 - PROGRESS: at 8.95% examples, 58948 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:27,762, word2vec, INFO, EPOCH 4 - PROGRESS: at 11.05% examples, 61922 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:28,887, word2vec, INFO, EPOCH 4 - PROGRESS: at 13.56% examples, 64881 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:25:29,894, word2vec, INFO, EPOCH 4 - PROGRESS: at 15.52% examples, 65956 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:31,073, word2vec, INFO, EPOCH 4 - PROGRESS: at 17.65% examples, 66620 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:25:32,074, word2vec, INFO, EPOCH 4 - PROGRESS: at 19.58% examples, 67363 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:33,098, word2vec, INFO, EPOCH 4 - PROGRESS: at 21.44% examples, 67880 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:34,116, word2vec, INFO, EPOCH 4 - PROGRESS: at 23.33% examples, 68342 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:35,128, word2vec, INFO, EPOCH 4 - PROGRESS: at 25.47% examples, 69387 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:36,131, word2vec, INFO, EPOCH 4 - PROGRESS: at 27.58% examples, 70378 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:37,180, word2vec, INFO, EPOCH 4 - PROGRESS: at 29.71% examples, 71025 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:38,199, word2vec, INFO, EPOCH 4 - PROGRESS: at 31.87% examples, 71726 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:39,210, word2vec, INFO, EPOCH 4 - PROGRESS: at 33.75% examples, 71867 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:25:40,221, word2vec, INFO, EPOCH 4 - PROGRESS: at 36.11% examples, 72934 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:41,845, word2vec, INFO, EPOCH 4 - PROGRESS: at 38.27% examples, 71340 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:25:42,951, word2vec, INFO, EPOCH 4 - PROGRESS: at 40.14% examples, 71181 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:43,984, word2vec, INFO, EPOCH 4 - PROGRESS: at 41.95% examples, 71258 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:45,024, word2vec, INFO, EPOCH 4 - PROGRESS: at 43.91% examples, 71296 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:46,069, word2vec, INFO, EPOCH 4 - PROGRESS: at 45.88% examples, 71305 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:47,162, word2vec, INFO, EPOCH 4 - PROGRESS: at 48.07% examples, 71559 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:48,169, word2vec, INFO, EPOCH 4 - PROGRESS: at 50.04% examples, 71671 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 18:25:49,178, word2vec, INFO, EPOCH 4 - PROGRESS: at 52.42% examples, 72432 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:50,378, word2vec, INFO, EPOCH 4 - PROGRESS: at 54.79% examples, 72677 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:51,388, word2vec, INFO, EPOCH 4 - PROGRESS: at 56.70% examples, 72734 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:25:52,414, word2vec, INFO, EPOCH 4 - PROGRESS: at 58.61% examples, 72758 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:53,478, word2vec, INFO, EPOCH 4 - PROGRESS: at 60.54% examples, 72691 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:54,584, word2vec, INFO, EPOCH 4 - PROGRESS: at 62.69% examples, 72797 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:55,697, word2vec, INFO, EPOCH 4 - PROGRESS: at 64.90% examples, 72894 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:25:56,771, word2vec, INFO, EPOCH 4 - PROGRESS: at 66.80% examples, 72803 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:25:57,967, word2vec, INFO, EPOCH 4 - PROGRESS: at 68.64% examples, 72488 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:25:59,104, word2vec, INFO, EPOCH 4 - PROGRESS: at 70.74% examples, 72547 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:26:00,183, word2vec, INFO, EPOCH 4 - PROGRESS: at 72.92% examples, 72708 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:01,379, word2vec, INFO, EPOCH 4 - PROGRESS: at 75.00% examples, 72653 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:02,418, word2vec, INFO, EPOCH 4 - PROGRESS: at 77.09% examples, 72874 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:26:03,482, word2vec, INFO, EPOCH 4 - PROGRESS: at 79.01% examples, 72824 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:04,540, word2vec, INFO, EPOCH 4 - PROGRESS: at 81.30% examples, 73209 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:05,619, word2vec, INFO, EPOCH 4 - PROGRESS: at 83.44% examples, 73332 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:26:07,085, word2vec, INFO, EPOCH 4 - PROGRESS: at 85.65% examples, 72840 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:08,090, word2vec, INFO, EPOCH 4 - PROGRESS: at 87.84% examples, 73080 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:09,160, word2vec, INFO, EPOCH 4 - PROGRESS: at 90.37% examples, 73405 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:10,182, word2vec, INFO, EPOCH 4 - PROGRESS: at 92.22% examples, 73409 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:26:11,215, word2vec, INFO, EPOCH 4 - PROGRESS: at 94.38% examples, 73588 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:12,215, word2vec, INFO, EPOCH 4 - PROGRESS: at 96.36% examples, 73614 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:13,283, word2vec, INFO, EPOCH 4 - PROGRESS: at 98.56% examples, 73728 words/s, in_qsize 6, out_qsize 1 ]
[2024-12-11 18:26:13,847, word2vec, INFO, EPOCH 4: training on 4170053 raw words (3937293 effective words) took 53.2s, 73986 effective words/s ]
[2024-12-11 18:26:16,307, word2vec, INFO, EPOCH 5 - PROGRESS: at 0.23% examples, 3850 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:17,318, word2vec, INFO, EPOCH 5 - PROGRESS: at 2.55% examples, 29774 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 18:26:18,327, word2vec, INFO, EPOCH 5 - PROGRESS: at 4.49% examples, 39907 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:19,334, word2vec, INFO, EPOCH 5 - PROGRESS: at 7.28% examples, 53141 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:20,975, word2vec, INFO, EPOCH 5 - PROGRESS: at 9.68% examples, 54079 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:22,117, word2vec, INFO, EPOCH 5 - PROGRESS: at 11.81% examples, 56862 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:23,119, word2vec, INFO, EPOCH 5 - PROGRESS: at 14.05% examples, 59847 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:26:24,125, word2vec, INFO, EPOCH 5 - PROGRESS: at 16.24% examples, 62228 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:25,150, word2vec, INFO, EPOCH 5 - PROGRESS: at 18.60% examples, 64922 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:26,158, word2vec, INFO, EPOCH 5 - PROGRESS: at 20.53% examples, 65709 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:27,191, word2vec, INFO, EPOCH 5 - PROGRESS: at 22.64% examples, 66980 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:28,256, word2vec, INFO, EPOCH 5 - PROGRESS: at 24.74% examples, 67896 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:26:29,730, word2vec, INFO, EPOCH 5 - PROGRESS: at 26.88% examples, 66931 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:26:30,808, word2vec, INFO, EPOCH 5 - PROGRESS: at 29.00% examples, 67674 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:31,837, word2vec, INFO, EPOCH 5 - PROGRESS: at 30.87% examples, 67989 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:32,848, word2vec, INFO, EPOCH 5 - PROGRESS: at 33.03% examples, 68825 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:33,914, word2vec, INFO, EPOCH 5 - PROGRESS: at 35.40% examples, 69823 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:26:34,921, word2vec, INFO, EPOCH 5 - PROGRESS: at 37.29% examples, 70059 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:35,927, word2vec, INFO, EPOCH 5 - PROGRESS: at 39.25% examples, 70284 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:37,084, word2vec, INFO, EPOCH 5 - PROGRESS: at 41.27% examples, 70434 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:38,125, word2vec, INFO, EPOCH 5 - PROGRESS: at 43.39% examples, 70898 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:39,165, word2vec, INFO, EPOCH 5 - PROGRESS: at 45.35% examples, 70943 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:40,178, word2vec, INFO, EPOCH 5 - PROGRESS: at 47.85% examples, 71779 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:41,225, word2vec, INFO, EPOCH 5 - PROGRESS: at 49.77% examples, 71787 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:42,492, word2vec, INFO, EPOCH 5 - PROGRESS: at 52.19% examples, 71892 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:43,708, word2vec, INFO, EPOCH 5 - PROGRESS: at 54.32% examples, 71807 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:44,903, word2vec, INFO, EPOCH 5 - PROGRESS: at 56.44% examples, 71766 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:45,923, word2vec, INFO, EPOCH 5 - PROGRESS: at 58.61% examples, 72127 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:46,969, word2vec, INFO, EPOCH 5 - PROGRESS: at 60.76% examples, 72386 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:48,098, word2vec, INFO, EPOCH 5 - PROGRESS: at 62.95% examples, 72475 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 18:26:49,102, word2vec, INFO, EPOCH 5 - PROGRESS: at 65.13% examples, 72800 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:50,189, word2vec, INFO, EPOCH 5 - PROGRESS: at 67.48% examples, 73208 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:51,751, word2vec, INFO, EPOCH 5 - PROGRESS: at 69.61% examples, 72428 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:52,909, word2vec, INFO, EPOCH 5 - PROGRESS: at 71.94% examples, 72694 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:26:53,930, word2vec, INFO, EPOCH 5 - PROGRESS: at 73.83% examples, 72716 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:55,004, word2vec, INFO, EPOCH 5 - PROGRESS: at 75.67% examples, 72653 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:26:56,032, word2vec, INFO, EPOCH 5 - PROGRESS: at 77.81% examples, 72891 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:57,078, word2vec, INFO, EPOCH 5 - PROGRESS: at 79.94% examples, 73092 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:58,130, word2vec, INFO, EPOCH 5 - PROGRESS: at 82.25% examples, 73466 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:26:59,206, word2vec, INFO, EPOCH 5 - PROGRESS: at 84.41% examples, 73589 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:00,256, word2vec, INFO, EPOCH 5 - PROGRESS: at 86.41% examples, 73543 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:27:01,590, word2vec, INFO, EPOCH 5 - PROGRESS: at 88.60% examples, 73262 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:27:02,628, word2vec, INFO, EPOCH 5 - PROGRESS: at 90.85% examples, 73433 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:03,859, word2vec, INFO, EPOCH 5 - PROGRESS: at 92.95% examples, 73319 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:04,979, word2vec, INFO, EPOCH 5 - PROGRESS: at 95.10% examples, 73372 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:06,004, word2vec, INFO, EPOCH 5 - PROGRESS: at 97.05% examples, 73367 words/s, in_qsize 12, out_qsize 0 ]
[2024-12-11 18:27:07,018, word2vec, INFO, EPOCH 5 - PROGRESS: at 99.51% examples, 73736 words/s, in_qsize 2, out_qsize 1 ]
[2024-12-11 18:27:07,073, word2vec, INFO, EPOCH 5: training on 4170053 raw words (3937566 effective words) took 53.2s, 73992 effective words/s ]
[2024-12-11 18:27:08,100, word2vec, INFO, EPOCH 6 - PROGRESS: at 0.96% examples, 37415 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 18:27:09,100, word2vec, INFO, EPOCH 6 - PROGRESS: at 2.57% examples, 51416 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:10,112, word2vec, INFO, EPOCH 6 - PROGRESS: at 4.95% examples, 65448 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 18:27:11,129, word2vec, INFO, EPOCH 6 - PROGRESS: at 6.60% examples, 65217 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:27:12,132, word2vec, INFO, EPOCH 6 - PROGRESS: at 8.95% examples, 70891 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:13,141, word2vec, INFO, EPOCH 6 - PROGRESS: at 11.05% examples, 73069 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:14,168, word2vec, INFO, EPOCH 6 - PROGRESS: at 13.05% examples, 73091 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:27:15,192, word2vec, INFO, EPOCH 6 - PROGRESS: at 15.28% examples, 74308 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:16,669, word2vec, INFO, EPOCH 6 - PROGRESS: at 17.41% examples, 71690 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:17,800, word2vec, INFO, EPOCH 6 - PROGRESS: at 19.58% examples, 72020 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:18,848, word2vec, INFO, EPOCH 6 - PROGRESS: at 21.44% examples, 72013 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:19,882, word2vec, INFO, EPOCH 6 - PROGRESS: at 23.33% examples, 72083 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:21,015, word2vec, INFO, EPOCH 6 - PROGRESS: at 25.69% examples, 72959 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:22,051, word2vec, INFO, EPOCH 6 - PROGRESS: at 27.58% examples, 72954 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:27:23,106, word2vec, INFO, EPOCH 6 - PROGRESS: at 29.49% examples, 72848 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:24,120, word2vec, INFO, EPOCH 6 - PROGRESS: at 31.63% examples, 73495 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:25,139, word2vec, INFO, EPOCH 6 - PROGRESS: at 33.75% examples, 74021 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:27:26,265, word2vec, INFO, EPOCH 6 - PROGRESS: at 35.87% examples, 74061 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:27,336, word2vec, INFO, EPOCH 6 - PROGRESS: at 37.75% examples, 73863 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 18:27:28,346, word2vec, INFO, EPOCH 6 - PROGRESS: at 39.68% examples, 73896 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:29,396, word2vec, INFO, EPOCH 6 - PROGRESS: at 41.70% examples, 74225 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:27:30,429, word2vec, INFO, EPOCH 6 - PROGRESS: at 43.91% examples, 74557 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:31,722, word2vec, INFO, EPOCH 6 - PROGRESS: at 46.14% examples, 74060 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:27:32,916, word2vec, INFO, EPOCH 6 - PROGRESS: at 48.31% examples, 73914 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:27:33,969, word2vec, INFO, EPOCH 6 - PROGRESS: at 50.50% examples, 74170 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:34,978, word2vec, INFO, EPOCH 6 - PROGRESS: at 52.65% examples, 74518 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:36,177, word2vec, INFO, EPOCH 6 - PROGRESS: at 54.79% examples, 74361 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:37,241, word2vec, INFO, EPOCH 6 - PROGRESS: at 56.90% examples, 74543 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:38,266, word2vec, INFO, EPOCH 6 - PROGRESS: at 58.86% examples, 74507 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:39,348, word2vec, INFO, EPOCH 6 - PROGRESS: at 60.99% examples, 74616 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:27:40,348, word2vec, INFO, EPOCH 6 - PROGRESS: at 62.94% examples, 74636 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:41,397, word2vec, INFO, EPOCH 6 - PROGRESS: at 65.13% examples, 74813 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:42,430, word2vec, INFO, EPOCH 6 - PROGRESS: at 67.28% examples, 75015 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:27:43,527, word2vec, INFO, EPOCH 6 - PROGRESS: at 69.36% examples, 75087 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:44,544, word2vec, INFO, EPOCH 6 - PROGRESS: at 71.21% examples, 75055 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:45,869, word2vec, INFO, EPOCH 6 - PROGRESS: at 73.38% examples, 74669 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:27:46,893, word2vec, INFO, EPOCH 6 - PROGRESS: at 75.44% examples, 74880 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:47,929, word2vec, INFO, EPOCH 6 - PROGRESS: at 77.32% examples, 74822 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:48,947, word2vec, INFO, EPOCH 6 - PROGRESS: at 79.46% examples, 75029 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:49,997, word2vec, INFO, EPOCH 6 - PROGRESS: at 81.31% examples, 74942 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 18:27:51,303, word2vec, INFO, EPOCH 6 - PROGRESS: at 83.90% examples, 75063 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:52,358, word2vec, INFO, EPOCH 6 - PROGRESS: at 86.41% examples, 75386 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:53,402, word2vec, INFO, EPOCH 6 - PROGRESS: at 88.37% examples, 75312 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:54,642, word2vec, INFO, EPOCH 6 - PROGRESS: at 90.60% examples, 75126 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:55,855, word2vec, INFO, EPOCH 6 - PROGRESS: at 92.70% examples, 74993 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:56,906, word2vec, INFO, EPOCH 6 - PROGRESS: at 95.13% examples, 75300 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:27:57,925, word2vec, INFO, EPOCH 6 - PROGRESS: at 97.08% examples, 75267 words/s, in_qsize 12, out_qsize 0 ]
[2024-12-11 18:27:59,062, word2vec, INFO, EPOCH 6 - PROGRESS: at 99.51% examples, 75431 words/s, in_qsize 2, out_qsize 1 ]
[2024-12-11 18:27:59,223, word2vec, INFO, EPOCH 6: training on 4170053 raw words (3937674 effective words) took 52.1s, 75538 effective words/s ]
[2024-12-11 18:28:00,270, word2vec, INFO, EPOCH 7 - PROGRESS: at 1.42% examples, 54864 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:01,293, word2vec, INFO, EPOCH 7 - PROGRESS: at 3.06% examples, 59454 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:02,354, word2vec, INFO, EPOCH 7 - PROGRESS: at 5.66% examples, 72449 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:03,960, word2vec, INFO, EPOCH 7 - PROGRESS: at 7.73% examples, 65728 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:05,026, word2vec, INFO, EPOCH 7 - PROGRESS: at 9.68% examples, 66600 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:06,062, word2vec, INFO, EPOCH 7 - PROGRESS: at 11.56% examples, 67534 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:07,122, word2vec, INFO, EPOCH 7 - PROGRESS: at 13.80% examples, 69205 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:08,164, word2vec, INFO, EPOCH 7 - PROGRESS: at 16.02% examples, 70613 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 18:28:09,258, word2vec, INFO, EPOCH 7 - PROGRESS: at 17.90% examples, 70420 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 18:28:10,308, word2vec, INFO, EPOCH 7 - PROGRESS: at 20.06% examples, 71372 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:11,337, word2vec, INFO, EPOCH 7 - PROGRESS: at 22.14% examples, 72321 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:12,481, word2vec, INFO, EPOCH 7 - PROGRESS: at 24.51% examples, 73157 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:13,508, word2vec, INFO, EPOCH 7 - PROGRESS: at 26.61% examples, 73839 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:15,082, word2vec, INFO, EPOCH 7 - PROGRESS: at 28.76% examples, 71853 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:16,082, word2vec, INFO, EPOCH 7 - PROGRESS: at 30.64% examples, 72056 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:17,123, word2vec, INFO, EPOCH 7 - PROGRESS: at 32.60% examples, 72067 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 18:28:18,168, word2vec, INFO, EPOCH 7 - PROGRESS: at 35.40% examples, 74010 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:19,212, word2vec, INFO, EPOCH 7 - PROGRESS: at 37.50% examples, 74387 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:20,242, word2vec, INFO, EPOCH 7 - PROGRESS: at 39.68% examples, 74774 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:21,253, word2vec, INFO, EPOCH 7 - PROGRESS: at 41.50% examples, 74767 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:22,274, word2vec, INFO, EPOCH 7 - PROGRESS: at 43.64% examples, 75121 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:23,301, word2vec, INFO, EPOCH 7 - PROGRESS: at 45.61% examples, 75025 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:24,753, word2vec, INFO, EPOCH 7 - PROGRESS: at 47.85% examples, 74065 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:25,773, word2vec, INFO, EPOCH 7 - PROGRESS: at 50.02% examples, 74411 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:26,786, word2vec, INFO, EPOCH 7 - PROGRESS: at 51.95% examples, 74399 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:28,105, word2vec, INFO, EPOCH 7 - PROGRESS: at 54.10% examples, 73939 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:29,151, word2vec, INFO, EPOCH 7 - PROGRESS: at 56.24% examples, 74191 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:30,184, word2vec, INFO, EPOCH 7 - PROGRESS: at 58.36% examples, 74446 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:31,242, word2vec, INFO, EPOCH 7 - PROGRESS: at 60.76% examples, 74907 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:32,279, word2vec, INFO, EPOCH 7 - PROGRESS: at 62.69% examples, 74834 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:33,329, word2vec, INFO, EPOCH 7 - PROGRESS: at 64.90% examples, 75006 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:34,379, word2vec, INFO, EPOCH 7 - PROGRESS: at 66.80% examples, 74901 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:35,436, word2vec, INFO, EPOCH 7 - PROGRESS: at 68.89% examples, 75057 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:36,593, word2vec, INFO, EPOCH 7 - PROGRESS: at 70.99% examples, 74999 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:37,630, word2vec, INFO, EPOCH 7 - PROGRESS: at 72.92% examples, 74930 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:38,691, word2vec, INFO, EPOCH 7 - PROGRESS: at 74.76% examples, 74824 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:39,924, word2vec, INFO, EPOCH 7 - PROGRESS: at 76.87% examples, 74638 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:41,135, word2vec, INFO, EPOCH 7 - PROGRESS: at 79.01% examples, 74505 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:42,247, word2vec, INFO, EPOCH 7 - PROGRESS: at 81.07% examples, 74542 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:43,253, word2vec, INFO, EPOCH 7 - PROGRESS: at 82.99% examples, 74544 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:44,298, word2vec, INFO, EPOCH 7 - PROGRESS: at 85.16% examples, 74692 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:45,323, word2vec, INFO, EPOCH 7 - PROGRESS: at 87.14% examples, 74664 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:46,438, word2vec, INFO, EPOCH 7 - PROGRESS: at 89.60% examples, 74894 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:47,451, word2vec, INFO, EPOCH 7 - PROGRESS: at 91.55% examples, 74877 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:48,467, word2vec, INFO, EPOCH 7 - PROGRESS: at 93.72% examples, 75050 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:49,523, word2vec, INFO, EPOCH 7 - PROGRESS: at 95.87% examples, 75158 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:50,773, word2vec, INFO, EPOCH 7 - PROGRESS: at 98.05% examples, 74974 words/s, in_qsize 8, out_qsize 0 ]
[2024-12-11 18:28:51,548, word2vec, INFO, EPOCH 7: training on 4170053 raw words (3937584 effective words) took 52.3s, 75281 effective words/s ]
[2024-12-11 18:28:52,607, word2vec, INFO, EPOCH 8 - PROGRESS: at 0.23% examples, 8995 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:53,754, word2vec, INFO, EPOCH 8 - PROGRESS: at 2.12% examples, 38473 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 18:28:54,777, word2vec, INFO, EPOCH 8 - PROGRESS: at 4.01% examples, 49548 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:55,825, word2vec, INFO, EPOCH 8 - PROGRESS: at 5.93% examples, 54953 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:56,835, word2vec, INFO, EPOCH 8 - PROGRESS: at 8.22% examples, 62252 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:28:57,842, word2vec, INFO, EPOCH 8 - PROGRESS: at 9.87% examples, 62761 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:58,901, word2vec, INFO, EPOCH 8 - PROGRESS: at 12.06% examples, 65225 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:28:59,916, word2vec, INFO, EPOCH 8 - PROGRESS: at 14.04% examples, 66331 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:00,945, word2vec, INFO, EPOCH 8 - PROGRESS: at 16.46% examples, 69087 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:01,949, word2vec, INFO, EPOCH 8 - PROGRESS: at 18.35% examples, 69651 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:03,130, word2vec, INFO, EPOCH 8 - PROGRESS: at 21.00% examples, 71477 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:04,218, word2vec, INFO, EPOCH 8 - PROGRESS: at 22.87% examples, 71299 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:05,322, word2vec, INFO, EPOCH 8 - PROGRESS: at 24.74% examples, 71035 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:06,356, word2vec, INFO, EPOCH 8 - PROGRESS: at 26.61% examples, 71172 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:07,421, word2vec, INFO, EPOCH 8 - PROGRESS: at 28.51% examples, 71146 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:08,478, word2vec, INFO, EPOCH 8 - PROGRESS: at 30.41% examples, 71150 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:09,507, word2vec, INFO, EPOCH 8 - PROGRESS: at 32.35% examples, 71262 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:10,746, word2vec, INFO, EPOCH 8 - PROGRESS: at 34.44% examples, 71057 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:11,783, word2vec, INFO, EPOCH 8 - PROGRESS: at 36.35% examples, 71116 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:12,884, word2vec, INFO, EPOCH 8 - PROGRESS: at 38.27% examples, 70971 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:13,885, word2vec, INFO, EPOCH 8 - PROGRESS: at 40.14% examples, 71169 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:15,000, word2vec, INFO, EPOCH 8 - PROGRESS: at 42.21% examples, 71395 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:16,127, word2vec, INFO, EPOCH 8 - PROGRESS: at 44.37% examples, 71546 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:17,149, word2vec, INFO, EPOCH 8 - PROGRESS: at 46.39% examples, 71629 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:18,235, word2vec, INFO, EPOCH 8 - PROGRESS: at 48.82% examples, 72242 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:19,278, word2vec, INFO, EPOCH 8 - PROGRESS: at 50.79% examples, 72237 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 18:29:20,278, word2vec, INFO, EPOCH 8 - PROGRESS: at 52.68% examples, 72334 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:21,416, word2vec, INFO, EPOCH 8 - PROGRESS: at 55.03% examples, 72735 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:22,439, word2vec, INFO, EPOCH 8 - PROGRESS: at 56.90% examples, 72757 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:23,481, word2vec, INFO, EPOCH 8 - PROGRESS: at 58.86% examples, 72745 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:24,710, word2vec, INFO, EPOCH 8 - PROGRESS: at 61.02% examples, 72580 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:25,824, word2vec, INFO, EPOCH 8 - PROGRESS: at 63.20% examples, 72691 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 18:29:26,870, word2vec, INFO, EPOCH 8 - PROGRESS: at 65.38% examples, 72927 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:27,872, word2vec, INFO, EPOCH 8 - PROGRESS: at 67.28% examples, 72985 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:29,015, word2vec, INFO, EPOCH 8 - PROGRESS: at 69.34% examples, 73025 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:30,018, word2vec, INFO, EPOCH 8 - PROGRESS: at 71.21% examples, 73076 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:31,141, word2vec, INFO, EPOCH 8 - PROGRESS: at 73.60% examples, 73375 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:32,181, word2vec, INFO, EPOCH 8 - PROGRESS: at 75.44% examples, 73356 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:33,224, word2vec, INFO, EPOCH 8 - PROGRESS: at 77.32% examples, 73324 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:34,331, word2vec, INFO, EPOCH 8 - PROGRESS: at 79.46% examples, 73413 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:35,361, word2vec, INFO, EPOCH 8 - PROGRESS: at 81.54% examples, 73610 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:36,437, word2vec, INFO, EPOCH 8 - PROGRESS: at 83.44% examples, 73517 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:37,468, word2vec, INFO, EPOCH 8 - PROGRESS: at 85.65% examples, 73707 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:38,526, word2vec, INFO, EPOCH 8 - PROGRESS: at 87.84% examples, 73849 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:39,546, word2vec, INFO, EPOCH 8 - PROGRESS: at 89.84% examples, 73850 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:40,585, word2vec, INFO, EPOCH 8 - PROGRESS: at 91.97% examples, 74010 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:41,756, word2vec, INFO, EPOCH 8 - PROGRESS: at 94.15% examples, 73968 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:42,805, word2vec, INFO, EPOCH 8 - PROGRESS: at 96.13% examples, 73923 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:43,811, word2vec, INFO, EPOCH 8 - PROGRESS: at 98.05% examples, 73937 words/s, in_qsize 8, out_qsize 0 ]
[2024-12-11 18:29:44,557, word2vec, INFO, EPOCH 8: training on 4170053 raw words (3937646 effective words) took 53.0s, 74295 effective words/s ]
[2024-12-11 18:29:45,583, word2vec, INFO, EPOCH 9 - PROGRESS: at 1.88% examples, 73870 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:46,597, word2vec, INFO, EPOCH 9 - PROGRESS: at 3.31% examples, 64631 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:47,663, word2vec, INFO, EPOCH 9 - PROGRESS: at 5.66% examples, 72824 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:48,674, word2vec, INFO, EPOCH 9 - PROGRESS: at 7.50% examples, 73197 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:50,283, word2vec, INFO, EPOCH 9 - PROGRESS: at 9.68% examples, 67360 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:51,330, word2vec, INFO, EPOCH 9 - PROGRESS: at 12.06% examples, 70856 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:52,349, word2vec, INFO, EPOCH 9 - PROGRESS: at 14.05% examples, 71258 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:53,364, word2vec, INFO, EPOCH 9 - PROGRESS: at 15.98% examples, 71605 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 18:29:54,426, word2vec, INFO, EPOCH 9 - PROGRESS: at 18.35% examples, 73431 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:55,500, word2vec, INFO, EPOCH 9 - PROGRESS: at 20.53% examples, 73948 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:56,515, word2vec, INFO, EPOCH 9 - PROGRESS: at 22.39% examples, 73984 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:29:57,636, word2vec, INFO, EPOCH 9 - PROGRESS: at 24.49% examples, 74109 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:58,665, word2vec, INFO, EPOCH 9 - PROGRESS: at 26.36% examples, 74041 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:29:59,703, word2vec, INFO, EPOCH 9 - PROGRESS: at 28.29% examples, 73939 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:00,739, word2vec, INFO, EPOCH 9 - PROGRESS: at 30.41% examples, 74439 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:30:01,740, word2vec, INFO, EPOCH 9 - PROGRESS: at 32.35% examples, 74477 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:02,956, word2vec, INFO, EPOCH 9 - PROGRESS: at 34.44% examples, 74135 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:03,957, word2vec, INFO, EPOCH 9 - PROGRESS: at 36.35% examples, 74174 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:05,142, word2vec, INFO, EPOCH 9 - PROGRESS: at 38.50% examples, 74016 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:30:06,148, word2vec, INFO, EPOCH 9 - PROGRESS: at 40.60% examples, 74494 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:07,424, word2vec, INFO, EPOCH 9 - PROGRESS: at 42.91% examples, 74455 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:08,426, word2vec, INFO, EPOCH 9 - PROGRESS: at 44.87% examples, 74456 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:09,466, word2vec, INFO, EPOCH 9 - PROGRESS: at 46.90% examples, 74372 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:10,528, word2vec, INFO, EPOCH 9 - PROGRESS: at 49.06% examples, 74592 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:11,552, word2vec, INFO, EPOCH 9 - PROGRESS: at 51.00% examples, 74548 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:12,740, word2vec, INFO, EPOCH 9 - PROGRESS: at 53.64% examples, 75072 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:13,990, word2vec, INFO, EPOCH 9 - PROGRESS: at 55.74% examples, 74766 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:15,022, word2vec, INFO, EPOCH 9 - PROGRESS: at 58.12% examples, 75323 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:16,045, word2vec, INFO, EPOCH 9 - PROGRESS: at 60.08% examples, 75265 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:17,542, word2vec, INFO, EPOCH 9 - PROGRESS: at 62.22% examples, 74402 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:18,562, word2vec, INFO, EPOCH 9 - PROGRESS: at 64.67% examples, 74930 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:19,568, word2vec, INFO, EPOCH 9 - PROGRESS: at 66.56% examples, 74922 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 18:30:20,615, word2vec, INFO, EPOCH 9 - PROGRESS: at 68.42% examples, 74834 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:21,657, word2vec, INFO, EPOCH 9 - PROGRESS: at 70.54% examples, 75020 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:22,672, word2vec, INFO, EPOCH 9 - PROGRESS: at 72.44% examples, 74993 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:30:23,681, word2vec, INFO, EPOCH 9 - PROGRESS: at 74.32% examples, 74981 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:30:24,710, word2vec, INFO, EPOCH 9 - PROGRESS: at 76.13% examples, 74941 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:25,742, word2vec, INFO, EPOCH 9 - PROGRESS: at 78.06% examples, 74889 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:26,777, word2vec, INFO, EPOCH 9 - PROGRESS: at 79.94% examples, 74842 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:27,789, word2vec, INFO, EPOCH 9 - PROGRESS: at 81.77% examples, 74821 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:28,842, word2vec, INFO, EPOCH 9 - PROGRESS: at 83.93% examples, 74953 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:29,854, word2vec, INFO, EPOCH 9 - PROGRESS: at 85.90% examples, 74937 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:30,898, word2vec, INFO, EPOCH 9 - PROGRESS: at 88.11% examples, 75074 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 18:30:31,924, word2vec, INFO, EPOCH 9 - PROGRESS: at 89.84% examples, 74839 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:32,957, word2vec, INFO, EPOCH 9 - PROGRESS: at 92.48% examples, 75377 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:33,970, word2vec, INFO, EPOCH 9 - PROGRESS: at 93.91% examples, 74977 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 18:30:35,138, word2vec, INFO, EPOCH 9 - PROGRESS: at 96.57% examples, 75289 words/s, in_qsize 14, out_qsize 0 ]
[2024-12-11 18:30:36,330, word2vec, INFO, EPOCH 9 - PROGRESS: at 98.80% examples, 75190 words/s, in_qsize 5, out_qsize 1 ]
[2024-12-11 18:30:36,766, word2vec, INFO, EPOCH 9: training on 4170053 raw words (3938036 effective words) took 52.2s, 75443 effective words/s ]
[2024-12-11 18:30:36,769, utils, INFO, FastText lifecycle event {'msg': 'training on 41700530 raw words (39376105 effective words) took 532.6s, 73934 effective words/s', 'datetime': '2024-12-11T18:30:36.769018', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'} ]
[2024-12-11 18:30:50,233, utils, INFO, FastText lifecycle event {'params': 'FastText<vocab=201843, vector_size=500, alpha=0.025>', 'datetime': '2024-12-11T18:30:50.233635', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'} ]
[2024-12-11 18:30:50,242, utils, INFO, FastText lifecycle event {'fname_or_handle': 'fasttext_reviews.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-12-11T18:30:50.242192', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'saving'} ]
[2024-12-11 18:30:50,253, utils, INFO, not storing attribute vectors ]
[2024-12-11 18:30:50,254, utils, INFO, storing np array 'vectors_vocab' to fasttext_reviews.model.wv.vectors_vocab.npy ]
[2024-12-11 18:30:51,500, utils, INFO, storing np array 'vectors_ngrams' to fasttext_reviews.model.wv.vectors_ngrams.npy ]
[2024-12-11 18:31:11,557, utils, INFO, not storing attribute buckets_word ]
[2024-12-11 18:31:11,559, utils, INFO, storing np array 'syn1neg' to fasttext_reviews.model.syn1neg.npy ]
[2024-12-11 18:31:14,260, utils, INFO, not storing attribute cum_table ]
[2024-12-11 18:31:14,393, utils, INFO, saved fasttext_reviews.model ]
[2024-12-11 20:32:20,364, utils, INFO, loading FastText object from fasttext_reviews.model ]
[2024-12-11 20:32:20,480, utils, INFO, loading wv recursively from fasttext_reviews.model.wv.* with mmap=None ]
[2024-12-11 20:32:20,481, utils, INFO, loading vectors_vocab from fasttext_reviews.model.wv.vectors_vocab.npy with mmap=None ]
[2024-12-11 20:32:21,538, utils, INFO, loading vectors_ngrams from fasttext_reviews.model.wv.vectors_ngrams.npy with mmap=None ]
[2024-12-11 20:32:52,712, utils, INFO, setting ignored attribute vectors to None ]
[2024-12-11 20:32:52,918, utils, INFO, setting ignored attribute buckets_word to None ]
[2024-12-11 20:33:07,930, utils, INFO, loading syn1neg from fasttext_reviews.model.syn1neg.npy with mmap=None ]
[2024-12-11 20:33:09,520, utils, INFO, setting ignored attribute cum_table to None ]
[2024-12-11 20:33:11,576, utils, INFO, FastText lifecycle event {'fname': 'fasttext_reviews.model', 'datetime': '2024-12-11T20:33:11.574555', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'loaded'} ]
[2024-12-11 21:09:36,931, word2vec, INFO, collecting all words and their counts ]
[2024-12-11 21:09:36,932, word2vec, INFO, PROGRESS: at sentence #0, processed 0 words, keeping 0 word types ]
[2024-12-11 21:09:37,058, word2vec, INFO, PROGRESS: at sentence #10000, processed 417356 words, keeping 38269 word types ]
[2024-12-11 21:09:37,163, word2vec, INFO, PROGRESS: at sentence #20000, processed 827291 words, keeping 57463 word types ]
[2024-12-11 21:09:37,277, word2vec, INFO, PROGRESS: at sentence #30000, processed 1245251 words, keeping 73816 word types ]
[2024-12-11 21:09:37,400, word2vec, INFO, PROGRESS: at sentence #40000, processed 1659818 words, keeping 88317 word types ]
[2024-12-11 21:09:37,535, word2vec, INFO, PROGRESS: at sentence #50000, processed 2073395 words, keeping 101105 word types ]
[2024-12-11 21:09:37,637, word2vec, INFO, PROGRESS: at sentence #60000, processed 2485740 words, keeping 113234 word types ]
[2024-12-11 21:09:37,740, word2vec, INFO, PROGRESS: at sentence #70000, processed 2895180 words, keeping 124533 word types ]
[2024-12-11 21:09:37,843, word2vec, INFO, PROGRESS: at sentence #80000, processed 3316945 words, keeping 135881 word types ]
[2024-12-11 21:09:37,947, word2vec, INFO, PROGRESS: at sentence #90000, processed 3730627 words, keeping 146822 word types ]
[2024-12-11 21:09:38,084, word2vec, INFO, PROGRESS: at sentence #100000, processed 4136518 words, keeping 156920 word types ]
[2024-12-11 21:09:38,134, word2vec, INFO, collected 160129 word types from a corpus of 4268692 raw words and 103304 sentences ]
[2024-12-11 21:09:38,135, word2vec, INFO, Creating a fresh vocabulary ]
[2024-12-11 21:09:38,997, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 retains 160129 unique words (100.00% of original 160129, drops 0)', 'datetime': '2024-12-11T21:09:38.997116', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-11 21:09:38,998, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 leaves 4268692 word corpus (100.00% of original 4268692, drops 0)', 'datetime': '2024-12-11T21:09:38.998114', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-11 21:09:40,061, word2vec, INFO, deleting the raw counts dictionary of 160129 items ]
[2024-12-11 21:09:40,065, word2vec, INFO, sample=0.001 downsamples 31 most-common words ]
[2024-12-11 21:09:40,066, utils, INFO, FastText lifecycle event {'msg': 'downsampling leaves estimated 3978110.9017322585 word corpus (93.2%% of prior 4268692)', 'datetime': '2024-12-11T21:09:40.066152', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-11 21:09:43,359, fasttext, INFO, estimated required memory for 160129 words, 2000000 buckets and 500 dimensions: 4756101440 bytes ]
[2024-12-11 21:09:43,360, word2vec, INFO, resetting layer weights ]
[2024-12-11 21:11:34,454, word2vec, INFO, collecting all words and their counts ]
[2024-12-11 21:11:34,456, word2vec, INFO, PROGRESS: at sentence #0, processed 0 words, keeping 0 word types ]
[2024-12-11 21:11:34,598, word2vec, INFO, PROGRESS: at sentence #10000, processed 417356 words, keeping 38269 word types ]
[2024-12-11 21:11:34,768, word2vec, INFO, PROGRESS: at sentence #20000, processed 827291 words, keeping 57463 word types ]
[2024-12-11 21:11:34,899, word2vec, INFO, PROGRESS: at sentence #30000, processed 1245251 words, keeping 73816 word types ]
[2024-12-11 21:11:35,012, word2vec, INFO, PROGRESS: at sentence #40000, processed 1659818 words, keeping 88317 word types ]
[2024-12-11 21:11:35,140, word2vec, INFO, PROGRESS: at sentence #50000, processed 2073395 words, keeping 101105 word types ]
[2024-12-11 21:11:35,249, word2vec, INFO, PROGRESS: at sentence #60000, processed 2485740 words, keeping 113234 word types ]
[2024-12-11 21:11:35,362, word2vec, INFO, PROGRESS: at sentence #70000, processed 2895180 words, keeping 124533 word types ]
[2024-12-11 21:11:35,480, word2vec, INFO, PROGRESS: at sentence #80000, processed 3316945 words, keeping 135881 word types ]
[2024-12-11 21:11:35,585, word2vec, INFO, PROGRESS: at sentence #90000, processed 3730627 words, keeping 146822 word types ]
[2024-12-11 21:11:35,697, word2vec, INFO, PROGRESS: at sentence #100000, processed 4136518 words, keeping 156920 word types ]
[2024-12-11 21:11:35,735, word2vec, INFO, collected 160129 word types from a corpus of 4268692 raw words and 103304 sentences ]
[2024-12-11 21:11:35,736, word2vec, INFO, Creating a fresh vocabulary ]
[2024-12-11 21:11:36,542, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 retains 160129 unique words (100.00% of original 160129, drops 0)', 'datetime': '2024-12-11T21:11:36.542152', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-11 21:11:36,544, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 leaves 4268692 word corpus (100.00% of original 4268692, drops 0)', 'datetime': '2024-12-11T21:11:36.544153', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-11 21:11:37,762, word2vec, INFO, deleting the raw counts dictionary of 160129 items ]
[2024-12-11 21:11:37,766, word2vec, INFO, sample=0.001 downsamples 31 most-common words ]
[2024-12-11 21:11:37,768, utils, INFO, FastText lifecycle event {'msg': 'downsampling leaves estimated 3978110.9017322585 word corpus (93.2%% of prior 4268692)', 'datetime': '2024-12-11T21:11:37.768872', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-11 21:11:41,443, fasttext, INFO, estimated required memory for 160129 words, 2000000 buckets and 500 dimensions: 4756101440 bytes ]
[2024-12-11 21:11:41,444, word2vec, INFO, resetting layer weights ]
[2024-12-11 21:12:02,179, utils, INFO, FastText lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-12-11T21:12:02.179769', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'} ]
[2024-12-11 21:12:02,181, utils, INFO, FastText lifecycle event {'msg': 'training model with 8 workers on 160129 vocabulary and 500 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-12-11T21:12:02.181727', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'} ]
[2024-12-11 21:19:35,726, word2vec, INFO, collecting all words and their counts ]
[2024-12-11 21:19:35,728, word2vec, INFO, PROGRESS: at sentence #0, processed 0 words, keeping 0 word types ]
[2024-12-11 21:19:35,869, word2vec, INFO, PROGRESS: at sentence #10000, processed 417356 words, keeping 38269 word types ]
[2024-12-11 21:19:35,966, word2vec, INFO, PROGRESS: at sentence #20000, processed 827291 words, keeping 57463 word types ]
[2024-12-11 21:19:36,071, word2vec, INFO, PROGRESS: at sentence #30000, processed 1245251 words, keeping 73816 word types ]
[2024-12-11 21:19:36,201, word2vec, INFO, PROGRESS: at sentence #40000, processed 1659818 words, keeping 88317 word types ]
[2024-12-11 21:19:36,337, word2vec, INFO, PROGRESS: at sentence #50000, processed 2073395 words, keeping 101105 word types ]
[2024-12-11 21:19:36,469, word2vec, INFO, PROGRESS: at sentence #60000, processed 2485740 words, keeping 113234 word types ]
[2024-12-11 21:19:36,583, word2vec, INFO, PROGRESS: at sentence #70000, processed 2895180 words, keeping 124533 word types ]
[2024-12-11 21:19:36,700, word2vec, INFO, PROGRESS: at sentence #80000, processed 3316945 words, keeping 135881 word types ]
[2024-12-11 21:19:36,812, word2vec, INFO, PROGRESS: at sentence #90000, processed 3730627 words, keeping 146822 word types ]
[2024-12-11 21:19:36,924, word2vec, INFO, PROGRESS: at sentence #100000, processed 4136518 words, keeping 156920 word types ]
[2024-12-11 21:19:36,965, word2vec, INFO, collected 160129 word types from a corpus of 4268692 raw words and 103304 sentences ]
[2024-12-11 21:19:36,966, word2vec, INFO, Creating a fresh vocabulary ]
[2024-12-11 21:19:37,752, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 retains 160129 unique words (100.00% of original 160129, drops 0)', 'datetime': '2024-12-11T21:19:37.752660', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-11 21:19:37,753, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 leaves 4268692 word corpus (100.00% of original 4268692, drops 0)', 'datetime': '2024-12-11T21:19:37.753638', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-11 21:19:38,851, word2vec, INFO, deleting the raw counts dictionary of 160129 items ]
[2024-12-11 21:19:38,855, word2vec, INFO, sample=0.001 downsamples 31 most-common words ]
[2024-12-11 21:19:38,856, utils, INFO, FastText lifecycle event {'msg': 'downsampling leaves estimated 3978110.9017322585 word corpus (93.2%% of prior 4268692)', 'datetime': '2024-12-11T21:19:38.856374', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-11 21:19:42,025, fasttext, INFO, estimated required memory for 160129 words, 2000000 buckets and 500 dimensions: 4756101440 bytes ]
[2024-12-11 21:19:42,026, word2vec, INFO, resetting layer weights ]
[2024-12-11 21:20:00,402, utils, INFO, FastText lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-12-11T21:20:00.402727', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'} ]
[2024-12-11 21:20:00,409, utils, INFO, FastText lifecycle event {'msg': 'training model with 8 workers on 160129 vocabulary and 500 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-12-11T21:20:00.409141', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'} ]
[2024-12-11 21:20:01,742, word2vec, INFO, EPOCH 0 - PROGRESS: at 1.38% examples, 53602 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:02,737, word2vec, INFO, EPOCH 0 - PROGRESS: at 3.66% examples, 72670 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:04,218, word2vec, INFO, EPOCH 0 - PROGRESS: at 5.78% examples, 65777 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:05,230, word2vec, INFO, EPOCH 0 - PROGRESS: at 8.49% examples, 75756 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:06,261, word2vec, INFO, EPOCH 0 - PROGRESS: at 10.56% examples, 76716 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:20:07,467, word2vec, INFO, EPOCH 0 - PROGRESS: at 12.97% examples, 76774 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:08,558, word2vec, INFO, EPOCH 0 - PROGRESS: at 15.16% examples, 76741 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:09,589, word2vec, INFO, EPOCH 0 - PROGRESS: at 17.71% examples, 79337 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:20:10,666, word2vec, INFO, EPOCH 0 - PROGRESS: at 19.82% examples, 79132 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:11,831, word2vec, INFO, EPOCH 0 - PROGRESS: at 21.87% examples, 78379 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:20:12,841, word2vec, INFO, EPOCH 0 - PROGRESS: at 24.16% examples, 79492 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:13,853, word2vec, INFO, EPOCH 0 - PROGRESS: at 26.19% examples, 79660 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:20:15,120, word2vec, INFO, EPOCH 0 - PROGRESS: at 28.76% examples, 79736 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:16,235, word2vec, INFO, EPOCH 0 - PROGRESS: at 31.03% examples, 79980 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:17,246, word2vec, INFO, EPOCH 0 - PROGRESS: at 33.18% examples, 80113 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:20:18,375, word2vec, INFO, EPOCH 0 - PROGRESS: at 35.48% examples, 80263 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:19,483, word2vec, INFO, EPOCH 0 - PROGRESS: at 37.53% examples, 79969 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:20,509, word2vec, INFO, EPOCH 0 - PROGRESS: at 39.89% examples, 80512 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:21,780, word2vec, INFO, EPOCH 0 - PROGRESS: at 42.34% examples, 80502 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:22,839, word2vec, INFO, EPOCH 0 - PROGRESS: at 44.48% examples, 80422 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 21:20:24,034, word2vec, INFO, EPOCH 0 - PROGRESS: at 47.18% examples, 80662 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:25,069, word2vec, INFO, EPOCH 0 - PROGRESS: at 49.30% examples, 80671 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:26,208, word2vec, INFO, EPOCH 0 - PROGRESS: at 51.39% examples, 80344 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:27,259, word2vec, INFO, EPOCH 0 - PROGRESS: at 53.95% examples, 81008 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:28,425, word2vec, INFO, EPOCH 0 - PROGRESS: at 56.30% examples, 80948 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:29,740, word2vec, INFO, EPOCH 0 - PROGRESS: at 58.59% examples, 80466 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:30,808, word2vec, INFO, EPOCH 0 - PROGRESS: at 61.19% examples, 81007 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:20:31,856, word2vec, INFO, EPOCH 0 - PROGRESS: at 63.33% examples, 80950 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:20:32,965, word2vec, INFO, EPOCH 0 - PROGRESS: at 65.47% examples, 80752 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:34,025, word2vec, INFO, EPOCH 0 - PROGRESS: at 67.52% examples, 80696 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:35,059, word2vec, INFO, EPOCH 0 - PROGRESS: at 69.78% examples, 80969 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:36,115, word2vec, INFO, EPOCH 0 - PROGRESS: at 71.88% examples, 80916 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:20:37,326, word2vec, INFO, EPOCH 0 - PROGRESS: at 74.21% examples, 80774 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:20:38,340, word2vec, INFO, EPOCH 0 - PROGRESS: at 76.23% examples, 80817 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:39,434, word2vec, INFO, EPOCH 0 - PROGRESS: at 78.54% examples, 80931 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:40,794, word2vec, INFO, EPOCH 0 - PROGRESS: at 81.02% examples, 80736 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:41,819, word2vec, INFO, EPOCH 0 - PROGRESS: at 83.34% examples, 80984 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:42,847, word2vec, INFO, EPOCH 0 - PROGRESS: at 85.50% examples, 80984 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:43,878, word2vec, INFO, EPOCH 0 - PROGRESS: at 87.40% examples, 80768 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:20:44,946, word2vec, INFO, EPOCH 0 - PROGRESS: at 89.37% examples, 80495 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:46,023, word2vec, INFO, EPOCH 0 - PROGRESS: at 91.45% examples, 80418 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:47,082, word2vec, INFO, EPOCH 0 - PROGRESS: at 93.83% examples, 80575 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:48,158, word2vec, INFO, EPOCH 0 - PROGRESS: at 95.97% examples, 80512 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:49,161, word2vec, INFO, EPOCH 0 - PROGRESS: at 98.09% examples, 80571 words/s, in_qsize 8, out_qsize 0 ]
[2024-12-11 21:20:49,783, word2vec, INFO, EPOCH 0: training on 4268692 raw words (3978540 effective words) took 49.1s, 81058 effective words/s ]
[2024-12-11 21:20:50,839, word2vec, INFO, EPOCH 1 - PROGRESS: at 1.56% examples, 62008 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:51,862, word2vec, INFO, EPOCH 1 - PROGRESS: at 3.66% examples, 71571 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:53,343, word2vec, INFO, EPOCH 1 - PROGRESS: at 5.74% examples, 65201 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:20:54,504, word2vec, INFO, EPOCH 1 - PROGRESS: at 8.49% examples, 72829 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:20:55,560, word2vec, INFO, EPOCH 1 - PROGRESS: at 10.78% examples, 75572 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:20:56,566, word2vec, INFO, EPOCH 1 - PROGRESS: at 12.97% examples, 76677 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:20:57,822, word2vec, INFO, EPOCH 1 - PROGRESS: at 15.16% examples, 75082 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:20:58,913, word2vec, INFO, EPOCH 1 - PROGRESS: at 16.98% examples, 74245 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:00,014, word2vec, INFO, EPOCH 1 - PROGRESS: at 18.88% examples, 73508 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:01,074, word2vec, INFO, EPOCH 1 - PROGRESS: at 20.73% examples, 73174 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:02,309, word2vec, INFO, EPOCH 1 - PROGRESS: at 22.80% examples, 72652 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:03,339, word2vec, INFO, EPOCH 1 - PROGRESS: at 24.87% examples, 73269 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:04,373, word2vec, INFO, EPOCH 1 - PROGRESS: at 26.89% examples, 73740 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:05,561, word2vec, INFO, EPOCH 1 - PROGRESS: at 28.99% examples, 73488 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:06,734, word2vec, INFO, EPOCH 1 - PROGRESS: at 30.82% examples, 72773 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:07,768, word2vec, INFO, EPOCH 1 - PROGRESS: at 33.18% examples, 73728 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:08,857, word2vec, INFO, EPOCH 1 - PROGRESS: at 35.00% examples, 73421 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:09,993, word2vec, INFO, EPOCH 1 - PROGRESS: at 37.09% examples, 73417 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:11,055, word2vec, INFO, EPOCH 1 - PROGRESS: at 38.98% examples, 73244 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:12,324, word2vec, INFO, EPOCH 1 - PROGRESS: at 40.96% examples, 72815 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:13,457, word2vec, INFO, EPOCH 1 - PROGRESS: at 43.04% examples, 72868 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:14,686, word2vec, INFO, EPOCH 1 - PROGRESS: at 45.19% examples, 72614 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:15,770, word2vec, INFO, EPOCH 1 - PROGRESS: at 47.18% examples, 72428 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:16,932, word2vec, INFO, EPOCH 1 - PROGRESS: at 49.25% examples, 72412 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:18,135, word2vec, INFO, EPOCH 1 - PROGRESS: at 51.39% examples, 72282 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:19,256, word2vec, INFO, EPOCH 1 - PROGRESS: at 53.29% examples, 72050 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 21:21:20,292, word2vec, INFO, EPOCH 1 - PROGRESS: at 55.10% examples, 72033 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:21,359, word2vec, INFO, EPOCH 1 - PROGRESS: at 56.94% examples, 71951 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:22,431, word2vec, INFO, EPOCH 1 - PROGRESS: at 59.09% examples, 72136 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:23,464, word2vec, INFO, EPOCH 1 - PROGRESS: at 60.94% examples, 72128 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:24,629, word2vec, INFO, EPOCH 1 - PROGRESS: at 63.08% examples, 72107 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:25,826, word2vec, INFO, EPOCH 1 - PROGRESS: at 65.23% examples, 72024 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:26,845, word2vec, INFO, EPOCH 1 - PROGRESS: at 67.08% examples, 72053 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:28,128, word2vec, INFO, EPOCH 1 - PROGRESS: at 69.11% examples, 71825 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:29,282, word2vec, INFO, EPOCH 1 - PROGRESS: at 70.93% examples, 71609 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:30,341, word2vec, INFO, EPOCH 1 - PROGRESS: at 73.07% examples, 71800 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:31,552, word2vec, INFO, EPOCH 1 - PROGRESS: at 75.07% examples, 71722 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:32,564, word2vec, INFO, EPOCH 1 - PROGRESS: at 77.13% examples, 71970 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:33,579, word2vec, INFO, EPOCH 1 - PROGRESS: at 79.20% examples, 72214 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:34,686, word2vec, INFO, EPOCH 1 - PROGRESS: at 81.24% examples, 72294 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:35,823, word2vec, INFO, EPOCH 1 - PROGRESS: at 83.12% examples, 72120 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:36,825, word2vec, INFO, EPOCH 1 - PROGRESS: at 85.01% examples, 72157 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:37,931, word2vec, INFO, EPOCH 1 - PROGRESS: at 87.15% examples, 72233 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:39,168, word2vec, INFO, EPOCH 1 - PROGRESS: at 89.59% examples, 72304 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:40,257, word2vec, INFO, EPOCH 1 - PROGRESS: at 91.88% examples, 72567 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:41,391, word2vec, INFO, EPOCH 1 - PROGRESS: at 94.24% examples, 72773 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:42,442, word2vec, INFO, EPOCH 1 - PROGRESS: at 96.64% examples, 73092 words/s, in_qsize 14, out_qsize 0 ]
[2024-12-11 21:21:43,477, word2vec, INFO, EPOCH 1 - PROGRESS: at 98.81% examples, 73238 words/s, in_qsize 5, out_qsize 1 ]
[2024-12-11 21:21:43,941, word2vec, INFO, EPOCH 1: training on 4268692 raw words (3977767 effective words) took 54.1s, 73461 effective words/s ]
[2024-12-11 21:21:45,222, word2vec, INFO, EPOCH 2 - PROGRESS: at 0.87% examples, 29543 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:46,392, word2vec, INFO, EPOCH 2 - PROGRESS: at 2.75% examples, 45653 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:47,456, word2vec, INFO, EPOCH 2 - PROGRESS: at 4.64% examples, 52957 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:48,514, word2vec, INFO, EPOCH 2 - PROGRESS: at 6.46% examples, 56893 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:49,551, word2vec, INFO, EPOCH 2 - PROGRESS: at 8.50% examples, 61331 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 21:21:50,571, word2vec, INFO, EPOCH 2 - PROGRESS: at 10.78% examples, 65919 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:51,668, word2vec, INFO, EPOCH 2 - PROGRESS: at 12.25% examples, 63754 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:52,689, word2vec, INFO, EPOCH 2 - PROGRESS: at 14.71% examples, 66956 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:53,693, word2vec, INFO, EPOCH 2 - PROGRESS: at 16.53% examples, 67669 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:54,915, word2vec, INFO, EPOCH 2 - PROGRESS: at 18.39% examples, 66896 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:21:56,022, word2vec, INFO, EPOCH 2 - PROGRESS: at 20.06% examples, 66139 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:57,074, word2vec, INFO, EPOCH 2 - PROGRESS: at 21.40% examples, 65086 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:58,088, word2vec, INFO, EPOCH 2 - PROGRESS: at 23.51% examples, 66320 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:21:59,144, word2vec, INFO, EPOCH 2 - PROGRESS: at 25.96% examples, 68393 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:22:00,153, word2vec, INFO, EPOCH 2 - PROGRESS: at 27.85% examples, 68698 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:01,160, word2vec, INFO, EPOCH 2 - PROGRESS: at 29.93% examples, 69532 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:22:02,323, word2vec, INFO, EPOCH 2 - PROGRESS: at 32.00% examples, 69652 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:03,444, word2vec, INFO, EPOCH 2 - PROGRESS: at 34.10% examples, 69933 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:04,548, word2vec, INFO, EPOCH 2 - PROGRESS: at 36.40% examples, 70689 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:05,631, word2vec, INFO, EPOCH 2 - PROGRESS: at 38.52% examples, 71010 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:22:06,662, word2vec, INFO, EPOCH 2 - PROGRESS: at 40.50% examples, 71460 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:07,767, word2vec, INFO, EPOCH 2 - PROGRESS: at 42.59% examples, 71654 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:08,861, word2vec, INFO, EPOCH 2 - PROGRESS: at 44.73% examples, 71855 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:09,899, word2vec, INFO, EPOCH 2 - PROGRESS: at 46.94% examples, 72192 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:22:11,011, word2vec, INFO, EPOCH 2 - PROGRESS: at 49.05% examples, 72311 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:12,190, word2vec, INFO, EPOCH 2 - PROGRESS: at 51.39% examples, 72578 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:13,327, word2vec, INFO, EPOCH 2 - PROGRESS: at 53.51% examples, 72608 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:22:14,422, word2vec, INFO, EPOCH 2 - PROGRESS: at 55.78% examples, 73048 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:22:15,560, word2vec, INFO, EPOCH 2 - PROGRESS: at 58.12% examples, 73341 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:16,654, word2vec, INFO, EPOCH 2 - PROGRESS: at 60.25% examples, 73448 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:22:17,687, word2vec, INFO, EPOCH 2 - PROGRESS: at 62.35% examples, 73669 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:18,763, word2vec, INFO, EPOCH 2 - PROGRESS: at 64.30% examples, 73519 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:22:19,784, word2vec, INFO, EPOCH 2 - PROGRESS: at 66.16% examples, 73494 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:20,929, word2vec, INFO, EPOCH 2 - PROGRESS: at 68.44% examples, 73729 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 21:22:21,965, word2vec, INFO, EPOCH 2 - PROGRESS: at 70.69% examples, 74165 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:23,029, word2vec, INFO, EPOCH 2 - PROGRESS: at 72.85% examples, 74286 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:24,098, word2vec, INFO, EPOCH 2 - PROGRESS: at 74.85% examples, 74387 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:25,173, word2vec, INFO, EPOCH 2 - PROGRESS: at 76.90% examples, 74463 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:26,217, word2vec, INFO, EPOCH 2 - PROGRESS: at 79.00% examples, 74603 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:22:27,393, word2vec, INFO, EPOCH 2 - PROGRESS: at 81.24% examples, 74722 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:28,769, word2vec, INFO, EPOCH 2 - PROGRESS: at 83.57% examples, 74498 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:29,984, word2vec, INFO, EPOCH 2 - PROGRESS: at 86.23% examples, 74744 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:31,031, word2vec, INFO, EPOCH 2 - PROGRESS: at 88.39% examples, 74859 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:32,051, word2vec, INFO, EPOCH 2 - PROGRESS: at 90.83% examples, 75189 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:33,214, word2vec, INFO, EPOCH 2 - PROGRESS: at 92.83% examples, 75100 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:22:34,287, word2vec, INFO, EPOCH 2 - PROGRESS: at 94.97% examples, 75164 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:35,312, word2vec, INFO, EPOCH 2 - PROGRESS: at 97.09% examples, 75292 words/s, in_qsize 12, out_qsize 0 ]
[2024-12-11 21:22:36,418, word2vec, INFO, EPOCH 2 - PROGRESS: at 99.77% examples, 75660 words/s, in_qsize 1, out_qsize 1 ]
[2024-12-11 21:22:36,444, word2vec, INFO, EPOCH 2: training on 4268692 raw words (3977695 effective words) took 52.5s, 75790 effective words/s ]
[2024-12-11 21:22:37,488, word2vec, INFO, EPOCH 3 - PROGRESS: at 1.39% examples, 53639 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:38,500, word2vec, INFO, EPOCH 3 - PROGRESS: at 3.66% examples, 72306 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:22:40,090, word2vec, INFO, EPOCH 3 - PROGRESS: at 5.74% examples, 63660 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:41,236, word2vec, INFO, EPOCH 3 - PROGRESS: at 8.26% examples, 69789 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:22:42,264, word2vec, INFO, EPOCH 3 - PROGRESS: at 10.32% examples, 71852 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:43,377, word2vec, INFO, EPOCH 3 - PROGRESS: at 12.25% examples, 71011 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:44,460, word2vec, INFO, EPOCH 3 - PROGRESS: at 14.43% examples, 71839 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:45,516, word2vec, INFO, EPOCH 3 - PROGRESS: at 16.54% examples, 72677 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:46,595, word2vec, INFO, EPOCH 3 - PROGRESS: at 18.62% examples, 73191 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:47,705, word2vec, INFO, EPOCH 3 - PROGRESS: at 20.75% examples, 73383 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:48,722, word2vec, INFO, EPOCH 3 - PROGRESS: at 23.04% examples, 74887 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:49,780, word2vec, INFO, EPOCH 3 - PROGRESS: at 24.87% examples, 74512 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:50,823, word2vec, INFO, EPOCH 3 - PROGRESS: at 26.69% examples, 74206 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:51,832, word2vec, INFO, EPOCH 3 - PROGRESS: at 28.52% examples, 74166 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:52,843, word2vec, INFO, EPOCH 3 - PROGRESS: at 30.59% examples, 74690 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:22:53,868, word2vec, INFO, EPOCH 3 - PROGRESS: at 32.69% examples, 75067 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:54,897, word2vec, INFO, EPOCH 3 - PROGRESS: at 35.02% examples, 75914 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:55,958, word2vec, INFO, EPOCH 3 - PROGRESS: at 37.09% examples, 76065 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:22:57,381, word2vec, INFO, EPOCH 3 - PROGRESS: at 39.18% examples, 74889 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:58,497, word2vec, INFO, EPOCH 3 - PROGRESS: at 41.45% examples, 75304 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:22:59,574, word2vec, INFO, EPOCH 3 - PROGRESS: at 44.02% examples, 76222 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:00,817, word2vec, INFO, EPOCH 3 - PROGRESS: at 46.20% examples, 75736 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:01,826, word2vec, INFO, EPOCH 3 - PROGRESS: at 48.11% examples, 75653 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:02,843, word2vec, INFO, EPOCH 3 - PROGRESS: at 50.48% examples, 76248 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:03,875, word2vec, INFO, EPOCH 3 - PROGRESS: at 52.33% examples, 76084 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:04,887, word2vec, INFO, EPOCH 3 - PROGRESS: at 54.43% examples, 76319 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:05,890, word2vec, INFO, EPOCH 3 - PROGRESS: at 56.52% examples, 76560 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:06,946, word2vec, INFO, EPOCH 3 - PROGRESS: at 58.35% examples, 76331 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:08,139, word2vec, INFO, EPOCH 3 - PROGRESS: at 60.73% examples, 76387 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:09,354, word2vec, INFO, EPOCH 3 - PROGRESS: at 63.08% examples, 76378 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:10,405, word2vec, INFO, EPOCH 3 - PROGRESS: at 64.99% examples, 76194 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:11,449, word2vec, INFO, EPOCH 3 - PROGRESS: at 67.31% examples, 76578 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:12,498, word2vec, INFO, EPOCH 3 - PROGRESS: at 69.11% examples, 76412 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:13,654, word2vec, INFO, EPOCH 3 - PROGRESS: at 71.16% examples, 76285 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:14,666, word2vec, INFO, EPOCH 3 - PROGRESS: at 73.29% examples, 76446 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:15,910, word2vec, INFO, EPOCH 3 - PROGRESS: at 75.30% examples, 76159 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:16,978, word2vec, INFO, EPOCH 3 - PROGRESS: at 77.57% examples, 76431 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:18,018, word2vec, INFO, EPOCH 3 - PROGRESS: at 79.43% examples, 76307 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:19,105, word2vec, INFO, EPOCH 3 - PROGRESS: at 81.49% examples, 76320 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:20,273, word2vec, INFO, EPOCH 3 - PROGRESS: at 83.81% examples, 76406 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:21,374, word2vec, INFO, EPOCH 3 - PROGRESS: at 86.00% examples, 76389 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 21:23:22,385, word2vec, INFO, EPOCH 3 - PROGRESS: at 88.39% examples, 76729 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:23,428, word2vec, INFO, EPOCH 3 - PROGRESS: at 90.34% examples, 76605 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:24,456, word2vec, INFO, EPOCH 3 - PROGRESS: at 92.14% examples, 76489 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:25,468, word2vec, INFO, EPOCH 3 - PROGRESS: at 94.24% examples, 76615 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:26,478, word2vec, INFO, EPOCH 3 - PROGRESS: at 96.20% examples, 76559 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:27,648, word2vec, INFO, EPOCH 3 - PROGRESS: at 98.58% examples, 76624 words/s, in_qsize 6, out_qsize 1 ]
[2024-12-11 21:23:28,059, word2vec, INFO, EPOCH 3: training on 4268692 raw words (3978163 effective words) took 51.6s, 77086 effective words/s ]
[2024-12-11 21:23:29,078, word2vec, INFO, EPOCH 4 - PROGRESS: at 1.38% examples, 55122 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:30,088, word2vec, INFO, EPOCH 4 - PROGRESS: at 3.20% examples, 64174 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:31,179, word2vec, INFO, EPOCH 4 - PROGRESS: at 5.07% examples, 65550 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:32,268, word2vec, INFO, EPOCH 4 - PROGRESS: at 7.10% examples, 68470 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:33,292, word2vec, INFO, EPOCH 4 - PROGRESS: at 9.22% examples, 71062 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:34,383, word2vec, INFO, EPOCH 4 - PROGRESS: at 11.03% examples, 70529 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:35,422, word2vec, INFO, EPOCH 4 - PROGRESS: at 13.19% examples, 71913 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:36,525, word2vec, INFO, EPOCH 4 - PROGRESS: at 15.40% examples, 72433 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:37,607, word2vec, INFO, EPOCH 4 - PROGRESS: at 17.71% examples, 73939 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:39,010, word2vec, INFO, EPOCH 4 - PROGRESS: at 19.82% examples, 72072 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:40,017, word2vec, INFO, EPOCH 4 - PROGRESS: at 21.64% examples, 72244 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:41,033, word2vec, INFO, EPOCH 4 - PROGRESS: at 23.47% examples, 72289 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:42,111, word2vec, INFO, EPOCH 4 - PROGRESS: at 25.57% examples, 72687 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:43,120, word2vec, INFO, EPOCH 4 - PROGRESS: at 27.60% examples, 73318 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:44,124, word2vec, INFO, EPOCH 4 - PROGRESS: at 29.95% examples, 74494 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:45,265, word2vec, INFO, EPOCH 4 - PROGRESS: at 32.05% examples, 74401 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:46,572, word2vec, INFO, EPOCH 4 - PROGRESS: at 34.33% examples, 74155 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:47,604, word2vec, INFO, EPOCH 4 - PROGRESS: at 36.17% examples, 74026 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:48,723, word2vec, INFO, EPOCH 4 - PROGRESS: at 38.51% examples, 74512 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:49,745, word2vec, INFO, EPOCH 4 - PROGRESS: at 40.50% examples, 74852 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:50,762, word2vec, INFO, EPOCH 4 - PROGRESS: at 42.59% examples, 75178 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:51,811, word2vec, INFO, EPOCH 4 - PROGRESS: at 44.73% examples, 75365 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:53,139, word2vec, INFO, EPOCH 4 - PROGRESS: at 47.16% examples, 75060 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:54,164, word2vec, INFO, EPOCH 4 - PROGRESS: at 49.05% examples, 74961 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:55,451, word2vec, INFO, EPOCH 4 - PROGRESS: at 51.16% examples, 74482 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:56,722, word2vec, INFO, EPOCH 4 - PROGRESS: at 53.29% examples, 74091 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:57,800, word2vec, INFO, EPOCH 4 - PROGRESS: at 55.56% examples, 74527 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:23:58,924, word2vec, INFO, EPOCH 4 - PROGRESS: at 57.64% examples, 74515 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:23:59,997, word2vec, INFO, EPOCH 4 - PROGRESS: at 60.03% examples, 74913 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:01,131, word2vec, INFO, EPOCH 4 - PROGRESS: at 62.35% examples, 75148 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:02,211, word2vec, INFO, EPOCH 4 - PROGRESS: at 64.30% examples, 74937 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:24:03,301, word2vec, INFO, EPOCH 4 - PROGRESS: at 66.12% examples, 74727 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:04,309, word2vec, INFO, EPOCH 4 - PROGRESS: at 68.19% examples, 74956 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:05,310, word2vec, INFO, EPOCH 4 - PROGRESS: at 70.02% examples, 74938 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:06,403, word2vec, INFO, EPOCH 4 - PROGRESS: at 72.11% examples, 74977 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:07,463, word2vec, INFO, EPOCH 4 - PROGRESS: at 73.97% examples, 74850 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:08,470, word2vec, INFO, EPOCH 4 - PROGRESS: at 75.75% examples, 74830 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:09,722, word2vec, INFO, EPOCH 4 - PROGRESS: at 78.07% examples, 74795 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:10,726, word2vec, INFO, EPOCH 4 - PROGRESS: at 79.90% examples, 74781 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 21:24:11,746, word2vec, INFO, EPOCH 4 - PROGRESS: at 82.16% examples, 75159 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:12,958, word2vec, INFO, EPOCH 4 - PROGRESS: at 84.29% examples, 74990 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:14,074, word2vec, INFO, EPOCH 4 - PROGRESS: at 86.47% examples, 74984 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:15,359, word2vec, INFO, EPOCH 4 - PROGRESS: at 88.86% examples, 74907 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:24:16,386, word2vec, INFO, EPOCH 4 - PROGRESS: at 91.04% examples, 75035 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:24:17,411, word2vec, INFO, EPOCH 4 - PROGRESS: at 92.83% examples, 74972 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:18,436, word2vec, INFO, EPOCH 4 - PROGRESS: at 94.72% examples, 74922 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:19,493, word2vec, INFO, EPOCH 4 - PROGRESS: at 96.86% examples, 75007 words/s, in_qsize 13, out_qsize 0 ]
[2024-12-11 21:24:20,582, word2vec, INFO, EPOCH 4 - PROGRESS: at 99.03% examples, 75044 words/s, in_qsize 4, out_qsize 1 ]
[2024-12-11 21:24:20,767, word2vec, INFO, EPOCH 4: training on 4268692 raw words (3977347 effective words) took 52.7s, 75478 effective words/s ]
[2024-12-11 21:24:21,833, word2vec, INFO, EPOCH 5 - PROGRESS: at 1.39% examples, 52570 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 21:24:22,836, word2vec, INFO, EPOCH 5 - PROGRESS: at 3.43% examples, 67356 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:23,909, word2vec, INFO, EPOCH 5 - PROGRESS: at 5.52% examples, 70954 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:24:24,919, word2vec, INFO, EPOCH 5 - PROGRESS: at 7.13% examples, 69342 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:25,940, word2vec, INFO, EPOCH 5 - PROGRESS: at 8.75% examples, 68257 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:26,945, word2vec, INFO, EPOCH 5 - PROGRESS: at 10.56% examples, 69158 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:27,945, word2vec, INFO, EPOCH 5 - PROGRESS: at 12.97% examples, 72452 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:24:29,549, word2vec, INFO, EPOCH 5 - PROGRESS: at 15.16% examples, 68717 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:30,764, word2vec, INFO, EPOCH 5 - PROGRESS: at 17.45% examples, 69659 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:31,777, word2vec, INFO, EPOCH 5 - PROGRESS: at 19.37% examples, 69987 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:32,788, word2vec, INFO, EPOCH 5 - PROGRESS: at 21.19% examples, 70285 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:33,805, word2vec, INFO, EPOCH 5 - PROGRESS: at 23.49% examples, 71935 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 21:24:34,844, word2vec, INFO, EPOCH 5 - PROGRESS: at 25.53% examples, 72546 words/s, in_qsize 15, out_qsize 1 ]
[2024-12-11 21:24:35,881, word2vec, INFO, EPOCH 5 - PROGRESS: at 27.37% examples, 72430 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:36,945, word2vec, INFO, EPOCH 5 - PROGRESS: at 29.47% examples, 72825 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:24:37,977, word2vec, INFO, EPOCH 5 - PROGRESS: at 31.32% examples, 72788 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:24:38,988, word2vec, INFO, EPOCH 5 - PROGRESS: at 33.18% examples, 72794 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:24:40,039, word2vec, INFO, EPOCH 5 - PROGRESS: at 34.99% examples, 72684 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:24:41,143, word2vec, INFO, EPOCH 5 - PROGRESS: at 37.09% examples, 72841 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:42,228, word2vec, INFO, EPOCH 5 - PROGRESS: at 39.67% examples, 73914 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:24:43,246, word2vec, INFO, EPOCH 5 - PROGRESS: at 41.42% examples, 73866 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:44,280, word2vec, INFO, EPOCH 5 - PROGRESS: at 43.28% examples, 73788 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:24:45,581, word2vec, INFO, EPOCH 5 - PROGRESS: at 45.45% examples, 73260 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:46,635, word2vec, INFO, EPOCH 5 - PROGRESS: at 47.86% examples, 73859 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:24:47,647, word2vec, INFO, EPOCH 5 - PROGRESS: at 50.00% examples, 74185 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:48,911, word2vec, INFO, EPOCH 5 - PROGRESS: at 52.10% examples, 73819 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:49,985, word2vec, INFO, EPOCH 5 - PROGRESS: at 53.95% examples, 73649 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:51,044, word2vec, INFO, EPOCH 5 - PROGRESS: at 55.82% examples, 73519 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 21:24:52,064, word2vec, INFO, EPOCH 5 - PROGRESS: at 58.35% examples, 74383 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:53,127, word2vec, INFO, EPOCH 5 - PROGRESS: at 60.73% examples, 74805 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:54,394, word2vec, INFO, EPOCH 5 - PROGRESS: at 62.82% examples, 74464 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 21:24:55,412, word2vec, INFO, EPOCH 5 - PROGRESS: at 65.01% examples, 74676 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:56,426, word2vec, INFO, EPOCH 5 - PROGRESS: at 66.84% examples, 74643 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:57,445, word2vec, INFO, EPOCH 5 - PROGRESS: at 68.44% examples, 74341 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:58,503, word2vec, INFO, EPOCH 5 - PROGRESS: at 70.26% examples, 74224 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:24:59,591, word2vec, INFO, EPOCH 5 - PROGRESS: at 72.58% examples, 74541 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:25:00,650, word2vec, INFO, EPOCH 5 - PROGRESS: at 75.08% examples, 75125 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:01,714, word2vec, INFO, EPOCH 5 - PROGRESS: at 77.13% examples, 75204 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:25:02,779, word2vec, INFO, EPOCH 5 - PROGRESS: at 79.00% examples, 75068 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:03,890, word2vec, INFO, EPOCH 5 - PROGRESS: at 80.80% examples, 74857 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:25:04,971, word2vec, INFO, EPOCH 5 - PROGRESS: at 82.67% examples, 74703 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:06,246, word2vec, INFO, EPOCH 5 - PROGRESS: at 84.77% examples, 74442 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:07,302, word2vec, INFO, EPOCH 5 - PROGRESS: at 86.94% examples, 74548 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:08,359, word2vec, INFO, EPOCH 5 - PROGRESS: at 89.09% examples, 74646 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:25:09,386, word2vec, INFO, EPOCH 5 - PROGRESS: at 91.24% examples, 74780 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:10,451, word2vec, INFO, EPOCH 5 - PROGRESS: at 93.59% examples, 75036 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:11,639, word2vec, INFO, EPOCH 5 - PROGRESS: at 95.46% examples, 74748 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 21:25:12,639, word2vec, INFO, EPOCH 5 - PROGRESS: at 97.34% examples, 74738 words/s, in_qsize 11, out_qsize 0 ]
[2024-12-11 21:25:13,493, word2vec, INFO, EPOCH 5: training on 4268692 raw words (3977879 effective words) took 52.7s, 75462 effective words/s ]
[2024-12-11 21:25:14,650, word2vec, INFO, EPOCH 6 - PROGRESS: at 0.90% examples, 32158 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:15,724, word2vec, INFO, EPOCH 6 - PROGRESS: at 3.43% examples, 62448 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:16,758, word2vec, INFO, EPOCH 6 - PROGRESS: at 5.52% examples, 68284 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:17,768, word2vec, INFO, EPOCH 6 - PROGRESS: at 7.30% examples, 69541 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:25:19,092, word2vec, INFO, EPOCH 6 - PROGRESS: at 9.69% examples, 69711 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:25:20,341, word2vec, INFO, EPOCH 6 - PROGRESS: at 12.00% examples, 70544 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:21,421, word2vec, INFO, EPOCH 6 - PROGRESS: at 14.43% examples, 72636 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:22,604, word2vec, INFO, EPOCH 6 - PROGRESS: at 16.54% examples, 72368 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:23,823, word2vec, INFO, EPOCH 6 - PROGRESS: at 18.62% examples, 71928 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:24,832, word2vec, INFO, EPOCH 6 - PROGRESS: at 20.75% examples, 72868 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:25,857, word2vec, INFO, EPOCH 6 - PROGRESS: at 22.80% examples, 73621 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:26,874, word2vec, INFO, EPOCH 6 - PROGRESS: at 24.64% examples, 73544 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:27,955, word2vec, INFO, EPOCH 6 - PROGRESS: at 26.93% examples, 74410 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:29,093, word2vec, INFO, EPOCH 6 - PROGRESS: at 28.99% examples, 74344 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:30,202, word2vec, INFO, EPOCH 6 - PROGRESS: at 31.03% examples, 74401 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:31,243, word2vec, INFO, EPOCH 6 - PROGRESS: at 33.18% examples, 74725 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:25:32,364, word2vec, INFO, EPOCH 6 - PROGRESS: at 35.25% examples, 74719 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:25:33,388, word2vec, INFO, EPOCH 6 - PROGRESS: at 37.32% examples, 75069 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:25:34,395, word2vec, INFO, EPOCH 6 - PROGRESS: at 39.21% examples, 75014 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:35,431, word2vec, INFO, EPOCH 6 - PROGRESS: at 41.18% examples, 75263 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:25:36,516, word2vec, INFO, EPOCH 6 - PROGRESS: at 43.05% examples, 74953 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:25:37,571, word2vec, INFO, EPOCH 6 - PROGRESS: at 44.97% examples, 74744 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:38,632, word2vec, INFO, EPOCH 6 - PROGRESS: at 46.94% examples, 74526 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:39,673, word2vec, INFO, EPOCH 6 - PROGRESS: at 48.81% examples, 74401 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:25:40,688, word2vec, INFO, EPOCH 6 - PROGRESS: at 50.70% examples, 74348 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:41,693, word2vec, INFO, EPOCH 6 - PROGRESS: at 52.56% examples, 74335 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:25:42,759, word2vec, INFO, EPOCH 6 - PROGRESS: at 54.42% examples, 74158 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:43,766, word2vec, INFO, EPOCH 6 - PROGRESS: at 56.26% examples, 74149 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:44,767, word2vec, INFO, EPOCH 6 - PROGRESS: at 58.12% examples, 74140 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:45,853, word2vec, INFO, EPOCH 6 - PROGRESS: at 60.03% examples, 73945 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:46,939, word2vec, INFO, EPOCH 6 - PROGRESS: at 61.88% examples, 73768 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:48,003, word2vec, INFO, EPOCH 6 - PROGRESS: at 63.83% examples, 73636 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:49,034, word2vec, INFO, EPOCH 6 - PROGRESS: at 65.92% examples, 73847 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:50,082, word2vec, INFO, EPOCH 6 - PROGRESS: at 68.00% examples, 74010 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:25:51,106, word2vec, INFO, EPOCH 6 - PROGRESS: at 69.80% examples, 73974 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:52,126, word2vec, INFO, EPOCH 6 - PROGRESS: at 71.62% examples, 73946 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:25:53,174, word2vec, INFO, EPOCH 6 - PROGRESS: at 73.97% examples, 74331 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:54,229, word2vec, INFO, EPOCH 6 - PROGRESS: at 75.75% examples, 74230 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:55,324, word2vec, INFO, EPOCH 6 - PROGRESS: at 77.61% examples, 74060 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:56,338, word2vec, INFO, EPOCH 6 - PROGRESS: at 79.20% examples, 73827 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 21:25:57,389, word2vec, INFO, EPOCH 6 - PROGRESS: at 81.26% examples, 73960 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:58,428, word2vec, INFO, EPOCH 6 - PROGRESS: at 83.10% examples, 73903 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:25:59,563, word2vec, INFO, EPOCH 6 - PROGRESS: at 85.50% examples, 74091 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:00,644, word2vec, INFO, EPOCH 6 - PROGRESS: at 87.64% examples, 74163 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:01,802, word2vec, INFO, EPOCH 6 - PROGRESS: at 89.82% examples, 74112 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:02,860, word2vec, INFO, EPOCH 6 - PROGRESS: at 91.88% examples, 74200 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:04,090, word2vec, INFO, EPOCH 6 - PROGRESS: at 94.03% examples, 74048 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:05,157, word2vec, INFO, EPOCH 6 - PROGRESS: at 95.97% examples, 73958 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:06,220, word2vec, INFO, EPOCH 6 - PROGRESS: at 98.09% examples, 74054 words/s, in_qsize 8, out_qsize 0 ]
[2024-12-11 21:26:06,875, word2vec, INFO, EPOCH 6: training on 4268692 raw words (3977884 effective words) took 53.4s, 74531 effective words/s ]
[2024-12-11 21:26:07,915, word2vec, INFO, EPOCH 7 - PROGRESS: at 1.61% examples, 62987 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 21:26:08,936, word2vec, INFO, EPOCH 7 - PROGRESS: at 3.19% examples, 63105 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 21:26:10,003, word2vec, INFO, EPOCH 7 - PROGRESS: at 5.09% examples, 65313 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:11,018, word2vec, INFO, EPOCH 7 - PROGRESS: at 7.10% examples, 69454 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:12,086, word2vec, INFO, EPOCH 7 - PROGRESS: at 8.97% examples, 69501 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:13,173, word2vec, INFO, EPOCH 7 - PROGRESS: at 11.03% examples, 70773 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:14,395, word2vec, INFO, EPOCH 7 - PROGRESS: at 13.19% examples, 70372 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:15,418, word2vec, INFO, EPOCH 7 - PROGRESS: at 15.39% examples, 71746 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:16,877, word2vec, INFO, EPOCH 7 - PROGRESS: at 17.71% examples, 70545 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:17,912, word2vec, INFO, EPOCH 7 - PROGRESS: at 19.81% examples, 71503 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:18,918, word2vec, INFO, EPOCH 7 - PROGRESS: at 21.64% examples, 71705 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:19,928, word2vec, INFO, EPOCH 7 - PROGRESS: at 23.49% examples, 71833 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:20,994, word2vec, INFO, EPOCH 7 - PROGRESS: at 25.75% examples, 72948 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:22,018, word2vec, INFO, EPOCH 7 - PROGRESS: at 27.61% examples, 72898 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:23,124, word2vec, INFO, EPOCH 7 - PROGRESS: at 29.69% examples, 73078 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:24,243, word2vec, INFO, EPOCH 7 - PROGRESS: at 31.78% examples, 73158 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:25,346, word2vec, INFO, EPOCH 7 - PROGRESS: at 33.63% examples, 72811 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:26,385, word2vec, INFO, EPOCH 7 - PROGRESS: at 35.50% examples, 72742 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:27,443, word2vec, INFO, EPOCH 7 - PROGRESS: at 38.01% examples, 73958 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:28,481, word2vec, INFO, EPOCH 7 - PROGRESS: at 39.89% examples, 73840 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:29,581, word2vec, INFO, EPOCH 7 - PROGRESS: at 41.90% examples, 73946 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:30,602, word2vec, INFO, EPOCH 7 - PROGRESS: at 44.02% examples, 74289 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:31,681, word2vec, INFO, EPOCH 7 - PROGRESS: at 45.97% examples, 74036 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:32,772, word2vec, INFO, EPOCH 7 - PROGRESS: at 47.86% examples, 73782 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:33,891, word2vec, INFO, EPOCH 7 - PROGRESS: at 50.00% examples, 73817 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:35,095, word2vec, INFO, EPOCH 7 - PROGRESS: at 52.33% examples, 73953 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:36,150, word2vec, INFO, EPOCH 7 - PROGRESS: at 54.43% examples, 74141 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:37,211, word2vec, INFO, EPOCH 7 - PROGRESS: at 56.52% examples, 74301 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:38,304, word2vec, INFO, EPOCH 7 - PROGRESS: at 58.60% examples, 74368 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:39,560, word2vec, INFO, EPOCH 7 - PROGRESS: at 60.73% examples, 74067 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:40,732, word2vec, INFO, EPOCH 7 - PROGRESS: at 62.82% examples, 73963 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:41,800, word2vec, INFO, EPOCH 7 - PROGRESS: at 65.23% examples, 74350 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:42,912, word2vec, INFO, EPOCH 7 - PROGRESS: at 67.31% examples, 74378 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:43,916, word2vec, INFO, EPOCH 7 - PROGRESS: at 69.11% examples, 74368 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:45,266, word2vec, INFO, EPOCH 7 - PROGRESS: at 71.16% examples, 73933 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:46,287, word2vec, INFO, EPOCH 7 - PROGRESS: at 73.07% examples, 73900 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:47,289, word2vec, INFO, EPOCH 7 - PROGRESS: at 74.89% examples, 73906 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:48,366, word2vec, INFO, EPOCH 7 - PROGRESS: at 76.90% examples, 73993 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:49,493, word2vec, INFO, EPOCH 7 - PROGRESS: at 78.99% examples, 74000 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:50,504, word2vec, INFO, EPOCH 7 - PROGRESS: at 81.03% examples, 74201 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:51,528, word2vec, INFO, EPOCH 7 - PROGRESS: at 82.90% examples, 74161 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:52,654, word2vec, INFO, EPOCH 7 - PROGRESS: at 85.01% examples, 74163 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:26:53,738, word2vec, INFO, EPOCH 7 - PROGRESS: at 86.92% examples, 74029 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:54,812, word2vec, INFO, EPOCH 7 - PROGRESS: at 88.84% examples, 73918 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:55,850, word2vec, INFO, EPOCH 7 - PROGRESS: at 91.03% examples, 74046 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:57,113, word2vec, INFO, EPOCH 7 - PROGRESS: at 93.59% examples, 74208 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:26:58,159, word2vec, INFO, EPOCH 7 - PROGRESS: at 95.47% examples, 74149 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-11 21:26:59,204, word2vec, INFO, EPOCH 7 - PROGRESS: at 97.61% examples, 74267 words/s, in_qsize 10, out_qsize 0 ]
[2024-12-11 21:27:00,055, word2vec, INFO, EPOCH 7: training on 4268692 raw words (3978166 effective words) took 53.2s, 74819 effective words/s ]
[2024-12-11 21:27:01,088, word2vec, INFO, EPOCH 8 - PROGRESS: at 1.16% examples, 45209 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:02,161, word2vec, INFO, EPOCH 8 - PROGRESS: at 3.20% examples, 61682 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:03,172, word2vec, INFO, EPOCH 8 - PROGRESS: at 5.07% examples, 65527 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:04,275, word2vec, INFO, EPOCH 8 - PROGRESS: at 7.10% examples, 68196 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:05,464, word2vec, INFO, EPOCH 8 - PROGRESS: at 9.22% examples, 68683 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:06,491, word2vec, INFO, EPOCH 8 - PROGRESS: at 11.03% examples, 69279 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:07,548, word2vec, INFO, EPOCH 8 - PROGRESS: at 12.97% examples, 69408 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:08,616, word2vec, INFO, EPOCH 8 - PROGRESS: at 14.95% examples, 69433 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:09,746, word2vec, INFO, EPOCH 8 - PROGRESS: at 17.48% examples, 71874 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:10,855, word2vec, INFO, EPOCH 8 - PROGRESS: at 19.33% examples, 71341 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:11,977, word2vec, INFO, EPOCH 8 - PROGRESS: at 21.19% examples, 70859 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:13,030, word2vec, INFO, EPOCH 8 - PROGRESS: at 23.04% examples, 70841 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:14,131, word2vec, INFO, EPOCH 8 - PROGRESS: at 25.13% examples, 71233 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:15,162, word2vec, INFO, EPOCH 8 - PROGRESS: at 26.93% examples, 71226 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:16,163, word2vec, INFO, EPOCH 8 - PROGRESS: at 29.23% examples, 72561 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:17,331, word2vec, INFO, EPOCH 8 - PROGRESS: at 31.32% examples, 72501 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:18,370, word2vec, INFO, EPOCH 8 - PROGRESS: at 33.18% examples, 72419 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:19,477, word2vec, INFO, EPOCH 8 - PROGRESS: at 35.00% examples, 72122 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:20,578, word2vec, INFO, EPOCH 8 - PROGRESS: at 36.86% examples, 71859 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:21,664, word2vec, INFO, EPOCH 8 - PROGRESS: at 38.75% examples, 71684 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:22,674, word2vec, INFO, EPOCH 8 - PROGRESS: at 40.94% examples, 72575 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:23,680, word2vec, INFO, EPOCH 8 - PROGRESS: at 43.05% examples, 73038 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:24,850, word2vec, INFO, EPOCH 8 - PROGRESS: at 45.19% examples, 72947 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:25,911, word2vec, INFO, EPOCH 8 - PROGRESS: at 47.18% examples, 72813 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:27,045, word2vec, INFO, EPOCH 8 - PROGRESS: at 49.27% examples, 72852 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 21:27:28,073, word2vec, INFO, EPOCH 8 - PROGRESS: at 51.40% examples, 73154 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:29,076, word2vec, INFO, EPOCH 8 - PROGRESS: at 53.27% examples, 73184 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:30,077, word2vec, INFO, EPOCH 8 - PROGRESS: at 54.91% examples, 72901 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:31,113, word2vec, INFO, EPOCH 8 - PROGRESS: at 57.38% examples, 73759 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:32,129, word2vec, INFO, EPOCH 8 - PROGRESS: at 59.30% examples, 73727 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:33,143, word2vec, INFO, EPOCH 8 - PROGRESS: at 60.98% examples, 73430 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:34,189, word2vec, INFO, EPOCH 8 - PROGRESS: at 63.06% examples, 73627 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:35,253, word2vec, INFO, EPOCH 8 - PROGRESS: at 65.47% examples, 74030 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:36,361, word2vec, INFO, EPOCH 8 - PROGRESS: at 67.31% examples, 73819 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:37,545, word2vec, INFO, EPOCH 8 - PROGRESS: at 69.35% examples, 73719 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:38,610, word2vec, INFO, EPOCH 8 - PROGRESS: at 71.16% examples, 73614 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:39,634, word2vec, INFO, EPOCH 8 - PROGRESS: at 73.07% examples, 73584 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:40,720, word2vec, INFO, EPOCH 8 - PROGRESS: at 75.07% examples, 73674 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:41,911, word2vec, INFO, EPOCH 8 - PROGRESS: at 77.39% examples, 73787 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:42,926, word2vec, INFO, EPOCH 8 - PROGRESS: at 79.44% examples, 73993 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:43,926, word2vec, INFO, EPOCH 8 - PROGRESS: at 81.49% examples, 74209 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:44,981, word2vec, INFO, EPOCH 8 - PROGRESS: at 83.36% examples, 74120 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:46,503, word2vec, INFO, EPOCH 8 - PROGRESS: at 85.50% examples, 73486 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:47,524, word2vec, INFO, EPOCH 8 - PROGRESS: at 87.64% examples, 73664 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:48,539, word2vec, INFO, EPOCH 8 - PROGRESS: at 89.87% examples, 73846 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:49,710, word2vec, INFO, EPOCH 8 - PROGRESS: at 92.14% examples, 73956 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:50,747, word2vec, INFO, EPOCH 8 - PROGRESS: at 94.05% examples, 73909 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:51,775, word2vec, INFO, EPOCH 8 - PROGRESS: at 95.95% examples, 73881 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:52,788, word2vec, INFO, EPOCH 8 - PROGRESS: at 97.83% examples, 73872 words/s, in_qsize 9, out_qsize 0 ]
[2024-12-11 21:27:53,483, word2vec, INFO, EPOCH 8: training on 4268692 raw words (3978021 effective words) took 53.4s, 74468 effective words/s ]
[2024-12-11 21:27:54,511, word2vec, INFO, EPOCH 9 - PROGRESS: at 0.48% examples, 18584 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-11 21:27:55,514, word2vec, INFO, EPOCH 9 - PROGRESS: at 2.96% examples, 59966 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:56,517, word2vec, INFO, EPOCH 9 - PROGRESS: at 4.85% examples, 64664 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:27:57,645, word2vec, INFO, EPOCH 9 - PROGRESS: at 6.70% examples, 64946 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:58,806, word2vec, INFO, EPOCH 9 - PROGRESS: at 8.75% examples, 66562 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:27:59,844, word2vec, INFO, EPOCH 9 - PROGRESS: at 10.56% examples, 67368 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:28:00,912, word2vec, INFO, EPOCH 9 - PROGRESS: at 12.47% examples, 67676 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:02,009, word2vec, INFO, EPOCH 9 - PROGRESS: at 14.71% examples, 68785 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:03,072, word2vec, INFO, EPOCH 9 - PROGRESS: at 16.78% examples, 69861 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:28:04,080, word2vec, INFO, EPOCH 9 - PROGRESS: at 18.86% examples, 71095 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:05,095, word2vec, INFO, EPOCH 9 - PROGRESS: at 20.97% examples, 72082 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:06,203, word2vec, INFO, EPOCH 9 - PROGRESS: at 23.04% examples, 72382 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:07,333, word2vec, INFO, EPOCH 9 - PROGRESS: at 25.13% examples, 72497 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:28:08,516, word2vec, INFO, EPOCH 9 - PROGRESS: at 26.93% examples, 71672 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:09,640, word2vec, INFO, EPOCH 9 - PROGRESS: at 28.76% examples, 71285 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:28:10,682, word2vec, INFO, EPOCH 9 - PROGRESS: at 31.03% examples, 72363 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:11,740, word2vec, INFO, EPOCH 9 - PROGRESS: at 33.18% examples, 72725 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:28:13,017, word2vec, INFO, EPOCH 9 - PROGRESS: at 35.25% examples, 72255 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:14,074, word2vec, INFO, EPOCH 9 - PROGRESS: at 37.09% examples, 72146 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:28:15,144, word2vec, INFO, EPOCH 9 - PROGRESS: at 38.98% examples, 72015 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:16,187, word2vec, INFO, EPOCH 9 - PROGRESS: at 40.96% examples, 72378 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:28:17,191, word2vec, INFO, EPOCH 9 - PROGRESS: at 43.06% examples, 72843 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:18,206, word2vec, INFO, EPOCH 9 - PROGRESS: at 45.21% examples, 73230 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:19,317, word2vec, INFO, EPOCH 9 - PROGRESS: at 47.40% examples, 73294 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:20,389, word2vec, INFO, EPOCH 9 - PROGRESS: at 49.30% examples, 73136 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:21,484, word2vec, INFO, EPOCH 9 - PROGRESS: at 51.16% examples, 72923 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:22,588, word2vec, INFO, EPOCH 9 - PROGRESS: at 53.27% examples, 73032 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:28:23,678, word2vec, INFO, EPOCH 9 - PROGRESS: at 55.11% examples, 72847 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:24,760, word2vec, INFO, EPOCH 9 - PROGRESS: at 57.38% examples, 73295 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:25,787, word2vec, INFO, EPOCH 9 - PROGRESS: at 59.55% examples, 73541 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:26,901, word2vec, INFO, EPOCH 9 - PROGRESS: at 61.66% examples, 73589 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:27,926, word2vec, INFO, EPOCH 9 - PROGRESS: at 63.60% examples, 73548 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:28:29,029, word2vec, INFO, EPOCH 9 - PROGRESS: at 65.23% examples, 73088 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:30,089, word2vec, INFO, EPOCH 9 - PROGRESS: at 67.09% examples, 73007 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:28:31,118, word2vec, INFO, EPOCH 9 - PROGRESS: at 69.13% examples, 73232 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:32,225, word2vec, INFO, EPOCH 9 - PROGRESS: at 71.16% examples, 73301 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:33,246, word2vec, INFO, EPOCH 9 - PROGRESS: at 73.31% examples, 73519 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-11 21:28:34,358, word2vec, INFO, EPOCH 9 - PROGRESS: at 75.30% examples, 73565 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:35,401, word2vec, INFO, EPOCH 9 - PROGRESS: at 77.13% examples, 73497 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:36,505, word2vec, INFO, EPOCH 9 - PROGRESS: at 79.00% examples, 73340 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:37,627, word2vec, INFO, EPOCH 9 - PROGRESS: at 80.80% examples, 73163 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:38,658, word2vec, INFO, EPOCH 9 - PROGRESS: at 83.13% examples, 73544 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:39,735, word2vec, INFO, EPOCH 9 - PROGRESS: at 85.01% examples, 73435 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:40,785, word2vec, INFO, EPOCH 9 - PROGRESS: at 86.95% examples, 73374 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:41,825, word2vec, INFO, EPOCH 9 - PROGRESS: at 89.12% examples, 73523 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:42,861, word2vec, INFO, EPOCH 9 - PROGRESS: at 91.25% examples, 73663 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:43,891, word2vec, INFO, EPOCH 9 - PROGRESS: at 93.34% examples, 73806 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:44,891, word2vec, INFO, EPOCH 9 - PROGRESS: at 94.94% examples, 73639 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-11 21:28:45,936, word2vec, INFO, EPOCH 9 - PROGRESS: at 97.09% examples, 73764 words/s, in_qsize 12, out_qsize 0 ]
[2024-12-11 21:28:46,948, word2vec, INFO, EPOCH 9 - PROGRESS: at 99.27% examples, 73935 words/s, in_qsize 3, out_qsize 1 ]
[2024-12-11 21:28:47,204, word2vec, INFO, EPOCH 9: training on 4268692 raw words (3978260 effective words) took 53.7s, 74092 effective words/s ]
[2024-12-11 21:28:47,205, utils, INFO, FastText lifecycle event {'msg': 'training on 42686920 raw words (39779722 effective words) took 526.8s, 75513 effective words/s', 'datetime': '2024-12-11T21:28:47.205950', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'} ]
[2024-12-11 21:28:56,352, utils, INFO, FastText lifecycle event {'params': 'FastText<vocab=160129, vector_size=500, alpha=0.025>', 'datetime': '2024-12-11T21:28:56.352297', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'} ]
[2024-12-11 21:28:57,137, utils, INFO, FastText lifecycle event {'fname_or_handle': 'fasttext_reviews.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-12-11T21:28:57.137405', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'saving'} ]
[2024-12-11 21:28:57,141, utils, INFO, not storing attribute vectors ]
[2024-12-11 21:28:57,142, utils, INFO, storing np array 'vectors_vocab' to fasttext_reviews.model.wv.vectors_vocab.npy ]
[2024-12-11 21:28:59,174, utils, INFO, storing np array 'vectors_ngrams' to fasttext_reviews.model.wv.vectors_ngrams.npy ]
[2024-12-11 21:29:25,343, utils, INFO, not storing attribute buckets_word ]
[2024-12-11 21:29:25,350, utils, INFO, storing np array 'syn1neg' to fasttext_reviews.model.syn1neg.npy ]
[2024-12-11 21:29:27,389, utils, INFO, not storing attribute cum_table ]
[2024-12-11 21:29:27,562, utils, INFO, saved fasttext_reviews.model ]
[2024-12-11 21:29:35,454, utils, INFO, loading FastText object from fasttext_reviews.model ]
[2024-12-11 21:29:35,848, utils, INFO, loading wv recursively from fasttext_reviews.model.wv.* with mmap=None ]
[2024-12-11 21:29:35,849, utils, INFO, loading vectors_vocab from fasttext_reviews.model.wv.vectors_vocab.npy with mmap=None ]
[2024-12-11 21:29:36,006, utils, INFO, loading vectors_ngrams from fasttext_reviews.model.wv.vectors_ngrams.npy with mmap=None ]
[2024-12-11 21:29:46,632, utils, INFO, setting ignored attribute vectors to None ]
[2024-12-11 21:29:46,635, utils, INFO, setting ignored attribute buckets_word to None ]
[2024-12-11 21:29:58,177, utils, INFO, loading syn1neg from fasttext_reviews.model.syn1neg.npy with mmap=None ]
[2024-12-11 21:29:59,054, utils, INFO, setting ignored attribute cum_table to None ]
[2024-12-11 21:30:00,686, utils, INFO, FastText lifecycle event {'fname': 'fasttext_reviews.model', 'datetime': '2024-12-11T21:30:00.686556', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'loaded'} ]
[2024-12-11 22:14:35,804, utils, INFO, FastTextKeyedVectors lifecycle event {'fname_or_handle': 'fasttext_keyedvectors.kv', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-12-11T22:14:35.804502', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'saving'} ]
[2024-12-11 22:14:35,806, utils, INFO, storing np array 'vectors_vocab' to fasttext_keyedvectors.kv.vectors_vocab.npy ]
[2024-12-11 22:14:36,716, utils, INFO, storing np array 'vectors_ngrams' to fasttext_keyedvectors.kv.vectors_ngrams.npy ]
[2024-12-11 22:15:01,057, utils, INFO, not storing attribute vectors ]
[2024-12-11 22:15:01,060, utils, INFO, not storing attribute buckets_word ]
[2024-12-11 22:15:01,148, utils, INFO, saved fasttext_keyedvectors.kv ]
[2024-12-11 22:17:59,739, utils, INFO, loading KeyedVectors object from fasttext_keyedvectors.kv ]
[2024-12-11 22:17:59,910, utils, INFO, loading vectors_vocab from fasttext_keyedvectors.kv.vectors_vocab.npy with mmap=None ]
[2024-12-11 22:18:00,066, utils, INFO, loading vectors_ngrams from fasttext_keyedvectors.kv.vectors_ngrams.npy with mmap=None ]
[2024-12-11 22:18:11,561, utils, INFO, setting ignored attribute vectors to None ]
[2024-12-11 22:18:11,563, utils, INFO, setting ignored attribute buckets_word to None ]
[2024-12-11 22:18:23,548, utils, INFO, FastTextKeyedVectors lifecycle event {'fname': 'fasttext_keyedvectors.kv', 'datetime': '2024-12-11T22:18:23.548832', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'loaded'} ]
[2024-12-11 22:20:07,560, utils, INFO, FastTextKeyedVectors lifecycle event {'fname_or_handle': 'fasttext_keyedvectors.kv', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-12-11T22:20:07.560566', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'saving'} ]
[2024-12-11 22:20:07,563, utils, INFO, storing np array 'vectors_vocab' to fasttext_keyedvectors.kv.vectors_vocab.npy ]
[2024-12-11 22:20:10,573, utils, INFO, storing np array 'vectors_ngrams' to fasttext_keyedvectors.kv.vectors_ngrams.npy ]
[2024-12-11 22:21:02,012, utils, INFO, not storing attribute vectors ]
[2024-12-11 22:21:02,014, utils, INFO, not storing attribute buckets_word ]
[2024-12-11 22:21:02,151, utils, INFO, saved fasttext_keyedvectors.kv ]
[2024-12-11 22:21:37,984, utils, INFO, loading KeyedVectors object from fasttext_keyedvectors.kv ]
[2024-12-11 22:21:48,379, utils, INFO, loading vectors_vocab from fasttext_keyedvectors.kv.vectors_vocab.npy with mmap=None ]
[2024-12-11 22:22:37,194, utils, INFO, loading KeyedVectors object from fasttext_keyedvectors_binary.kv ]
[2024-12-11 22:22:56,926, utils, INFO, loading KeyedVectors object from fasttext_keyedvectors_binary.kv ]
[2024-12-11 22:23:08,371, utils, INFO, loading KeyedVectors object from fasttext_keyedvectors.kv ]
[2024-12-11 22:23:25,055, utils, INFO, loading vectors_vocab from fasttext_keyedvectors.kv.vectors_vocab.npy with mmap=None ]
[2024-12-12 18:38:22,851, keyedvectors, INFO, loading projection weights from skipgram_model.bin ]
[2024-12-12 19:04:57,161, keyedvectors, WARNING, attribute count not present in KeyedVectors<vector_size=300, 30489 keys>; will store in internal index_to_key order ]
[2024-12-12 19:04:57,162, keyedvectors, INFO, storing 30489x300 projection weights into gensim_skipgram_model.bin ]
[2024-12-12 19:04:57,456, utils, INFO, KeyedVectors lifecycle event {'fname_or_handle': 'quantized_model.kv', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-12-12T19:04:57.456015', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'saving'} ]
[2024-12-12 19:04:57,540, utils, INFO, saved quantized_model.kv ]
[2024-12-12 19:22:37,898, utils, INFO, loading KeyedVectors object from quantized_model.kv ]
[2024-12-12 19:22:37,944, utils, INFO, KeyedVectors lifecycle event {'fname': 'quantized_model.kv', 'datetime': '2024-12-12T19:22:37.944668', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'loaded'} ]
[2024-12-12 19:23:23,894, utils, INFO, loading KeyedVectors object from quantized_model.kv ]
[2024-12-12 19:23:23,934, utils, INFO, KeyedVectors lifecycle event {'fname': 'quantized_model.kv', 'datetime': '2024-12-12T19:23:23.934388', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'loaded'} ]
[2024-12-12 19:53:11,651, keyedvectors, INFO, loading projection weights from skipgram_model.bin ]
[2024-12-12 19:54:30,364, keyedvectors, INFO, loading projection weights from skipgram_model.bin ]
[2024-12-12 19:55:33,018, keyedvectors, INFO, loading projection weights from skipgram_model.bin ]
[2024-12-12 19:57:56,722, keyedvectors, INFO, loading projection weights from skipgram_model.bin ]
[2024-12-12 19:58:08,253, keyedvectors, INFO, loading projection weights from skipgram_model.bin ]
[2024-12-12 20:47:56,823, keyedvectors, WARNING, attribute count not present in KeyedVectors<vector_size=300, 115342 keys>; will store in internal index_to_key order ]
[2024-12-12 20:47:56,826, keyedvectors, INFO, storing 115342x300 projection weights into gensim_my_fasttext_model.bin ]
[2024-12-12 20:47:57,997, keyedvectors, WARNING, destructive init_sims(replace=True) deprecated & no longer required for space-efficiency ]
[2024-12-12 20:47:58,021, utils, INFO, KeyedVectors lifecycle event {'fname_or_handle': 'quantized_model.kv', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-12-12T20:47:58.021785', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'saving'} ]
[2024-12-12 20:47:58,026, utils, INFO, storing np array 'vectors' to quantized_model.kv.vectors.npy ]
[2024-12-12 20:47:58,419, utils, INFO, saved quantized_model.kv ]
[2024-12-12 20:49:58,661, utils, INFO, loading KeyedVectors object from quantized_model.kv ]
[2024-12-12 20:49:59,028, utils, INFO, loading vectors from quantized_model.kv.vectors.npy with mmap=r ]
[2024-12-12 20:49:59,055, utils, INFO, KeyedVectors lifecycle event {'fname': 'quantized_model.kv', 'datetime': '2024-12-12T20:49:59.055133', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'loaded'} ]
[2024-12-13 06:26:58,826, utils, INFO, loading KeyedVectors object from quantized_model.kv ]
[2024-12-13 06:26:58,881, utils, INFO, loading vectors from quantized_model.kv.vectors.npy with mmap=r ]
[2024-12-13 06:26:58,892, utils, INFO, KeyedVectors lifecycle event {'fname': 'quantized_model.kv', 'datetime': '2024-12-13T06:26:58.892142', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'loaded'} ]
[2024-12-13 06:30:00,441, utils, INFO, loading KeyedVectors object from quantized_model.kv ]
[2024-12-13 06:30:00,491, utils, INFO, loading vectors from quantized_model.kv.vectors.npy with mmap=None ]
[2024-12-13 06:30:00,537, utils, INFO, KeyedVectors lifecycle event {'fname': 'quantized_model.kv', 'datetime': '2024-12-13T06:30:00.537891', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'loaded'} ]
[2024-12-13 06:54:37,875, keyedvectors, INFO, loading projection weights from gensim_my_fasttext_model.bin ]
[2024-12-13 06:54:39,344, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (115342, 300) matrix of type float32 from gensim_my_fasttext_model.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T06:54:39.344131', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 07:03:55,951, word2vec, INFO, collecting all words and their counts ]
[2024-12-13 07:03:55,953, word2vec, INFO, PROGRESS: at sentence #0, processed 0 words, keeping 0 word types ]
[2024-12-13 07:03:56,093, word2vec, INFO, PROGRESS: at sentence #10000, processed 417356 words, keeping 38269 word types ]
[2024-12-13 07:03:56,277, word2vec, INFO, PROGRESS: at sentence #20000, processed 827291 words, keeping 57463 word types ]
[2024-12-13 07:03:56,435, word2vec, INFO, PROGRESS: at sentence #30000, processed 1245251 words, keeping 73816 word types ]
[2024-12-13 07:03:56,610, word2vec, INFO, PROGRESS: at sentence #40000, processed 1659818 words, keeping 88317 word types ]
[2024-12-13 07:03:56,845, word2vec, INFO, PROGRESS: at sentence #50000, processed 2073395 words, keeping 101105 word types ]
[2024-12-13 07:03:57,065, word2vec, INFO, PROGRESS: at sentence #60000, processed 2485740 words, keeping 113234 word types ]
[2024-12-13 07:03:57,233, word2vec, INFO, PROGRESS: at sentence #70000, processed 2895180 words, keeping 124533 word types ]
[2024-12-13 07:03:57,435, word2vec, INFO, PROGRESS: at sentence #80000, processed 3316945 words, keeping 135881 word types ]
[2024-12-13 07:03:57,612, word2vec, INFO, PROGRESS: at sentence #90000, processed 3730627 words, keeping 146822 word types ]
[2024-12-13 07:03:57,796, word2vec, INFO, PROGRESS: at sentence #100000, processed 4136518 words, keeping 156920 word types ]
[2024-12-13 07:03:57,860, word2vec, INFO, collected 160129 word types from a corpus of 4268692 raw words and 103304 sentences ]
[2024-12-13 07:03:57,862, word2vec, INFO, Creating a fresh vocabulary ]
[2024-12-13 07:03:58,748, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 retains 160129 unique words (100.00% of original 160129, drops 0)', 'datetime': '2024-12-13T07:03:58.748080', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-13 07:03:58,749, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 leaves 4268692 word corpus (100.00% of original 4268692, drops 0)', 'datetime': '2024-12-13T07:03:58.749114', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-13 07:04:00,531, word2vec, INFO, deleting the raw counts dictionary of 160129 items ]
[2024-12-13 07:04:00,538, word2vec, INFO, sample=0.001 downsamples 31 most-common words ]
[2024-12-13 07:04:00,540, utils, INFO, FastText lifecycle event {'msg': 'downsampling leaves estimated 3978110.9017322585 word corpus (93.2%% of prior 4268692)', 'datetime': '2024-12-13T07:04:00.540454', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-13 07:04:06,133, fasttext, INFO, estimated required memory for 160129 words, 2000000 buckets and 300 dimensions: 2899895040 bytes ]
[2024-12-13 07:04:06,134, word2vec, INFO, resetting layer weights ]
[2024-12-13 07:04:23,536, utils, INFO, FastText lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-12-13T07:04:23.536569', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'} ]
[2024-12-13 07:04:23,538, utils, INFO, FastText lifecycle event {'msg': 'training model with 8 workers on 160129 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-12-13T07:04:23.538522', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'} ]
[2024-12-13 07:04:24,562, word2vec, INFO, EPOCH 0 - PROGRESS: at 3.20% examples, 128248 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:25,578, word2vec, INFO, EPOCH 0 - PROGRESS: at 6.46% examples, 127985 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:26,588, word2vec, INFO, EPOCH 0 - PROGRESS: at 10.60% examples, 140501 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:27,757, word2vec, INFO, EPOCH 0 - PROGRESS: at 15.16% examples, 143435 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:04:28,789, word2vec, INFO, EPOCH 0 - PROGRESS: at 19.12% examples, 145265 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:29,842, word2vec, INFO, EPOCH 0 - PROGRESS: at 23.71% examples, 150465 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:04:30,920, word2vec, INFO, EPOCH 0 - PROGRESS: at 27.85% examples, 151044 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:32,016, word2vec, INFO, EPOCH 0 - PROGRESS: at 32.00% examples, 151167 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:33,029, word2vec, INFO, EPOCH 0 - PROGRESS: at 36.61% examples, 154577 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:34,165, word2vec, INFO, EPOCH 0 - PROGRESS: at 40.97% examples, 154631 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:35,240, word2vec, INFO, EPOCH 0 - PROGRESS: at 45.44% examples, 155499 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:36,258, word2vec, INFO, EPOCH 0 - PROGRESS: at 50.00% examples, 156897 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:37,297, word2vec, INFO, EPOCH 0 - PROGRESS: at 54.18% examples, 157177 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:04:38,319, word2vec, INFO, EPOCH 0 - PROGRESS: at 57.63% examples, 155710 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:39,337, word2vec, INFO, EPOCH 0 - PROGRESS: at 61.88% examples, 156250 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:40,380, word2vec, INFO, EPOCH 0 - PROGRESS: at 66.38% examples, 157024 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:04:41,487, word2vec, INFO, EPOCH 0 - PROGRESS: at 70.69% examples, 157163 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:42,488, word2vec, INFO, EPOCH 0 - PROGRESS: at 74.67% examples, 157187 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:04:43,560, word2vec, INFO, EPOCH 0 - PROGRESS: at 79.43% examples, 158504 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:44,620, word2vec, INFO, EPOCH 0 - PROGRESS: at 83.36% examples, 158023 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 07:04:45,694, word2vec, INFO, EPOCH 0 - PROGRESS: at 87.88% examples, 158314 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:46,743, word2vec, INFO, EPOCH 0 - PROGRESS: at 92.14% examples, 158310 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:47,793, word2vec, INFO, EPOCH 0 - PROGRESS: at 95.47% examples, 156828 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:48,798, word2vec, INFO, EPOCH 0 - PROGRESS: at 99.03% examples, 156105 words/s, in_qsize 4, out_qsize 1 ]
[2024-12-13 07:04:48,962, word2vec, INFO, EPOCH 0: training on 4268692 raw words (3977480 effective words) took 25.4s, 156542 effective words/s ]
[2024-12-13 07:04:49,993, word2vec, INFO, EPOCH 1 - PROGRESS: at 2.52% examples, 100279 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:51,007, word2vec, INFO, EPOCH 1 - PROGRESS: at 6.66% examples, 132439 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 07:04:52,184, word2vec, INFO, EPOCH 1 - PROGRESS: at 11.30% examples, 141739 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:04:53,217, word2vec, INFO, EPOCH 1 - PROGRESS: at 15.86% examples, 148807 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:04:54,242, word2vec, INFO, EPOCH 1 - PROGRESS: at 19.58% examples, 147988 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:04:55,277, word2vec, INFO, EPOCH 1 - PROGRESS: at 24.17% examples, 153208 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:56,463, word2vec, INFO, EPOCH 1 - PROGRESS: at 28.31% examples, 151114 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:04:57,519, word2vec, INFO, EPOCH 1 - PROGRESS: at 32.48% examples, 151956 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:58,526, word2vec, INFO, EPOCH 1 - PROGRESS: at 36.40% examples, 152451 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:04:59,603, word2vec, INFO, EPOCH 1 - PROGRESS: at 40.74% examples, 153593 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:05:00,812, word2vec, INFO, EPOCH 1 - PROGRESS: at 44.97% examples, 152031 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:01,821, word2vec, INFO, EPOCH 1 - PROGRESS: at 48.81% examples, 151607 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:02,861, word2vec, INFO, EPOCH 1 - PROGRESS: at 53.51% examples, 153617 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:03,897, word2vec, INFO, EPOCH 1 - PROGRESS: at 57.16% examples, 152912 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:04,936, word2vec, INFO, EPOCH 1 - PROGRESS: at 60.03% examples, 149907 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:05,940, word2vec, INFO, EPOCH 1 - PROGRESS: at 63.83% examples, 149774 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:07,027, word2vec, INFO, EPOCH 1 - PROGRESS: at 67.52% examples, 148981 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:08,119, word2vec, INFO, EPOCH 1 - PROGRESS: at 71.16% examples, 148243 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:05:09,242, word2vec, INFO, EPOCH 1 - PROGRESS: at 74.43% examples, 146443 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-13 07:05:10,319, word2vec, INFO, EPOCH 1 - PROGRESS: at 78.07% examples, 146001 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:11,373, word2vec, INFO, EPOCH 1 - PROGRESS: at 80.80% examples, 144125 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:12,514, word2vec, INFO, EPOCH 1 - PROGRESS: at 84.78% examples, 143827 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:13,582, word2vec, INFO, EPOCH 1 - PROGRESS: at 88.62% examples, 143621 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:14,683, word2vec, INFO, EPOCH 1 - PROGRESS: at 92.14% examples, 142856 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:05:15,692, word2vec, INFO, EPOCH 1 - PROGRESS: at 94.94% examples, 141641 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:05:16,768, word2vec, INFO, EPOCH 1 - PROGRESS: at 98.81% examples, 141510 words/s, in_qsize 5, out_qsize 1 ]
[2024-12-13 07:05:17,069, word2vec, INFO, EPOCH 1: training on 4268692 raw words (3978483 effective words) took 28.1s, 141634 effective words/s ]
[2024-12-13 07:05:18,213, word2vec, INFO, EPOCH 2 - PROGRESS: at 2.07% examples, 75267 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:19,352, word2vec, INFO, EPOCH 2 - PROGRESS: at 5.77% examples, 102978 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 07:05:20,363, word2vec, INFO, EPOCH 2 - PROGRESS: at 8.96% examples, 110956 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:21,392, word2vec, INFO, EPOCH 2 - PROGRESS: at 11.77% examples, 110319 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 07:05:22,464, word2vec, INFO, EPOCH 2 - PROGRESS: at 15.16% examples, 112463 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:23,548, word2vec, INFO, EPOCH 2 - PROGRESS: at 19.12% examples, 118036 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:05:24,566, word2vec, INFO, EPOCH 2 - PROGRESS: at 23.49% examples, 125574 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:05:25,582, word2vec, INFO, EPOCH 2 - PROGRESS: at 27.35% examples, 129018 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:26,598, word2vec, INFO, EPOCH 2 - PROGRESS: at 32.00% examples, 134718 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:27,642, word2vec, INFO, EPOCH 2 - PROGRESS: at 36.40% examples, 138097 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:05:28,724, word2vec, INFO, EPOCH 2 - PROGRESS: at 40.74% examples, 140403 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:29,725, word2vec, INFO, EPOCH 2 - PROGRESS: at 44.71% examples, 141800 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 07:05:30,757, word2vec, INFO, EPOCH 2 - PROGRESS: at 49.54% examples, 144626 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:31,850, word2vec, INFO, EPOCH 2 - PROGRESS: at 53.95% examples, 145863 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:05:32,982, word2vec, INFO, EPOCH 2 - PROGRESS: at 58.85% examples, 147716 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:34,015, word2vec, INFO, EPOCH 2 - PROGRESS: at 63.33% examples, 149109 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:35,027, word2vec, INFO, EPOCH 2 - PROGRESS: at 67.77% examples, 150527 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:36,124, word2vec, INFO, EPOCH 2 - PROGRESS: at 72.11% examples, 151125 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:05:37,137, word2vec, INFO, EPOCH 2 - PROGRESS: at 76.45% examples, 152288 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:38,254, word2vec, INFO, EPOCH 2 - PROGRESS: at 81.03% examples, 153033 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:39,261, word2vec, INFO, EPOCH 2 - PROGRESS: at 85.74% examples, 154450 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 07:05:40,490, word2vec, INFO, EPOCH 2 - PROGRESS: at 90.59% examples, 154244 words/s, in_qsize 15, out_qsize 2 ]
[2024-12-13 07:05:41,528, word2vec, INFO, EPOCH 2 - PROGRESS: at 95.72% examples, 156036 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:42,537, word2vec, INFO, EPOCH 2 - PROGRESS: at 99.51% examples, 155700 words/s, in_qsize 2, out_qsize 1 ]
[2024-12-13 07:05:42,730, word2vec, INFO, EPOCH 2: training on 4268692 raw words (3978071 effective words) took 25.6s, 155237 effective words/s ]
[2024-12-13 07:05:43,791, word2vec, INFO, EPOCH 3 - PROGRESS: at 2.06% examples, 80102 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:05:44,846, word2vec, INFO, EPOCH 3 - PROGRESS: at 5.78% examples, 110539 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:45,870, word2vec, INFO, EPOCH 3 - PROGRESS: at 9.67% examples, 124954 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:46,936, word2vec, INFO, EPOCH 3 - PROGRESS: at 14.43% examples, 137491 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:47,958, word2vec, INFO, EPOCH 3 - PROGRESS: at 19.12% examples, 146159 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:49,018, word2vec, INFO, EPOCH 3 - PROGRESS: at 22.80% examples, 145157 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:50,026, word2vec, INFO, EPOCH 3 - PROGRESS: at 27.85% examples, 152942 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:51,056, word2vec, INFO, EPOCH 3 - PROGRESS: at 33.18% examples, 159638 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:52,075, word2vec, INFO, EPOCH 3 - PROGRESS: at 37.55% examples, 161138 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:53,078, word2vec, INFO, EPOCH 3 - PROGRESS: at 41.63% examples, 161653 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:54,108, word2vec, INFO, EPOCH 3 - PROGRESS: at 46.20% examples, 162485 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:55,118, word2vec, INFO, EPOCH 3 - PROGRESS: at 50.70% examples, 163444 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 07:05:56,159, word2vec, INFO, EPOCH 3 - PROGRESS: at 56.05% examples, 166670 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:05:57,218, word2vec, INFO, EPOCH 3 - PROGRESS: at 61.20% examples, 168571 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:05:58,221, word2vec, INFO, EPOCH 3 - PROGRESS: at 66.84% examples, 172032 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:05:59,230, word2vec, INFO, EPOCH 3 - PROGRESS: at 71.88% examples, 173902 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:00,232, word2vec, INFO, EPOCH 3 - PROGRESS: at 76.90% examples, 175606 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:01,251, word2vec, INFO, EPOCH 3 - PROGRESS: at 81.92% examples, 176990 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:06:02,344, word2vec, INFO, EPOCH 3 - PROGRESS: at 87.15% examples, 177535 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:03,440, word2vec, INFO, EPOCH 3 - PROGRESS: at 92.83% examples, 178852 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:04,471, word2vec, INFO, EPOCH 3 - PROGRESS: at 98.32% examples, 180200 words/s, in_qsize 7, out_qsize 1 ]
[2024-12-13 07:06:04,645, word2vec, INFO, EPOCH 3: training on 4268692 raw words (3978766 effective words) took 21.9s, 181721 effective words/s ]
[2024-12-13 07:06:05,735, word2vec, INFO, EPOCH 4 - PROGRESS: at 3.91% examples, 145400 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:06,867, word2vec, INFO, EPOCH 4 - PROGRESS: at 9.44% examples, 171881 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:06:07,879, word2vec, INFO, EPOCH 4 - PROGRESS: at 14.69% examples, 181223 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:08,894, word2vec, INFO, EPOCH 4 - PROGRESS: at 19.82% examples, 185974 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:09,990, word2vec, INFO, EPOCH 4 - PROGRESS: at 24.41% examples, 182567 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:11,034, word2vec, INFO, EPOCH 4 - PROGRESS: at 29.93% examples, 187479 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:12,044, word2vec, INFO, EPOCH 4 - PROGRESS: at 35.25% examples, 190708 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:13,113, word2vec, INFO, EPOCH 4 - PROGRESS: at 40.74% examples, 192899 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:06:14,160, word2vec, INFO, EPOCH 4 - PROGRESS: at 46.43% examples, 195056 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:15,179, word2vec, INFO, EPOCH 4 - PROGRESS: at 51.16% examples, 193794 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:16,220, word2vec, INFO, EPOCH 4 - PROGRESS: at 56.74% examples, 195602 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:06:17,267, word2vec, INFO, EPOCH 4 - PROGRESS: at 62.35% examples, 197002 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:18,318, word2vec, INFO, EPOCH 4 - PROGRESS: at 67.77% examples, 197457 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:19,342, word2vec, INFO, EPOCH 4 - PROGRESS: at 72.61% examples, 196976 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:20,409, word2vec, INFO, EPOCH 4 - PROGRESS: at 77.61% examples, 196580 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-13 07:06:21,469, word2vec, INFO, EPOCH 4 - PROGRESS: at 82.42% examples, 195786 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:22,490, word2vec, INFO, EPOCH 4 - PROGRESS: at 86.70% examples, 193949 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:23,538, word2vec, INFO, EPOCH 4 - PROGRESS: at 92.36% examples, 194933 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:24,555, word2vec, INFO, EPOCH 4 - PROGRESS: at 97.10% examples, 194319 words/s, in_qsize 12, out_qsize 0 ]
[2024-12-13 07:06:24,932, word2vec, INFO, EPOCH 4: training on 4268692 raw words (3978549 effective words) took 20.3s, 196194 effective words/s ]
[2024-12-13 07:06:25,991, word2vec, INFO, EPOCH 5 - PROGRESS: at 3.91% examples, 149757 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:06:27,103, word2vec, INFO, EPOCH 5 - PROGRESS: at 9.44% examples, 175867 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:28,186, word2vec, INFO, EPOCH 5 - PROGRESS: at 15.16% examples, 185727 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:06:29,247, word2vec, INFO, EPOCH 5 - PROGRESS: at 20.51% examples, 189546 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:06:30,300, word2vec, INFO, EPOCH 5 - PROGRESS: at 25.56% examples, 190435 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:31,388, word2vec, INFO, EPOCH 5 - PROGRESS: at 30.82% examples, 191292 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:32,437, word2vec, INFO, EPOCH 5 - PROGRESS: at 36.40% examples, 194187 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:33,480, word2vec, INFO, EPOCH 5 - PROGRESS: at 41.87% examples, 196547 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:34,513, word2vec, INFO, EPOCH 5 - PROGRESS: at 46.65% examples, 194688 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 07:06:35,540, word2vec, INFO, EPOCH 5 - PROGRESS: at 52.10% examples, 195967 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 07:06:36,553, word2vec, INFO, EPOCH 5 - PROGRESS: at 57.38% examples, 197236 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:37,567, word2vec, INFO, EPOCH 5 - PROGRESS: at 62.82% examples, 198275 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:38,596, word2vec, INFO, EPOCH 5 - PROGRESS: at 68.00% examples, 198281 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:39,619, word2vec, INFO, EPOCH 5 - PROGRESS: at 73.07% examples, 198401 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:40,721, word2vec, INFO, EPOCH 5 - PROGRESS: at 78.29% examples, 198055 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:06:41,851, word2vec, INFO, EPOCH 5 - PROGRESS: at 83.81% examples, 198004 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:06:42,852, word2vec, INFO, EPOCH 5 - PROGRESS: at 89.37% examples, 198829 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:43,887, word2vec, INFO, EPOCH 5 - PROGRESS: at 94.72% examples, 199193 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:44,766, word2vec, INFO, EPOCH 5: training on 4268692 raw words (3978289 effective words) took 19.8s, 200656 effective words/s ]
[2024-12-13 07:06:45,846, word2vec, INFO, EPOCH 6 - PROGRESS: at 4.17% examples, 155529 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:46,870, word2vec, INFO, EPOCH 6 - PROGRESS: at 9.44% examples, 181490 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:47,899, word2vec, INFO, EPOCH 6 - PROGRESS: at 14.65% examples, 187021 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:48,947, word2vec, INFO, EPOCH 6 - PROGRESS: at 19.82% examples, 188981 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:50,038, word2vec, INFO, EPOCH 6 - PROGRESS: at 24.87% examples, 188593 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:51,106, word2vec, INFO, EPOCH 6 - PROGRESS: at 29.47% examples, 185948 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:52,230, word2vec, INFO, EPOCH 6 - PROGRESS: at 34.54% examples, 185267 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:53,243, word2vec, INFO, EPOCH 6 - PROGRESS: at 39.67% examples, 187183 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 07:06:54,269, word2vec, INFO, EPOCH 6 - PROGRESS: at 44.73% examples, 188460 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:55,273, word2vec, INFO, EPOCH 6 - PROGRESS: at 49.51% examples, 188085 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:06:56,382, word2vec, INFO, EPOCH 6 - PROGRESS: at 55.11% examples, 189276 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:57,399, word2vec, INFO, EPOCH 6 - PROGRESS: at 60.73% examples, 191642 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:58,420, word2vec, INFO, EPOCH 6 - PROGRESS: at 66.16% examples, 192935 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:06:59,447, word2vec, INFO, EPOCH 6 - PROGRESS: at 70.69% examples, 192095 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:07:00,452, word2vec, INFO, EPOCH 6 - PROGRESS: at 76.20% examples, 193981 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:01,452, word2vec, INFO, EPOCH 6 - PROGRESS: at 81.03% examples, 194048 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:02,579, word2vec, INFO, EPOCH 6 - PROGRESS: at 86.23% examples, 193218 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:03,590, word2vec, INFO, EPOCH 6 - PROGRESS: at 91.45% examples, 193673 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:07:04,650, word2vec, INFO, EPOCH 6 - PROGRESS: at 96.86% examples, 194077 words/s, in_qsize 12, out_qsize 1 ]
[2024-12-13 07:07:05,126, word2vec, INFO, EPOCH 6: training on 4268692 raw words (3977816 effective words) took 20.4s, 195454 effective words/s ]
[2024-12-13 07:07:06,166, word2vec, INFO, EPOCH 7 - PROGRESS: at 3.91% examples, 152781 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:07,167, word2vec, INFO, EPOCH 7 - PROGRESS: at 9.22% examples, 182678 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:08,201, word2vec, INFO, EPOCH 7 - PROGRESS: at 14.43% examples, 187688 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:09,253, word2vec, INFO, EPOCH 7 - PROGRESS: at 19.12% examples, 184814 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:07:10,265, word2vec, INFO, EPOCH 7 - PROGRESS: at 24.39% examples, 189993 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:11,334, word2vec, INFO, EPOCH 7 - PROGRESS: at 29.93% examples, 192983 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:12,357, word2vec, INFO, EPOCH 7 - PROGRESS: at 34.54% examples, 191305 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:13,359, word2vec, INFO, EPOCH 7 - PROGRESS: at 39.21% examples, 190598 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:07:14,369, word2vec, INFO, EPOCH 7 - PROGRESS: at 44.24% examples, 191838 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:15,453, word2vec, INFO, EPOCH 7 - PROGRESS: at 49.74% examples, 192315 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:07:16,545, word2vec, INFO, EPOCH 7 - PROGRESS: at 54.67% examples, 190970 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:07:17,555, word2vec, INFO, EPOCH 7 - PROGRESS: at 59.80% examples, 191845 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:18,583, word2vec, INFO, EPOCH 7 - PROGRESS: at 64.77% examples, 191645 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:19,723, word2vec, INFO, EPOCH 7 - PROGRESS: at 70.25% examples, 191979 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 07:07:20,801, word2vec, INFO, EPOCH 7 - PROGRESS: at 75.75% examples, 193004 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:21,812, word2vec, INFO, EPOCH 7 - PROGRESS: at 80.80% examples, 193538 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:22,860, word2vec, INFO, EPOCH 7 - PROGRESS: at 85.97% examples, 193601 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:23,896, word2vec, INFO, EPOCH 7 - PROGRESS: at 91.24% examples, 193773 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:25,015, word2vec, INFO, EPOCH 7 - PROGRESS: at 96.86% examples, 194072 words/s, in_qsize 13, out_qsize 0 ]
[2024-12-13 07:07:25,453, word2vec, INFO, EPOCH 7: training on 4268692 raw words (3978477 effective words) took 20.3s, 195812 effective words/s ]
[2024-12-13 07:07:26,500, word2vec, INFO, EPOCH 8 - PROGRESS: at 3.91% examples, 151574 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:27,600, word2vec, INFO, EPOCH 8 - PROGRESS: at 9.22% examples, 173488 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:07:28,714, word2vec, INFO, EPOCH 8 - PROGRESS: at 14.92% examples, 182504 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:29,740, word2vec, INFO, EPOCH 8 - PROGRESS: at 20.29% examples, 188653 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:30,750, word2vec, INFO, EPOCH 8 - PROGRESS: at 25.13% examples, 189439 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:31,792, word2vec, INFO, EPOCH 8 - PROGRESS: at 30.17% examples, 190326 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:32,887, word2vec, INFO, EPOCH 8 - PROGRESS: at 35.48% examples, 190997 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:33,930, word2vec, INFO, EPOCH 8 - PROGRESS: at 40.29% examples, 190481 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:34,939, word2vec, INFO, EPOCH 8 - PROGRESS: at 45.22% examples, 190777 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:07:36,033, word2vec, INFO, EPOCH 8 - PROGRESS: at 50.93% examples, 192069 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:37,044, word2vec, INFO, EPOCH 8 - PROGRESS: at 56.04% examples, 192931 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:38,047, word2vec, INFO, EPOCH 8 - PROGRESS: at 60.98% examples, 193044 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:39,146, word2vec, INFO, EPOCH 8 - PROGRESS: at 66.36% examples, 193130 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:40,245, word2vec, INFO, EPOCH 8 - PROGRESS: at 71.65% examples, 193223 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:07:41,368, word2vec, INFO, EPOCH 8 - PROGRESS: at 77.13% examples, 193583 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:42,499, word2vec, INFO, EPOCH 8 - PROGRESS: at 82.67% examples, 193806 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:43,605, word2vec, INFO, EPOCH 8 - PROGRESS: at 88.39% examples, 194263 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:44,637, word2vec, INFO, EPOCH 8 - PROGRESS: at 93.59% examples, 194403 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:45,650, word2vec, INFO, EPOCH 8 - PROGRESS: at 98.32% examples, 193862 words/s, in_qsize 7, out_qsize 1 ]
[2024-12-13 07:07:45,884, word2vec, INFO, EPOCH 8: training on 4268692 raw words (3978453 effective words) took 20.4s, 194810 effective words/s ]
[2024-12-13 07:07:46,926, word2vec, INFO, EPOCH 9 - PROGRESS: at 3.91% examples, 151892 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:47,927, word2vec, INFO, EPOCH 9 - PROGRESS: at 8.97% examples, 177617 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 07:07:48,945, word2vec, INFO, EPOCH 9 - PROGRESS: at 13.94% examples, 182245 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:49,981, word2vec, INFO, EPOCH 9 - PROGRESS: at 19.33% examples, 188258 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:50,996, word2vec, INFO, EPOCH 9 - PROGRESS: at 23.49% examples, 183595 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:52,033, word2vec, INFO, EPOCH 9 - PROGRESS: at 28.99% examples, 188747 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:53,038, word2vec, INFO, EPOCH 9 - PROGRESS: at 33.87% examples, 189401 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:07:54,068, word2vec, INFO, EPOCH 9 - PROGRESS: at 38.74% examples, 189359 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:55,088, word2vec, INFO, EPOCH 9 - PROGRESS: at 44.02% examples, 191585 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:07:56,093, word2vec, INFO, EPOCH 9 - PROGRESS: at 49.06% examples, 191756 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:57,103, word2vec, INFO, EPOCH 9 - PROGRESS: at 53.95% examples, 191852 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:07:58,108, word2vec, INFO, EPOCH 9 - PROGRESS: at 59.08% examples, 192734 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:07:59,128, word2vec, INFO, EPOCH 9 - PROGRESS: at 64.54% examples, 193986 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:08:00,174, word2vec, INFO, EPOCH 9 - PROGRESS: at 69.80% examples, 194756 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:08:01,206, word2vec, INFO, EPOCH 9 - PROGRESS: at 74.43% examples, 193748 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 07:08:02,278, word2vec, INFO, EPOCH 9 - PROGRESS: at 79.67% examples, 194098 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:08:03,319, word2vec, INFO, EPOCH 9 - PROGRESS: at 84.78% examples, 194216 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:08:04,323, word2vec, INFO, EPOCH 9 - PROGRESS: at 90.34% examples, 195207 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:08:05,342, word2vec, INFO, EPOCH 9 - PROGRESS: at 94.70% examples, 194002 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 07:08:06,224, word2vec, INFO, EPOCH 9: training on 4268692 raw words (3977569 effective words) took 20.3s, 195631 effective words/s ]
[2024-12-13 07:08:06,226, utils, INFO, FastText lifecycle event {'msg': 'training on 42686920 raw words (39781953 effective words) took 222.7s, 178646 effective words/s', 'datetime': '2024-12-13T07:08:06.226253', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'} ]
[2024-12-13 07:08:14,086, utils, INFO, FastText lifecycle event {'params': 'FastText<vocab=160129, vector_size=300, alpha=0.025>', 'datetime': '2024-12-13T07:08:14.086302', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'} ]
[2024-12-13 07:08:14,179, keyedvectors, WARNING, destructive init_sims(replace=True) deprecated & no longer required for space-efficiency ]
[2024-12-13 07:08:14,371, keyedvectors, INFO, storing 160129x300 projection weights into ft_reviews_vectors.bin ]
[2024-12-13 07:09:35,086, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 07:12:12,752, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 08:48:11,623, keyedvectors, WARNING, attribute count not present in KeyedVectors<vector_size=300, 120619 keys>; will store in internal index_to_key order ]
[2024-12-13 08:48:11,632, keyedvectors, INFO, storing 120619x300 projection weights into gensim_my_fasttext_model.bin ]
[2024-12-13 08:48:12,895, keyedvectors, WARNING, destructive init_sims(replace=True) deprecated & no longer required for space-efficiency ]
[2024-12-13 08:48:12,931, utils, INFO, KeyedVectors lifecycle event {'fname_or_handle': 'quantized_model.kv', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-12-13T08:48:12.931768', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'saving'} ]
[2024-12-13 08:48:12,940, utils, INFO, storing np array 'vectors' to quantized_model.kv.vectors.npy ]
[2024-12-13 08:48:13,345, utils, INFO, saved quantized_model.kv ]
[2024-12-13 08:49:25,874, utils, INFO, loading KeyedVectors object from quantized_model.kv ]
[2024-12-13 08:49:26,045, utils, INFO, loading vectors from quantized_model.kv.vectors.npy with mmap=r ]
[2024-12-13 08:49:26,068, utils, INFO, KeyedVectors lifecycle event {'fname': 'quantized_model.kv', 'datetime': '2024-12-13T08:49:26.068104', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'loaded'} ]
[2024-12-13 08:52:01,719, keyedvectors, INFO, loading projection weights from gensim_my_fasttext_model.bin ]
[2024-12-13 08:52:03,277, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (120619, 300) matrix of type float32 from gensim_my_fasttext_model.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T08:52:03.277696', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 18:03:07,296, word2vec, INFO, collecting all words and their counts ]
[2024-12-13 18:03:07,297, word2vec, INFO, PROGRESS: at sentence #0, processed 0 words, keeping 0 word types ]
[2024-12-13 18:03:07,414, word2vec, INFO, PROGRESS: at sentence #10000, processed 414946 words, keeping 45101 word types ]
[2024-12-13 18:03:07,554, word2vec, INFO, PROGRESS: at sentence #20000, processed 822575 words, keeping 69280 word types ]
[2024-12-13 18:03:07,691, word2vec, INFO, PROGRESS: at sentence #30000, processed 1238200 words, keeping 90115 word types ]
[2024-12-13 18:03:07,814, word2vec, INFO, PROGRESS: at sentence #40000, processed 1650529 words, keeping 108615 word types ]
[2024-12-13 18:03:07,921, word2vec, INFO, PROGRESS: at sentence #50000, processed 2061831 words, keeping 125191 word types ]
[2024-12-13 18:03:08,026, word2vec, INFO, PROGRESS: at sentence #60000, processed 2471877 words, keeping 140808 word types ]
[2024-12-13 18:03:08,152, word2vec, INFO, PROGRESS: at sentence #70000, processed 2878895 words, keeping 155424 word types ]
[2024-12-13 18:03:08,282, word2vec, INFO, PROGRESS: at sentence #80000, processed 3298436 words, keeping 170237 word types ]
[2024-12-13 18:03:08,411, word2vec, INFO, PROGRESS: at sentence #90000, processed 3709814 words, keeping 184531 word types ]
[2024-12-13 18:03:08,532, word2vec, INFO, PROGRESS: at sentence #100000, processed 4113390 words, keeping 197645 word types ]
[2024-12-13 18:03:08,570, word2vec, INFO, collected 201881 word types from a corpus of 4244784 raw words and 103304 sentences ]
[2024-12-13 18:03:08,571, word2vec, INFO, Creating a fresh vocabulary ]
[2024-12-13 18:03:09,545, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 retains 201881 unique words (100.00% of original 201881, drops 0)', 'datetime': '2024-12-13T18:03:09.545612', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-13 18:03:09,547, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 leaves 4244784 word corpus (100.00% of original 4244784, drops 0)', 'datetime': '2024-12-13T18:03:09.547571', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-13 18:03:11,082, word2vec, INFO, deleting the raw counts dictionary of 201881 items ]
[2024-12-13 18:03:11,088, word2vec, INFO, sample=0.001 downsamples 33 most-common words ]
[2024-12-13 18:03:11,089, utils, INFO, FastText lifecycle event {'msg': 'downsampling leaves estimated 4003657.77288981 word corpus (94.3%% of prior 4244784)', 'datetime': '2024-12-13T18:03:11.089450', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-13 18:03:15,597, fasttext, INFO, estimated required memory for 201881 words, 2000000 buckets and 25 dimensions: 384871980 bytes ]
[2024-12-13 18:03:15,598, word2vec, INFO, resetting layer weights ]
[2024-12-13 18:03:28,881, utils, INFO, FastText lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-12-13T18:03:28.881621', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'} ]
[2024-12-13 18:03:28,883, utils, INFO, FastText lifecycle event {'msg': 'training model with 8 workers on 201881 vocabulary and 25 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-12-13T18:03:28.883581', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'} ]
[2024-12-13 18:03:29,909, word2vec, INFO, EPOCH 0 - PROGRESS: at 9.74% examples, 388075 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:30,913, word2vec, INFO, EPOCH 0 - PROGRESS: at 20.41% examples, 404171 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:31,952, word2vec, INFO, EPOCH 0 - PROGRESS: at 31.02% examples, 408219 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 18:03:32,990, word2vec, INFO, EPOCH 0 - PROGRESS: at 41.67% examples, 410349 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-13 18:03:33,992, word2vec, INFO, EPOCH 0 - PROGRESS: at 53.38% examples, 419886 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:34,994, word2vec, INFO, EPOCH 0 - PROGRESS: at 63.94% examples, 419896 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:36,029, word2vec, INFO, EPOCH 0 - PROGRESS: at 75.04% examples, 422225 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:37,039, word2vec, INFO, EPOCH 0 - PROGRESS: at 86.29% examples, 425277 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:38,041, word2vec, INFO, EPOCH 0 - PROGRESS: at 96.76% examples, 423841 words/s, in_qsize 14, out_qsize 0 ]
[2024-12-13 18:03:38,330, word2vec, INFO, EPOCH 0: training on 4244784 raw words (4003695 effective words) took 9.4s, 424282 effective words/s ]
[2024-12-13 18:03:39,347, word2vec, INFO, EPOCH 1 - PROGRESS: at 9.52% examples, 382334 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:40,360, word2vec, INFO, EPOCH 1 - PROGRESS: at 19.24% examples, 381037 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:41,362, word2vec, INFO, EPOCH 1 - PROGRESS: at 29.64% examples, 394598 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:42,383, word2vec, INFO, EPOCH 1 - PROGRESS: at 39.48% examples, 392498 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-13 18:03:43,383, word2vec, INFO, EPOCH 1 - PROGRESS: at 50.78% examples, 404021 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:44,383, word2vec, INFO, EPOCH 1 - PROGRESS: at 62.00% examples, 411442 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:45,394, word2vec, INFO, EPOCH 1 - PROGRESS: at 72.52% examples, 412466 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:46,403, word2vec, INFO, EPOCH 1 - PROGRESS: at 82.91% examples, 413349 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 18:03:47,408, word2vec, INFO, EPOCH 1 - PROGRESS: at 93.69% examples, 414086 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:47,876, word2vec, INFO, EPOCH 1: training on 4244784 raw words (4003130 effective words) took 9.5s, 419788 effective words/s ]
[2024-12-13 18:03:48,888, word2vec, INFO, EPOCH 2 - PROGRESS: at 9.95% examples, 402591 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:49,915, word2vec, INFO, EPOCH 2 - PROGRESS: at 21.52% examples, 425653 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:50,944, word2vec, INFO, EPOCH 2 - PROGRESS: at 32.25% examples, 423859 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:51,946, word2vec, INFO, EPOCH 2 - PROGRESS: at 43.56% examples, 432377 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 18:03:52,963, word2vec, INFO, EPOCH 2 - PROGRESS: at 54.99% examples, 434455 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:53,981, word2vec, INFO, EPOCH 2 - PROGRESS: at 66.77% examples, 438705 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:54,983, word2vec, INFO, EPOCH 2 - PROGRESS: at 77.33% examples, 437714 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:55,986, word2vec, INFO, EPOCH 2 - PROGRESS: at 88.92% examples, 440370 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:56,913, word2vec, INFO, EPOCH 2: training on 4244784 raw words (4003035 effective words) took 9.0s, 443453 effective words/s ]
[2024-12-13 18:03:57,932, word2vec, INFO, EPOCH 3 - PROGRESS: at 9.95% examples, 399345 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:58,952, word2vec, INFO, EPOCH 3 - PROGRESS: at 21.08% examples, 416084 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:03:59,953, word2vec, INFO, EPOCH 3 - PROGRESS: at 32.69% examples, 433798 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:00,958, word2vec, INFO, EPOCH 3 - PROGRESS: at 44.07% examples, 439657 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:01,962, word2vec, INFO, EPOCH 3 - PROGRESS: at 55.68% examples, 443374 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:02,965, word2vec, INFO, EPOCH 3 - PROGRESS: at 66.77% examples, 442563 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:03,989, word2vec, INFO, EPOCH 3 - PROGRESS: at 78.06% examples, 443596 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:05,019, word2vec, INFO, EPOCH 3 - PROGRESS: at 89.42% examples, 442879 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 18:04:05,921, word2vec, INFO, EPOCH 3: training on 4244784 raw words (4003700 effective words) took 9.0s, 444892 effective words/s ]
[2024-12-13 18:04:06,956, word2vec, INFO, EPOCH 4 - PROGRESS: at 9.74% examples, 383809 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:07,964, word2vec, INFO, EPOCH 4 - PROGRESS: at 21.08% examples, 415123 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:08,975, word2vec, INFO, EPOCH 4 - PROGRESS: at 32.69% examples, 431687 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:09,993, word2vec, INFO, EPOCH 4 - PROGRESS: at 44.07% examples, 436810 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:11,015, word2vec, INFO, EPOCH 4 - PROGRESS: at 55.90% examples, 441384 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:12,019, word2vec, INFO, EPOCH 4 - PROGRESS: at 66.77% examples, 439298 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:13,040, word2vec, INFO, EPOCH 4 - PROGRESS: at 78.28% examples, 442401 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:14,047, word2vec, INFO, EPOCH 4 - PROGRESS: at 89.42% examples, 441933 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:14,891, word2vec, INFO, EPOCH 4: training on 4244784 raw words (4004438 effective words) took 9.0s, 446829 effective words/s ]
[2024-12-13 18:04:15,909, word2vec, INFO, EPOCH 5 - PROGRESS: at 10.16% examples, 409539 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:16,919, word2vec, INFO, EPOCH 5 - PROGRESS: at 21.08% examples, 418324 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:17,922, word2vec, INFO, EPOCH 5 - PROGRESS: at 32.69% examples, 434998 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:18,945, word2vec, INFO, EPOCH 5 - PROGRESS: at 43.56% examples, 434016 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:19,963, word2vec, INFO, EPOCH 5 - PROGRESS: at 55.20% examples, 437591 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:20,966, word2vec, INFO, EPOCH 5 - PROGRESS: at 66.03% examples, 436227 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 18:04:21,969, word2vec, INFO, EPOCH 5 - PROGRESS: at 77.33% examples, 439511 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:22,982, word2vec, INFO, EPOCH 5 - PROGRESS: at 88.20% examples, 437966 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:23,936, word2vec, INFO, EPOCH 5: training on 4244784 raw words (4003329 effective words) took 9.0s, 443021 effective words/s ]
[2024-12-13 18:04:24,953, word2vec, INFO, EPOCH 6 - PROGRESS: at 9.95% examples, 400846 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:25,973, word2vec, INFO, EPOCH 6 - PROGRESS: at 21.08% examples, 416755 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:26,981, word2vec, INFO, EPOCH 6 - PROGRESS: at 32.69% examples, 433136 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:28,001, word2vec, INFO, EPOCH 6 - PROGRESS: at 43.07% examples, 428324 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:29,011, word2vec, INFO, EPOCH 6 - PROGRESS: at 54.99% examples, 435642 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:30,031, word2vec, INFO, EPOCH 6 - PROGRESS: at 66.27% examples, 436397 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:31,034, word2vec, INFO, EPOCH 6 - PROGRESS: at 77.59% examples, 439661 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 18:04:32,051, word2vec, INFO, EPOCH 6 - PROGRESS: at 89.42% examples, 442520 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:32,980, word2vec, INFO, EPOCH 6: training on 4244784 raw words (4003758 effective words) took 9.0s, 443150 effective words/s ]
[2024-12-13 18:04:34,005, word2vec, INFO, EPOCH 7 - PROGRESS: at 9.95% examples, 397127 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:35,014, word2vec, INFO, EPOCH 7 - PROGRESS: at 21.30% examples, 421853 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:36,024, word2vec, INFO, EPOCH 7 - PROGRESS: at 32.90% examples, 436158 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:37,030, word2vec, INFO, EPOCH 7 - PROGRESS: at 43.56% examples, 434499 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 18:04:38,036, word2vec, INFO, EPOCH 7 - PROGRESS: at 54.99% examples, 437278 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:39,052, word2vec, INFO, EPOCH 7 - PROGRESS: at 66.52% examples, 439561 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 18:04:40,066, word2vec, INFO, EPOCH 7 - PROGRESS: at 77.11% examples, 437745 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:41,080, word2vec, INFO, EPOCH 7 - PROGRESS: at 89.18% examples, 442082 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:41,987, word2vec, INFO, EPOCH 7: training on 4244784 raw words (4003606 effective words) took 9.0s, 444883 effective words/s ]
[2024-12-13 18:04:43,010, word2vec, INFO, EPOCH 8 - PROGRESS: at 9.74% examples, 389048 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 18:04:44,013, word2vec, INFO, EPOCH 8 - PROGRESS: at 21.08% examples, 419069 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:45,014, word2vec, INFO, EPOCH 8 - PROGRESS: at 32.47% examples, 432655 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:46,037, word2vec, INFO, EPOCH 8 - PROGRESS: at 44.07% examples, 439313 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:47,045, word2vec, INFO, EPOCH 8 - PROGRESS: at 54.99% examples, 437221 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:48,074, word2vec, INFO, EPOCH 8 - PROGRESS: at 66.77% examples, 440153 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:49,077, word2vec, INFO, EPOCH 8 - PROGRESS: at 77.11% examples, 437580 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:50,077, word2vec, INFO, EPOCH 8 - PROGRESS: at 88.92% examples, 441552 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:51,003, word2vec, INFO, EPOCH 8: training on 4244784 raw words (4004168 effective words) took 9.0s, 444584 effective words/s ]
[2024-12-13 18:04:52,029, word2vec, INFO, EPOCH 9 - PROGRESS: at 10.16% examples, 406404 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:53,038, word2vec, INFO, EPOCH 9 - PROGRESS: at 21.30% examples, 421883 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:54,049, word2vec, INFO, EPOCH 9 - PROGRESS: at 32.25% examples, 426826 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:55,071, word2vec, INFO, EPOCH 9 - PROGRESS: at 43.81% examples, 434881 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:56,102, word2vec, INFO, EPOCH 9 - PROGRESS: at 54.99% examples, 433525 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:57,140, word2vec, INFO, EPOCH 9 - PROGRESS: at 66.77% examples, 436502 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:58,150, word2vec, INFO, EPOCH 9 - PROGRESS: at 77.59% examples, 436604 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 18:04:59,158, word2vec, INFO, EPOCH 9 - PROGRESS: at 88.92% examples, 437953 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-13 18:05:00,143, word2vec, INFO, EPOCH 9: training on 4244784 raw words (4003757 effective words) took 9.1s, 438486 effective words/s ]
[2024-12-13 18:05:00,144, utils, INFO, FastText lifecycle event {'msg': 'training on 42447840 raw words (40036616 effective words) took 91.3s, 438710 effective words/s', 'datetime': '2024-12-13T18:05:00.144110', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'} ]
[2024-12-13 18:05:10,033, utils, INFO, FastText lifecycle event {'params': 'FastText<vocab=201881, vector_size=25, alpha=0.025>', 'datetime': '2024-12-13T18:05:10.033708', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'} ]
[2024-12-13 18:05:10,048, keyedvectors, WARNING, destructive init_sims(replace=True) deprecated & no longer required for space-efficiency ]
[2024-12-13 18:05:10,250, keyedvectors, INFO, storing 201881x25 projection weights into ft_reviews_vectors.bin ]
[2024-12-13 18:07:35,667, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 18:07:38,241, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T18:07:38.241870', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 20:11:44,671, word2vec, INFO, collecting all words and their counts ]
[2024-12-13 20:11:44,673, word2vec, INFO, PROGRESS: at sentence #0, processed 0 words, keeping 0 word types ]
[2024-12-13 20:11:44,800, word2vec, INFO, PROGRESS: at sentence #10000, processed 414946 words, keeping 45101 word types ]
[2024-12-13 20:11:44,886, word2vec, INFO, PROGRESS: at sentence #20000, processed 822575 words, keeping 69280 word types ]
[2024-12-13 20:11:44,987, word2vec, INFO, PROGRESS: at sentence #30000, processed 1238200 words, keeping 90115 word types ]
[2024-12-13 20:11:45,079, word2vec, INFO, PROGRESS: at sentence #40000, processed 1650529 words, keeping 108615 word types ]
[2024-12-13 20:11:45,167, word2vec, INFO, PROGRESS: at sentence #50000, processed 2061831 words, keeping 125191 word types ]
[2024-12-13 20:11:45,264, word2vec, INFO, PROGRESS: at sentence #60000, processed 2471877 words, keeping 140808 word types ]
[2024-12-13 20:11:45,375, word2vec, INFO, PROGRESS: at sentence #70000, processed 2878895 words, keeping 155424 word types ]
[2024-12-13 20:11:45,476, word2vec, INFO, PROGRESS: at sentence #80000, processed 3298436 words, keeping 170237 word types ]
[2024-12-13 20:11:45,576, word2vec, INFO, PROGRESS: at sentence #90000, processed 3709814 words, keeping 184531 word types ]
[2024-12-13 20:11:45,687, word2vec, INFO, PROGRESS: at sentence #100000, processed 4113390 words, keeping 197645 word types ]
[2024-12-13 20:11:45,789, word2vec, INFO, collected 201881 word types from a corpus of 4244784 raw words and 103304 sentences ]
[2024-12-13 20:11:45,790, word2vec, INFO, Creating a fresh vocabulary ]
[2024-12-13 20:11:46,666, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 retains 201881 unique words (100.00% of original 201881, drops 0)', 'datetime': '2024-12-13T20:11:46.666338', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-13 20:11:46,668, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 leaves 4244784 word corpus (100.00% of original 4244784, drops 0)', 'datetime': '2024-12-13T20:11:46.668332', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-13 20:11:47,948, word2vec, INFO, deleting the raw counts dictionary of 201881 items ]
[2024-12-13 20:11:47,952, word2vec, INFO, sample=0.001 downsamples 33 most-common words ]
[2024-12-13 20:11:47,954, utils, INFO, FastText lifecycle event {'msg': 'downsampling leaves estimated 4003657.77288981 word corpus (94.3%% of prior 4244784)', 'datetime': '2024-12-13T20:11:47.954891', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-13 20:11:51,831, fasttext, INFO, estimated required memory for 201881 words, 2000000 buckets and 50 dimensions: 625248180 bytes ]
[2024-12-13 20:11:51,832, word2vec, INFO, resetting layer weights ]
[2024-12-13 20:12:03,285, utils, INFO, FastText lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-12-13T20:12:03.285585', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'} ]
[2024-12-13 20:12:03,287, utils, INFO, FastText lifecycle event {'msg': 'training model with 8 workers on 201881 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-12-13T20:12:03.287552', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'} ]
[2024-12-13 20:12:04,317, word2vec, INFO, EPOCH 0 - PROGRESS: at 4.42% examples, 176204 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:05,368, word2vec, INFO, EPOCH 0 - PROGRESS: at 9.74% examples, 191293 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:06,378, word2vec, INFO, EPOCH 0 - PROGRESS: at 16.20% examples, 210967 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:07,407, word2vec, INFO, EPOCH 0 - PROGRESS: at 21.08% examples, 206036 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:08,412, word2vec, INFO, EPOCH 0 - PROGRESS: at 26.60% examples, 209695 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:09,418, word2vec, INFO, EPOCH 0 - PROGRESS: at 32.25% examples, 212050 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:10,458, word2vec, INFO, EPOCH 0 - PROGRESS: at 38.75% examples, 217947 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:11,480, word2vec, INFO, EPOCH 0 - PROGRESS: at 44.28% examples, 218266 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:12,501, word2vec, INFO, EPOCH 0 - PROGRESS: at 50.56% examples, 220607 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:13,501, word2vec, INFO, EPOCH 0 - PROGRESS: at 56.16% examples, 221033 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:14,641, word2vec, INFO, EPOCH 0 - PROGRESS: at 62.00% examples, 219398 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:15,653, word2vec, INFO, EPOCH 0 - PROGRESS: at 67.91% examples, 220435 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:16,679, word2vec, INFO, EPOCH 0 - PROGRESS: at 73.25% examples, 219682 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:12:17,740, word2vec, INFO, EPOCH 0 - PROGRESS: at 79.43% examples, 221150 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:18,746, word2vec, INFO, EPOCH 0 - PROGRESS: at 85.04% examples, 221356 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:19,753, word2vec, INFO, EPOCH 0 - PROGRESS: at 90.87% examples, 221495 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:20,776, word2vec, INFO, EPOCH 0 - PROGRESS: at 95.82% examples, 219817 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:21,448, word2vec, INFO, EPOCH 0: training on 4244784 raw words (4003558 effective words) took 18.1s, 220688 effective words/s ]
[2024-12-13 20:12:22,458, word2vec, INFO, EPOCH 1 - PROGRESS: at 4.42% examples, 177746 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:23,465, word2vec, INFO, EPOCH 1 - PROGRESS: at 9.95% examples, 201066 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:24,488, word2vec, INFO, EPOCH 1 - PROGRESS: at 16.62% examples, 220015 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:25,523, word2vec, INFO, EPOCH 1 - PROGRESS: at 22.46% examples, 221609 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:26,675, word2vec, INFO, EPOCH 1 - PROGRESS: at 28.25% examples, 217645 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:27,682, word2vec, INFO, EPOCH 1 - PROGRESS: at 34.53% examples, 223183 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:28,691, word2vec, INFO, EPOCH 1 - PROGRESS: at 40.54% examples, 225875 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:29,722, word2vec, INFO, EPOCH 1 - PROGRESS: at 46.77% examples, 227199 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:30,791, word2vec, INFO, EPOCH 1 - PROGRESS: at 52.69% examples, 226379 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:31,824, word2vec, INFO, EPOCH 1 - PROGRESS: at 58.47% examples, 226308 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:32,849, word2vec, INFO, EPOCH 1 - PROGRESS: at 64.19% examples, 225677 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:33,869, word2vec, INFO, EPOCH 1 - PROGRESS: at 70.67% examples, 228360 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:34,885, word2vec, INFO, EPOCH 1 - PROGRESS: at 76.18% examples, 227892 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:12:35,936, word2vec, INFO, EPOCH 1 - PROGRESS: at 82.19% examples, 228243 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:36,997, word2vec, INFO, EPOCH 1 - PROGRESS: at 88.44% examples, 228384 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:38,006, word2vec, INFO, EPOCH 1 - PROGRESS: at 94.13% examples, 228064 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:38,834, word2vec, INFO, EPOCH 1: training on 4244784 raw words (4003644 effective words) took 17.4s, 230395 effective words/s ]
[2024-12-13 20:12:39,844, word2vec, INFO, EPOCH 2 - PROGRESS: at 5.56% examples, 225038 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:41,047, word2vec, INFO, EPOCH 2 - PROGRESS: at 11.39% examples, 208769 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:12:42,056, word2vec, INFO, EPOCH 2 - PROGRESS: at 17.59% examples, 219291 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:43,072, word2vec, INFO, EPOCH 2 - PROGRESS: at 23.62% examples, 224248 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:44,079, word2vec, INFO, EPOCH 2 - PROGRESS: at 29.42% examples, 225921 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:45,108, word2vec, INFO, EPOCH 2 - PROGRESS: at 35.25% examples, 226349 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:46,181, word2vec, INFO, EPOCH 2 - PROGRESS: at 41.22% examples, 226564 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:47,193, word2vec, INFO, EPOCH 2 - PROGRESS: at 46.99% examples, 226067 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:48,255, word2vec, INFO, EPOCH 2 - PROGRESS: at 53.63% examples, 228533 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:49,259, word2vec, INFO, EPOCH 2 - PROGRESS: at 59.20% examples, 227979 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:50,351, word2vec, INFO, EPOCH 2 - PROGRESS: at 65.36% examples, 227499 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:12:51,411, word2vec, INFO, EPOCH 2 - PROGRESS: at 70.87% examples, 226260 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:52,433, word2vec, INFO, EPOCH 2 - PROGRESS: at 76.67% examples, 226553 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-13 20:12:53,458, word2vec, INFO, EPOCH 2 - PROGRESS: at 82.68% examples, 227416 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:54,465, word2vec, INFO, EPOCH 2 - PROGRESS: at 88.68% examples, 227777 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:12:55,500, word2vec, INFO, EPOCH 2 - PROGRESS: at 94.57% examples, 227712 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:12:56,299, word2vec, INFO, EPOCH 2: training on 4244784 raw words (4003444 effective words) took 17.5s, 229345 effective words/s ]
[2024-12-13 20:12:57,347, word2vec, INFO, EPOCH 3 - PROGRESS: at 5.35% examples, 207545 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:58,370, word2vec, INFO, EPOCH 3 - PROGRESS: at 10.86% examples, 214059 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:12:59,395, word2vec, INFO, EPOCH 3 - PROGRESS: at 16.62% examples, 216032 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:00,456, word2vec, INFO, EPOCH 3 - PROGRESS: at 22.22% examples, 214997 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:01,485, word2vec, INFO, EPOCH 3 - PROGRESS: at 27.79% examples, 215781 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:02,498, word2vec, INFO, EPOCH 3 - PROGRESS: at 33.62% examples, 218459 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:03,593, word2vec, INFO, EPOCH 3 - PROGRESS: at 39.26% examples, 216577 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:04,619, word2vec, INFO, EPOCH 3 - PROGRESS: at 44.77% examples, 216966 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:05,667, word2vec, INFO, EPOCH 3 - PROGRESS: at 50.81% examples, 217723 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 20:13:06,674, word2vec, INFO, EPOCH 3 - PROGRESS: at 56.39% examples, 218291 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:07,773, word2vec, INFO, EPOCH 3 - PROGRESS: at 62.50% examples, 218521 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:08,803, word2vec, INFO, EPOCH 3 - PROGRESS: at 67.91% examples, 217807 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:09,806, word2vec, INFO, EPOCH 3 - PROGRESS: at 73.45% examples, 218361 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:10,832, word2vec, INFO, EPOCH 3 - PROGRESS: at 79.43% examples, 219787 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:11,839, word2vec, INFO, EPOCH 3 - PROGRESS: at 85.04% examples, 220072 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:12,895, word2vec, INFO, EPOCH 3 - PROGRESS: at 91.30% examples, 220760 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:13,910, word2vec, INFO, EPOCH 3 - PROGRESS: at 96.56% examples, 219772 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:14,446, word2vec, INFO, EPOCH 3: training on 4244784 raw words (4003791 effective words) took 18.1s, 220747 effective words/s ]
[2024-12-13 20:13:15,457, word2vec, INFO, EPOCH 4 - PROGRESS: at 4.87% examples, 196226 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:16,467, word2vec, INFO, EPOCH 4 - PROGRESS: at 9.95% examples, 200662 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:17,490, word2vec, INFO, EPOCH 4 - PROGRESS: at 16.44% examples, 216551 words/s, in_qsize 13, out_qsize 2 ]
[2024-12-13 20:13:18,509, word2vec, INFO, EPOCH 4 - PROGRESS: at 22.46% examples, 222208 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:19,561, word2vec, INFO, EPOCH 4 - PROGRESS: at 28.03% examples, 220580 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:20,610, word2vec, INFO, EPOCH 4 - PROGRESS: at 33.62% examples, 219666 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:21,622, word2vec, INFO, EPOCH 4 - PROGRESS: at 39.91% examples, 224027 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:13:22,637, word2vec, INFO, EPOCH 4 - PROGRESS: at 45.76% examples, 224899 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:23,638, word2vec, INFO, EPOCH 4 - PROGRESS: at 51.48% examples, 224921 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:24,672, word2vec, INFO, EPOCH 4 - PROGRESS: at 57.26% examples, 225088 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:13:25,700, word2vec, INFO, EPOCH 4 - PROGRESS: at 62.50% examples, 222775 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:26,721, word2vec, INFO, EPOCH 4 - PROGRESS: at 67.91% examples, 221856 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:27,725, word2vec, INFO, EPOCH 4 - PROGRESS: at 73.92% examples, 223513 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:13:28,735, word2vec, INFO, EPOCH 4 - PROGRESS: at 79.89% examples, 224827 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:29,782, word2vec, INFO, EPOCH 4 - PROGRESS: at 85.79% examples, 224803 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:30,815, word2vec, INFO, EPOCH 4 - PROGRESS: at 91.56% examples, 224360 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:31,835, word2vec, INFO, EPOCH 4 - PROGRESS: at 97.48% examples, 224729 words/s, in_qsize 11, out_qsize 0 ]
[2024-12-13 20:13:32,228, word2vec, INFO, EPOCH 4: training on 4244784 raw words (4003421 effective words) took 17.8s, 225264 effective words/s ]
[2024-12-13 20:13:33,239, word2vec, INFO, EPOCH 5 - PROGRESS: at 4.65% examples, 187234 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 20:13:34,276, word2vec, INFO, EPOCH 5 - PROGRESS: at 10.16% examples, 202732 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:35,283, word2vec, INFO, EPOCH 5 - PROGRESS: at 16.44% examples, 215949 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:36,292, word2vec, INFO, EPOCH 5 - PROGRESS: at 21.98% examples, 217660 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:37,315, word2vec, INFO, EPOCH 5 - PROGRESS: at 27.55% examples, 218189 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:38,344, word2vec, INFO, EPOCH 5 - PROGRESS: at 33.16% examples, 218357 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:39,352, word2vec, INFO, EPOCH 5 - PROGRESS: at 39.26% examples, 221738 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:40,365, word2vec, INFO, EPOCH 5 - PROGRESS: at 45.02% examples, 222981 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:13:41,367, word2vec, INFO, EPOCH 5 - PROGRESS: at 50.30% examples, 221119 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:42,377, word2vec, INFO, EPOCH 5 - PROGRESS: at 56.16% examples, 222259 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:43,399, word2vec, INFO, EPOCH 5 - PROGRESS: at 62.00% examples, 222788 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:44,438, word2vec, INFO, EPOCH 5 - PROGRESS: at 67.68% examples, 222291 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:13:45,480, word2vec, INFO, EPOCH 5 - PROGRESS: at 73.70% examples, 223265 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:46,563, word2vec, INFO, EPOCH 5 - PROGRESS: at 79.23% examples, 222156 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:47,578, word2vec, INFO, EPOCH 5 - PROGRESS: at 85.30% examples, 223401 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:48,652, word2vec, INFO, EPOCH 5 - PROGRESS: at 90.63% examples, 221346 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:49,689, word2vec, INFO, EPOCH 5 - PROGRESS: at 96.06% examples, 220574 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:50,262, word2vec, INFO, EPOCH 5: training on 4244784 raw words (4003332 effective words) took 18.0s, 222112 effective words/s ]
[2024-12-13 20:13:51,288, word2vec, INFO, EPOCH 6 - PROGRESS: at 4.65% examples, 184651 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:52,301, word2vec, INFO, EPOCH 6 - PROGRESS: at 9.95% examples, 199092 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:53,336, word2vec, INFO, EPOCH 6 - PROGRESS: at 16.20% examples, 211537 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:54,363, word2vec, INFO, EPOCH 6 - PROGRESS: at 21.52% examples, 211118 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:55,422, word2vec, INFO, EPOCH 6 - PROGRESS: at 27.55% examples, 215119 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:56,462, word2vec, INFO, EPOCH 6 - PROGRESS: at 33.16% examples, 215414 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:57,552, word2vec, INFO, EPOCH 6 - PROGRESS: at 38.75% examples, 214105 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:13:58,601, word2vec, INFO, EPOCH 6 - PROGRESS: at 44.28% examples, 214217 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:13:59,646, word2vec, INFO, EPOCH 6 - PROGRESS: at 50.35% examples, 215384 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:00,723, word2vec, INFO, EPOCH 6 - PROGRESS: at 55.93% examples, 214714 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:01,743, word2vec, INFO, EPOCH 6 - PROGRESS: at 61.55% examples, 215143 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:02,781, word2vec, INFO, EPOCH 6 - PROGRESS: at 67.68% examples, 216817 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:14:03,852, word2vec, INFO, EPOCH 6 - PROGRESS: at 73.25% examples, 216347 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:04,900, word2vec, INFO, EPOCH 6 - PROGRESS: at 78.53% examples, 215642 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:05,952, word2vec, INFO, EPOCH 6 - PROGRESS: at 84.32% examples, 216150 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:07,009, word2vec, INFO, EPOCH 6 - PROGRESS: at 89.89% examples, 215407 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:08,023, word2vec, INFO, EPOCH 6 - PROGRESS: at 95.82% examples, 216346 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:08,725, word2vec, INFO, EPOCH 6: training on 4244784 raw words (4003633 effective words) took 18.5s, 216984 effective words/s ]
[2024-12-13 20:14:09,737, word2vec, INFO, EPOCH 7 - PROGRESS: at 4.62% examples, 187037 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-13 20:14:10,751, word2vec, INFO, EPOCH 7 - PROGRESS: at 9.73% examples, 195620 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:11,755, word2vec, INFO, EPOCH 7 - PROGRESS: at 15.94% examples, 211511 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:12,787, word2vec, INFO, EPOCH 7 - PROGRESS: at 21.31% examples, 210819 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:13,788, word2vec, INFO, EPOCH 7 - PROGRESS: at 26.81% examples, 213702 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:14,797, word2vec, INFO, EPOCH 7 - PROGRESS: at 32.00% examples, 212273 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:15,799, word2vec, INFO, EPOCH 7 - PROGRESS: at 37.32% examples, 212679 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:16,828, word2vec, INFO, EPOCH 7 - PROGRESS: at 43.31% examples, 215837 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:14:17,884, word2vec, INFO, EPOCH 7 - PROGRESS: at 48.88% examples, 214477 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:18,920, word2vec, INFO, EPOCH 7 - PROGRESS: at 54.31% examples, 213870 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:14:19,971, word2vec, INFO, EPOCH 7 - PROGRESS: at 60.35% examples, 215487 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:20,986, word2vec, INFO, EPOCH 7 - PROGRESS: at 66.03% examples, 216014 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:21,990, word2vec, INFO, EPOCH 7 - PROGRESS: at 71.84% examples, 217362 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:22,997, word2vec, INFO, EPOCH 7 - PROGRESS: at 77.11% examples, 217212 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:24,009, word2vec, INFO, EPOCH 7 - PROGRESS: at 82.43% examples, 216979 words/s, in_qsize 13, out_qsize 2 ]
[2024-12-13 20:14:25,010, word2vec, INFO, EPOCH 7 - PROGRESS: at 87.94% examples, 216907 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:26,017, word2vec, INFO, EPOCH 7 - PROGRESS: at 93.90% examples, 217845 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:26,958, word2vec, INFO, EPOCH 7: training on 4244784 raw words (4003443 effective words) took 18.2s, 219683 effective words/s ]
[2024-12-13 20:14:27,975, word2vec, INFO, EPOCH 8 - PROGRESS: at 4.40% examples, 176770 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:29,053, word2vec, INFO, EPOCH 8 - PROGRESS: at 9.95% examples, 193550 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:30,117, word2vec, INFO, EPOCH 8 - PROGRESS: at 15.71% examples, 199697 words/s, in_qsize 15, out_qsize 1 ]
[2024-12-13 20:14:31,140, word2vec, INFO, EPOCH 8 - PROGRESS: at 21.30% examples, 204647 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:32,185, word2vec, INFO, EPOCH 8 - PROGRESS: at 27.55% examples, 212250 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:33,187, word2vec, INFO, EPOCH 8 - PROGRESS: at 32.90% examples, 212807 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:34,227, word2vec, INFO, EPOCH 8 - PROGRESS: at 39.00% examples, 215946 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:35,247, word2vec, INFO, EPOCH 8 - PROGRESS: at 43.56% examples, 212035 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:36,248, word2vec, INFO, EPOCH 8 - PROGRESS: at 49.37% examples, 213450 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:37,317, word2vec, INFO, EPOCH 8 - PROGRESS: at 55.68% examples, 215892 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:38,327, word2vec, INFO, EPOCH 8 - PROGRESS: at 61.07% examples, 215586 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:39,364, word2vec, INFO, EPOCH 8 - PROGRESS: at 67.23% examples, 217222 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:40,368, word2vec, INFO, EPOCH 8 - PROGRESS: at 72.06% examples, 215687 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:41,389, word2vec, INFO, EPOCH 8 - PROGRESS: at 77.81% examples, 216724 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:42,439, word2vec, INFO, EPOCH 8 - PROGRESS: at 83.37% examples, 216605 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:43,469, word2vec, INFO, EPOCH 8 - PROGRESS: at 89.64% examples, 217882 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:44,487, word2vec, INFO, EPOCH 8 - PROGRESS: at 95.06% examples, 217559 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:45,271, word2vec, INFO, EPOCH 8: training on 4244784 raw words (4003219 effective words) took 18.3s, 218709 effective words/s ]
[2024-12-13 20:14:46,310, word2vec, INFO, EPOCH 9 - PROGRESS: at 3.94% examples, 154729 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:47,337, word2vec, INFO, EPOCH 9 - PROGRESS: at 9.49% examples, 187215 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:48,363, word2vec, INFO, EPOCH 9 - PROGRESS: at 15.26% examples, 197970 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:49,415, word2vec, INFO, EPOCH 9 - PROGRESS: at 20.88% examples, 201987 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:14:50,468, word2vec, INFO, EPOCH 9 - PROGRESS: at 26.36% examples, 204457 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:51,571, word2vec, INFO, EPOCH 9 - PROGRESS: at 32.00% examples, 204502 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:52,579, word2vec, INFO, EPOCH 9 - PROGRESS: at 37.54% examples, 207095 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:53,588, word2vec, INFO, EPOCH 9 - PROGRESS: at 43.07% examples, 209087 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:54,644, word2vec, INFO, EPOCH 9 - PROGRESS: at 48.89% examples, 209546 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:55,653, word2vec, INFO, EPOCH 9 - PROGRESS: at 54.53% examples, 210924 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-13 20:14:56,676, word2vec, INFO, EPOCH 9 - PROGRESS: at 59.90% examples, 210814 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-13 20:14:57,721, word2vec, INFO, EPOCH 9 - PROGRESS: at 65.82% examples, 211922 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:58,727, word2vec, INFO, EPOCH 9 - PROGRESS: at 71.10% examples, 212181 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:14:59,768, word2vec, INFO, EPOCH 9 - PROGRESS: at 76.89% examples, 213153 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:15:00,786, word2vec, INFO, EPOCH 9 - PROGRESS: at 82.18% examples, 213111 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:15:01,833, word2vec, INFO, EPOCH 9 - PROGRESS: at 88.20% examples, 213814 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:15:02,874, word2vec, INFO, EPOCH 9 - PROGRESS: at 93.90% examples, 213965 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-13 20:15:03,798, word2vec, INFO, EPOCH 9: training on 4244784 raw words (4003256 effective words) took 18.5s, 216185 effective words/s ]
[2024-12-13 20:15:03,799, utils, INFO, FastText lifecycle event {'msg': 'training on 42447840 raw words (40034741 effective words) took 180.5s, 221786 effective words/s', 'datetime': '2024-12-13T20:15:03.799478', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'} ]
[2024-12-13 20:15:13,039, utils, INFO, FastText lifecycle event {'params': 'FastText<vocab=201881, vector_size=50, alpha=0.025>', 'datetime': '2024-12-13T20:15:13.039736', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'} ]
[2024-12-13 20:15:13,071, keyedvectors, WARNING, destructive init_sims(replace=True) deprecated & no longer required for space-efficiency ]
[2024-12-13 20:15:13,273, keyedvectors, INFO, storing 201881x50 projection weights into ft_reviews_vectors.bin ]
[2024-12-13 20:16:41,492, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 20:16:43,943, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T20:16:43.943035', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 21:34:37,365, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 21:34:37,367, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 21:34:37,371, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 21:34:37,372, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 21:34:38,631, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 21:36:12,166, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 21:36:12,166, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 21:36:12,169, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 21:36:12,170, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 21:36:12,601, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 21:36:51,274, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 21:36:51,276, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 21:36:51,278, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 21:36:51,280, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 21:36:51,614, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 21:36:53,122, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 21:36:53,124, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 21:36:54,603, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 21:36:54,635, data_transformation, INFO, Initiating the DataTransformation ]
[2024-12-13 21:57:31,608, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 21:57:31,610, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 21:57:31,613, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 21:57:31,615, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 21:57:31,945, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 21:57:33,416, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 21:57:33,418, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 21:57:35,127, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 21:59:16,121, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 21:59:16,123, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 21:59:16,124, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 21:59:16,125, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 21:59:16,518, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 21:59:18,086, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 21:59:18,087, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 21:59:19,814, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 21:59:19,846, data_transformation, INFO, Initiating the DataTransformation ]
[2024-12-13 21:59:19,847, data_transformation, INFO, Initiatig data transformation pipeline ]
[2024-12-13 21:59:21,214, data_transformation, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 21:59:21,218, data_transformation, INFO, Error in initiating the data transformation pipeline __init__() should return None, not 'remove_stop_words' ]
[2024-12-13 22:01:57,000, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:01:57,002, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:01:57,004, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:01:57,006, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:01:57,347, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:01:58,915, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:01:58,916, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:02:00,664, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:02:36,126, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:02:36,127, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:02:36,130, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:02:36,132, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:02:36,450, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:02:37,886, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:02:37,887, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:02:39,654, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:04:29,583, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:04:29,585, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:04:29,586, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:04:29,588, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:04:29,972, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:04:31,756, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:04:31,757, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:04:33,422, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:04:33,454, data_transformation, INFO, Initiating the DataTransformation ]
[2024-12-13 22:12:28,530, 882292963, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:12:28,532, 882292963, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:12:28,534, 882292963, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:12:28,883, 882292963, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:13:02,110, 1772344484, INFO, Initiating data ingestion ]
[2024-12-13 22:13:02,111, 882292963, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:13:02,113, 882292963, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:13:02,115, 882292963, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:13:02,461, 882292963, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:13:18,097, 3806098344, INFO, Initiating data ingestion ]
[2024-12-13 22:13:18,099, 882292963, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:13:18,101, 882292963, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:13:18,102, 882292963, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:13:18,439, 882292963, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:13:20,028, 3806098344, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:13:20,029, 3806098344, INFO, Initiating train test split ]
[2024-12-13 22:13:21,763, 3806098344, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:14:07,876, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:14:07,877, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:14:07,880, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:14:07,881, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:14:08,255, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:14:09,961, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:14:09,962, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:14:11,611, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:14:11,644, data_transformation, INFO, Initiating the DataTransformation ]
[2024-12-13 22:14:59,118, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:14:59,120, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:14:59,121, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:14:59,123, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:14:59,445, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:15:00,889, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:15:00,889, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:15:02,493, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:15:02,526, data_transformation, INFO, Initiating the DataTransformation ]
[2024-12-13 22:16:26,607, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:16:26,609, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:16:26,610, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:16:26,611, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:16:27,004, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:16:28,528, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:16:28,529, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:16:30,240, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:16:30,272, data_transformation, INFO, Initiating the DataTransformation ]
[2024-12-13 22:16:30,273, data_transformation, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:16:31,794, data_transformation, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:16:31,798, data_transformation, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:16:31,799, data_transformation, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:16:31,800, utils, INFO, loading KeyedVectors object from C:\Users\karthikeya\New_Delhi_Reviews\ft_reviews_vectors.bin ]
[2024-12-13 22:16:31,814, data_transformation, INFO, Error loading Gensim Word2Vec model: unpickling stack underflow ]
[2024-12-13 22:16:31,816, data_transformation, INFO, Error in creating the preprocessing pipeline : unpickling stack underflow ]
[2024-12-13 22:16:31,817, data_transformation, INFO, Error in initiating the data transformation pipeline unpickling stack underflow ]
[2024-12-13 22:17:47,939, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:17:47,940, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:17:47,942, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:17:47,944, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:17:48,275, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:17:49,954, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:17:49,956, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:17:51,687, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:17:51,716, data_transformation, INFO, Initiating the DataTransformation ]
[2024-12-13 22:17:51,717, data_transformation, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:17:53,195, data_transformation, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:17:53,196, data_transformation, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:17:53,198, data_transformation, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:17:53,199, utils, INFO, loading KeyedVectors object from C:\Users\karthikeya\New_Delhi_Reviews\ft_reviews_vectors.bin ]
[2024-12-13 22:17:53,200, data_transformation, INFO, Error loading Gensim Word2Vec model: unpickling stack underflow ]
[2024-12-13 22:17:53,201, data_transformation, INFO, Error in creating the preprocessing pipeline : unpickling stack underflow ]
[2024-12-13 22:17:53,203, data_transformation, INFO, Error in initiating the data transformation pipeline unpickling stack underflow ]
[2024-12-13 22:19:55,247, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:19:55,249, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:19:55,252, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:19:55,252, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:19:55,660, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:19:57,458, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:19:57,459, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:19:59,236, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:19:59,260, 4064193279, INFO, Initiating the DataTransformation ]
[2024-12-13 22:20:18,089, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:20:18,090, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:20:18,092, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:20:18,093, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:20:18,447, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:20:19,924, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:20:19,926, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:20:21,646, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:20:21,672, 2999778935, INFO, Initiating the DataTransformation ]
[2024-12-13 22:20:21,674, 2999778935, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:20:23,176, 308188128, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:20:23,178, 2999778935, INFO, Error in initiating the data transformation pipeline __init__() should return None, not 'remove_stop_words' ]
[2024-12-13 22:21:19,331, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:21:19,333, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:21:19,334, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:21:19,335, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:21:19,737, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:21:21,375, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:21:21,376, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:21:22,825, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:21:22,854, 2999778935, INFO, Initiating the DataTransformation ]
[2024-12-13 22:21:22,856, 2999778935, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:21:24,378, 4224321577, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:21:24,380, 4224321577, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:21:24,381, 4224321577, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:21:24,381, utils, INFO, loading KeyedVectors object from ft_reviews_vectors.model ]
[2024-12-13 22:21:24,383, 4224321577, INFO, Error loading Gensim Word2Vec model: [Errno 2] No such file or directory: 'ft_reviews_vectors.model' ]
[2024-12-13 22:21:24,383, 2999778935, INFO, Error in initiating the data transformation pipeline [Errno 2] No such file or directory: 'ft_reviews_vectors.model' ]
[2024-12-13 22:21:58,290, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:21:58,292, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:21:58,293, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:21:58,295, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:21:58,640, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:22:00,200, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:22:00,201, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:22:01,697, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:22:01,725, 2999778935, INFO, Initiating the DataTransformation ]
[2024-12-13 22:22:01,726, 2999778935, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:22:03,271, 2030179346, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:22:03,273, 2030179346, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:22:03,274, 2030179346, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:22:03,275, utils, INFO, loading KeyedVectors object from ft_reviews_vectors.bin ]
[2024-12-13 22:22:03,277, 2030179346, INFO, Error loading Gensim Word2Vec model: unpickling stack underflow ]
[2024-12-13 22:22:03,277, 2999778935, INFO, Error in initiating the data transformation pipeline unpickling stack underflow ]
[2024-12-13 22:23:04,230, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:23:04,232, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:23:04,233, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:23:04,235, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:23:04,567, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:23:06,150, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:23:06,151, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:23:07,908, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:23:07,932, 2999778935, INFO, Initiating the DataTransformation ]
[2024-12-13 22:23:07,934, 2999778935, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:23:09,415, 3260265656, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:23:09,416, 3260265656, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:23:09,417, 3260265656, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:23:09,419, 3260265656, INFO, Error loading Gensim Word2Vec model: load() got an unexpected keyword argument 'binary' ]
[2024-12-13 22:23:09,420, 2999778935, INFO, Error in initiating the data transformation pipeline load() got an unexpected keyword argument 'binary' ]
[2024-12-13 22:24:14,717, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:24:14,718, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:24:14,720, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:24:14,721, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:24:15,138, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:24:16,830, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:24:16,831, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:24:18,311, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:24:18,335, 2999778935, INFO, Initiating the DataTransformation ]
[2024-12-13 22:24:18,337, 2999778935, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:24:19,614, 1131251720, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:24:19,615, 1131251720, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:24:19,616, 1131251720, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:24:19,617, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:24:21,957, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:24:21.957954', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:24:21,958, 2999778935, INFO, Numerical and text pipelines created ]
[2024-12-13 22:24:21,968, 1131251720, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:24:21,971, 1131251720, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:24:21,973, 1131251720, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:24:21,974, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:24:24,007, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:24:24.007432', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:24:24,032, 1131251720, INFO, Transforming all the letters into lowercase ]
[2024-12-13 22:24:24,039, 1131251720, INFO, Error in pre-processing the text: 'Series' object has no attribute 'lower' ]
[2024-12-13 22:24:24,040, 2999778935, INFO, Error in initiating the data transformation pipeline 'Series' object has no attribute 'lower' ]
[2024-12-13 22:26:36,712, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:26:36,713, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:26:36,716, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:26:36,717, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:26:37,055, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:26:38,690, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:26:38,691, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:26:40,169, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:26:40,192, 2999778935, INFO, Initiating the DataTransformation ]
[2024-12-13 22:26:40,192, 2999778935, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:26:41,675, 4064944957, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:26:41,677, 4064944957, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:26:41,678, 4064944957, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:26:41,678, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:26:44,227, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:26:44.227965', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:26:44,229, 2999778935, INFO, Numerical and text pipelines created ]
[2024-12-13 22:26:44,233, 4064944957, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:26:44,235, 4064944957, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:26:44,236, 4064944957, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:26:44,237, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:26:46,508, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:26:46.508872', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:26:46,526, 4064944957, INFO, Transforming all the letters into lowercase ]
[2024-12-13 22:26:46,527, 4064944957, INFO, Error in pre-processing the text: 'DataFrame' object has no attribute 'str' ]
[2024-12-13 22:26:46,528, 2999778935, INFO, Error in initiating the data transformation pipeline 'DataFrame' object has no attribute 'str' ]
[2024-12-13 22:27:08,736, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:27:08,738, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:27:08,740, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:27:08,741, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:27:09,162, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:27:10,755, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:27:10,756, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:27:14,416, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:27:14,435, 2999778935, INFO, Initiating the DataTransformation ]
[2024-12-13 22:27:14,436, 2999778935, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:27:15,731, 110027380, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:27:15,732, 110027380, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:27:15,733, 110027380, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:27:15,734, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:27:19,490, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:27:19.490049', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:27:19,491, 2999778935, INFO, Numerical and text pipelines created ]
[2024-12-13 22:27:19,495, 110027380, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:27:19,497, 110027380, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:27:19,498, 110027380, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:27:19,499, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:27:21,539, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:27:21.539103', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:27:21,556, 110027380, INFO, Transforming all the letters into lowercase ]
[2024-12-13 22:27:21,667, 110027380, INFO, Transforming all letters into lowercase is successful ]
[2024-12-13 22:27:21,669, 110027380, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-13 22:27:21,670, 110027380, INFO, Error in pre-processing the text: 'Series' object has no attribute 'split' ]
[2024-12-13 22:27:21,671, 2999778935, INFO, Error in initiating the data transformation pipeline 'Series' object has no attribute 'split' ]
[2024-12-13 22:27:49,751, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:27:49,753, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:27:49,755, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:27:49,756, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:27:50,107, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:27:52,628, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:27:52,631, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:27:54,704, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:27:54,725, 2999778935, INFO, Initiating the DataTransformation ]
[2024-12-13 22:27:54,726, 2999778935, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:27:56,034, 3199597980, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:27:56,036, 3199597980, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:27:56,036, 3199597980, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:27:56,037, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:27:58,191, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:27:58.191380', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:27:58,192, 2999778935, INFO, Numerical and text pipelines created ]
[2024-12-13 22:27:58,194, 3199597980, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:27:58,196, 3199597980, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:27:58,197, 3199597980, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:27:58,199, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:28:00,322, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:28:00.322681', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:28:00,344, 3199597980, INFO, Transforming all the letters into lowercase ]
[2024-12-13 22:28:00,481, 3199597980, INFO, Transforming all letters into lowercase is successful ]
[2024-12-13 22:28:00,482, 3199597980, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-13 22:28:01,822, 3199597980, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-13 22:28:01,824, 3199597980, INFO, Removing punctuations from text ]
[2024-12-13 22:28:01,825, 3199597980, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-13 22:28:01,825, 2999778935, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-13 22:32:07,308, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:32:07,311, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:32:07,312, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:32:07,313, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:32:07,628, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:32:09,141, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:32:09,142, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:32:10,664, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:32:10,686, 2999778935, INFO, Initiating the DataTransformation ]
[2024-12-13 22:32:10,688, 2999778935, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:32:12,217, 2935546167, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:32:12,218, 2935546167, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:32:12,219, 2935546167, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:32:12,220, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:32:14,618, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:32:14.618451', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:32:14,619, 2999778935, INFO, Numerical and text pipelines created ]
[2024-12-13 22:32:14,623, 2935546167, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:32:14,624, 2935546167, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:32:14,626, 2935546167, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:32:14,627, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:32:16,825, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:32:16.825572', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:32:16,841, 2935546167, INFO, Transforming all the letters into lowercase ]
[2024-12-13 22:32:16,843, 2935546167, INFO, Error in pre-processing the text: 'DataFrame' object has no attribute 'str' ]
[2024-12-13 22:32:16,844, 2999778935, INFO, Error in initiating the data transformation pipeline 'DataFrame' object has no attribute 'str' ]
[2024-12-13 22:35:08,652, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:35:08,654, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:35:08,656, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:35:08,657, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:35:08,998, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:35:10,587, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:35:10,589, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:35:12,209, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:35:12,232, 2999778935, INFO, Initiating the DataTransformation ]
[2024-12-13 22:35:12,233, 2999778935, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:35:13,797, 967265483, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:35:13,799, 967265483, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:35:13,800, 967265483, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:35:13,801, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:35:16,156, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:35:16.156866', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:35:16,157, 2999778935, INFO, Numerical and text pipelines created ]
[2024-12-13 22:35:16,161, 967265483, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:35:16,162, 967265483, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:35:16,163, 967265483, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:35:16,164, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:35:18,302, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:35:18.302976', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:35:18,317, 967265483, INFO, Transforming all the letters into lowercase ]
[2024-12-13 22:35:18,418, 967265483, INFO, Transforming all letters into lowercase is successful ]
[2024-12-13 22:35:18,419, 967265483, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-13 22:35:19,390, 967265483, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-13 22:35:19,391, 967265483, INFO, Removing punctuations from text ]
[2024-12-13 22:35:19,392, 967265483, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-13 22:35:19,394, 2999778935, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-13 22:36:38,288, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:36:38,290, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:36:38,292, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:36:38,294, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:36:38,608, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:36:40,167, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:36:40,168, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:36:41,758, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:36:41,775, 2999778935, INFO, Initiating the DataTransformation ]
[2024-12-13 22:36:41,776, 2999778935, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:36:43,295, 184367788, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:36:43,297, 184367788, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:36:43,298, 184367788, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:36:43,299, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:36:45,662, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:36:45.662913', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:36:45,663, 2999778935, INFO, Numerical and text pipelines created ]
[2024-12-13 22:36:45,666, 184367788, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:36:45,668, 184367788, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:36:45,669, 184367788, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:36:45,671, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:36:48,066, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:36:48.066273', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:36:48,085, 184367788, INFO, Transforming all the letters into lowercase ]
[2024-12-13 22:36:48,188, 184367788, INFO, Transforming all letters into lowercase is successful ]
[2024-12-13 22:36:48,189, 184367788, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-13 22:36:49,218, 184367788, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-13 22:36:49,220, 184367788, INFO, Removing punctuations from text ]
[2024-12-13 22:36:49,223, 184367788, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-13 22:36:49,224, 2999778935, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-13 22:38:05,246, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:38:05,248, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:38:05,250, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:38:05,251, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:38:05,647, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:38:07,194, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:38:07,196, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:38:08,666, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:38:08,687, 2999778935, INFO, Initiating the DataTransformation ]
[2024-12-13 22:38:08,688, 2999778935, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:38:10,234, 772459225, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:38:10,236, 772459225, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:38:10,237, 772459225, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:38:10,237, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:38:12,665, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:38:12.665305', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:38:12,666, 2999778935, INFO, Numerical and text pipelines created ]
[2024-12-13 22:38:12,669, 772459225, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:38:12,670, 772459225, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:38:12,671, 772459225, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:38:12,672, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:38:14,814, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:38:14.814557', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:38:14,832, 772459225, INFO, Transforming all the letters into lowercase ]
[2024-12-13 22:38:14,951, 772459225, INFO, Transforming all letters into lowercase is successful ]
[2024-12-13 22:38:14,952, 772459225, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-13 22:38:16,660, 772459225, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-13 22:38:16,661, 772459225, INFO, Removing punctuations from text ]
[2024-12-13 22:38:16,888, 772459225, INFO, Removing punctuations from text successful ]
[2024-12-13 22:38:16,889, 772459225, INFO, Removing the stopwords from the tokenized words ]
[2024-12-13 22:38:16,891, 772459225, INFO, Error in pre-processing the text: Length of values (0) does not match length of index (1) ]
[2024-12-13 22:38:16,893, 2999778935, INFO, Error in initiating the data transformation pipeline Length of values (0) does not match length of index (1) ]
[2024-12-13 22:39:57,573, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:39:57,574, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:39:57,576, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:39:57,577, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:39:57,902, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:39:59,632, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:39:59,634, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:40:01,422, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:40:01,444, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-13 22:40:01,445, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:40:02,939, 772459225, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:40:02,941, 772459225, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:40:02,942, 772459225, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:40:02,943, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:40:05,260, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:40:05.260278', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:40:05,261, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-13 22:40:05,264, 772459225, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:40:05,266, 772459225, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:40:05,267, 772459225, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:40:05,268, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:40:07,381, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:40:07.381597', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:40:07,396, 772459225, INFO, Transforming all the letters into lowercase ]
[2024-12-13 22:40:07,486, 772459225, INFO, Transforming all letters into lowercase is successful ]
[2024-12-13 22:40:07,487, 772459225, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-13 22:40:08,839, 772459225, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-13 22:40:08,841, 772459225, INFO, Removing punctuations from text ]
[2024-12-13 22:40:09,067, 772459225, INFO, Removing punctuations from text successful ]
[2024-12-13 22:40:09,068, 772459225, INFO, Removing the stopwords from the tokenized words ]
[2024-12-13 22:40:09,070, 772459225, INFO, Error in pre-processing the text: Length of values (0) does not match length of index (1) ]
[2024-12-13 22:40:09,070, 3413596454, INFO, Error in initiating the data transformation pipeline Length of values (0) does not match length of index (1) ]
[2024-12-13 22:42:29,477, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:42:29,479, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:42:29,481, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:42:29,482, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:42:29,801, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:42:31,526, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:42:31,528, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:42:33,287, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:42:33,303, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-13 22:42:33,304, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:42:34,687, 184367788, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:42:34,689, 184367788, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:42:34,689, 184367788, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:42:34,690, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:42:36,995, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:42:36.995705', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:42:36,996, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-13 22:42:36,999, 184367788, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:42:37,001, 184367788, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:42:37,002, 184367788, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:42:37,003, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:42:39,316, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:42:39.316486', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:42:39,338, 184367788, INFO, Transforming all the letters into lowercase ]
[2024-12-13 22:42:39,443, 184367788, INFO, Transforming all letters into lowercase is successful ]
[2024-12-13 22:42:39,444, 184367788, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-13 22:42:40,751, 184367788, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-13 22:42:40,752, 184367788, INFO, Removing punctuations from text ]
[2024-12-13 22:42:40,754, 184367788, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-13 22:42:40,755, 3413596454, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-13 22:43:04,234, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:43:04,236, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:43:04,238, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:43:04,240, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:43:04,577, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:43:06,652, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:43:06,660, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:43:10,113, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:43:10,138, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-13 22:43:10,140, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:43:11,695, 184367788, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:43:11,697, 184367788, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:43:11,698, 184367788, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:43:11,699, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:43:15,701, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:43:15.700440', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:43:15,702, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-13 22:43:15,706, 184367788, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:43:15,708, 184367788, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:43:15,708, 184367788, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:43:15,710, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:43:18,026, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:43:18.026182', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:43:18,043, 184367788, INFO, Transforming all the letters into lowercase ]
[2024-12-13 22:43:18,146, 184367788, INFO, Transforming all letters into lowercase is successful ]
[2024-12-13 22:43:18,147, 184367788, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-13 22:43:19,168, 184367788, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-13 22:43:19,170, 184367788, INFO, Removing punctuations from text ]
[2024-12-13 22:43:19,172, 184367788, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-13 22:43:19,174, 3413596454, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-13 22:43:30,025, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:43:30,026, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:43:30,028, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:43:30,030, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:43:30,377, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:43:32,014, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:43:32,015, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:43:33,721, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:43:33,742, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-13 22:43:33,744, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:43:35,129, 772459225, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:43:35,132, 772459225, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:43:35,133, 772459225, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:43:35,134, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:43:37,593, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:43:37.593240', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:43:37,595, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-13 22:43:37,598, 772459225, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:43:37,600, 772459225, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:43:37,602, 772459225, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:43:37,603, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:43:39,848, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:43:39.848682', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:43:39,865, 772459225, INFO, Transforming all the letters into lowercase ]
[2024-12-13 22:43:39,972, 772459225, INFO, Transforming all letters into lowercase is successful ]
[2024-12-13 22:43:39,973, 772459225, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-13 22:43:41,520, 772459225, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-13 22:43:41,522, 772459225, INFO, Removing punctuations from text ]
[2024-12-13 22:43:41,723, 772459225, INFO, Removing punctuations from text successful ]
[2024-12-13 22:43:41,724, 772459225, INFO, Removing the stopwords from the tokenized words ]
[2024-12-13 22:43:41,727, 772459225, INFO, Error in pre-processing the text: Length of values (0) does not match length of index (1) ]
[2024-12-13 22:43:41,728, 3413596454, INFO, Error in initiating the data transformation pipeline Length of values (0) does not match length of index (1) ]
[2024-12-13 22:45:11,016, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:45:11,018, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:45:11,020, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:45:11,020, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:45:11,329, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:45:12,925, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:45:12,926, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:45:14,661, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:45:14,678, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-13 22:45:14,679, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:45:16,209, 4093102912, INFO, Getting set of stopwords from NLTK for English language ]
[2024-12-13 22:45:16,211, 772459225, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:45:16,212, 772459225, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:45:16,212, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:45:18,491, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:45:18.491894', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:45:18,492, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-13 22:45:18,495, 4093102912, INFO, Getting set of stopwords from NLTK for English language ]
[2024-12-13 22:45:18,497, 772459225, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:45:18,498, 772459225, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:45:18,499, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:45:20,476, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:45:20.476589', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:45:20,495, 4093102912, INFO, Ensuring input is a pandas Series of strings ]
[2024-12-13 22:45:20,497, 4093102912, ERROR, Error in pre-processing the text: Input X must be a pandas Series ]
[2024-12-13 22:45:20,498, 3413596454, INFO, Error in initiating the data transformation pipeline Input X must be a pandas Series ]
[2024-12-13 22:47:23,481, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:47:23,483, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:47:23,485, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:47:23,487, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:47:23,855, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:47:27,424, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:47:27,425, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:47:29,064, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:47:29,087, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-13 22:47:29,088, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:47:30,649, 967265483, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:47:30,650, 967265483, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:47:30,651, 967265483, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:47:30,652, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:47:33,025, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:47:33.025997', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:47:33,026, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-13 22:47:33,030, 967265483, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:47:33,032, 967265483, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:47:33,033, 967265483, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:47:33,034, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:47:35,482, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:47:35.482468', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:47:35,501, 967265483, INFO, Transforming all the letters into lowercase ]
[2024-12-13 22:47:35,600, 967265483, INFO, Transforming all letters into lowercase is successful ]
[2024-12-13 22:47:35,602, 967265483, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-13 22:47:37,124, 967265483, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-13 22:47:37,125, 967265483, INFO, Removing punctuations from text ]
[2024-12-13 22:47:37,127, 967265483, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-13 22:47:37,128, 3413596454, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-13 22:48:20,059, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:48:20,061, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:48:20,063, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:48:20,065, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:48:20,490, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:48:22,376, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:48:22,377, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:48:23,827, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:48:23,848, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-13 22:48:23,850, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:48:25,409, 3416562058, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:48:25,411, 3416562058, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:48:25,412, 3416562058, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:48:25,413, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:48:27,878, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:48:27.878378', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:48:27,879, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-13 22:48:27,883, 3416562058, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:48:27,885, 3416562058, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:48:27,886, 3416562058, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:48:27,886, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:48:30,118, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:48:30.118691', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:48:30,134, 3416562058, INFO, Transforming all the letters into lowercase ]
[2024-12-13 22:48:30,227, 3416562058, INFO, Transforming all letters into lowercase is successful ]
[2024-12-13 22:48:30,228, 3416562058, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-13 22:48:31,137, 3416562058, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-13 22:48:31,139, 3416562058, INFO, Removing punctuations from text ]
[2024-12-13 22:48:31,140, 3416562058, INFO, Error in pre-processing the text: type object 'str' has no attribute 'x' ]
[2024-12-13 22:48:31,140, 3413596454, INFO, Error in initiating the data transformation pipeline type object 'str' has no attribute 'x' ]
[2024-12-13 22:49:04,487, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-13 22:49:04,489, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-13 22:49:04,491, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-13 22:49:04,493, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-13 22:49:04,842, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-13 22:49:06,428, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-13 22:49:06,429, data_ingestion, INFO, Initiating train test split ]
[2024-12-13 22:49:09,285, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-13 22:49:09,349, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-13 22:49:09,355, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-13 22:49:10,904, 1679785480, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:49:10,907, 1679785480, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:49:10,908, 1679785480, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:49:10,909, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:49:17,720, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:49:17.720339', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:49:17,721, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-13 22:49:17,726, 1679785480, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-13 22:49:17,729, 1679785480, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-13 22:49:17,731, 1679785480, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-13 22:49:17,732, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-13 22:49:19,697, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-13T22:49:19.697043', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-13 22:49:19,713, 1679785480, INFO, Transforming all the letters into lowercase ]
[2024-12-13 22:49:19,816, 1679785480, INFO, Transforming all letters into lowercase is successful ]
[2024-12-13 22:49:19,817, 1679785480, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-13 22:49:21,278, 1679785480, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-13 22:49:21,279, 1679785480, INFO, Removing punctuations from text ]
[2024-12-13 22:49:21,285, 1679785480, INFO, Error in pre-processing the text: 'StringMethods' object is not iterable ]
[2024-12-13 22:49:21,286, 3413596454, INFO, Error in initiating the data transformation pipeline 'StringMethods' object is not iterable ]
[2024-12-14 11:11:20,720, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:11:20,722, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:11:20,724, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:11:20,726, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:11:21,070, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:11:22,588, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:11:22,590, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:11:24,067, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:11:24,088, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-14 11:11:24,089, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:11:25,428, 3818907554, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:11:25,430, 3818907554, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:11:25,431, 3818907554, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:11:25,432, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:11:27,648, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:11:27.648857', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:11:27,650, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-14 11:11:27,653, 3818907554, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:11:27,654, 3818907554, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:11:27,655, 3818907554, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:11:27,656, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:11:29,641, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:11:29.641965', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:11:29,655, 3818907554, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:11:29,751, 3818907554, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 11:11:29,752, 3818907554, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 11:11:31,353, 3818907554, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 11:11:31,358, 3818907554, INFO, Removing punctuations from text ]
[2024-12-14 11:11:31,359, 3818907554, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-14 11:11:31,360, 3413596454, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-14 11:12:02,368, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:12:02,370, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:12:02,372, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:12:02,373, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:12:02,692, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:12:04,142, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:12:04,143, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:12:05,705, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:12:05,740, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-14 11:12:05,742, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:12:07,270, 480795491, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:12:07,273, 480795491, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:12:07,274, 480795491, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:12:07,275, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:12:10,495, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:12:10.495953', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:12:10,496, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-14 11:12:10,501, 480795491, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:12:10,504, 480795491, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:12:10,505, 480795491, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:12:10,505, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:12:13,123, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:12:13.123929', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:12:13,139, 480795491, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:12:13,236, 480795491, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 11:12:13,238, 480795491, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 11:12:14,388, 480795491, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 11:12:14,389, 480795491, INFO, Removing punctuations from text ]
[2024-12-14 11:12:14,390, 480795491, INFO, Error in pre-processing the text: 'Series' object has no attribute 'split' ]
[2024-12-14 11:12:14,391, 3413596454, INFO, Error in initiating the data transformation pipeline 'Series' object has no attribute 'split' ]
[2024-12-14 11:13:07,074, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:13:07,075, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:13:07,077, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:13:07,078, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:13:07,433, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:13:09,042, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:13:09,043, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:13:10,522, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:13:10,543, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-14 11:13:10,545, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:13:11,949, 1515147130, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:13:11,950, 1515147130, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:13:11,952, 1515147130, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:13:11,953, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:13:14,234, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:13:14.234566', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:13:14,235, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-14 11:13:14,239, 1515147130, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:13:14,240, 1515147130, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:13:14,241, 1515147130, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:13:14,242, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:13:16,307, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:13:16.307023', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:13:16,323, 1515147130, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:13:16,436, 1515147130, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 11:13:16,437, 1515147130, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 11:13:18,307, 1515147130, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 11:13:18,308, 1515147130, INFO, Removing punctuations from text ]
[2024-12-14 11:13:18,309, 1515147130, INFO, Error in pre-processing the text: 'DataFrame' object has no attribute 'str' ]
[2024-12-14 11:13:18,310, 3413596454, INFO, Error in initiating the data transformation pipeline 'DataFrame' object has no attribute 'str' ]
[2024-12-14 11:14:24,339, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:14:24,341, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:14:24,342, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:14:24,343, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:14:24,667, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:14:26,215, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:14:26,216, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:14:27,716, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:14:27,738, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-14 11:14:27,739, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:14:29,170, 3818907554, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:14:29,172, 3818907554, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:14:29,174, 3818907554, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:14:29,175, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:14:31,443, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:14:31.443879', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:14:31,444, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-14 11:14:31,447, 3818907554, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:14:31,449, 3818907554, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:14:31,450, 3818907554, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:14:31,452, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:14:33,533, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:14:33.533691', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:14:33,552, 3818907554, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:14:33,646, 3818907554, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 11:14:33,648, 3818907554, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 11:14:35,292, 3818907554, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 11:14:35,293, 3818907554, INFO, Removing punctuations from text ]
[2024-12-14 11:14:35,294, 3818907554, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-14 11:14:35,296, 3413596454, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-14 11:16:08,186, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:16:08,188, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:16:08,189, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:16:08,190, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:16:08,509, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:16:10,140, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:16:10,141, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:16:11,726, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:16:11,748, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-14 11:16:11,748, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:16:13,185, 3851500527, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:16:13,187, 3851500527, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:16:13,187, 3851500527, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:16:13,189, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:16:15,595, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:16:15.595754', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:16:15,596, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-14 11:16:15,600, 3851500527, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:16:15,602, 3851500527, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:16:15,602, 3851500527, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:16:15,604, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:16:17,610, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:16:17.610522', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:16:17,626, 3851500527, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:16:17,713, 3851500527, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 11:16:17,714, 3851500527, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 11:16:18,541, 3851500527, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 11:16:18,543, 3851500527, INFO, Error in pre-processing the text: name 'X_' is not defined ]
[2024-12-14 11:16:18,543, 3413596454, INFO, Error in initiating the data transformation pipeline name 'X_' is not defined ]
[2024-12-14 11:16:38,298, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:16:38,300, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:16:38,301, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:16:38,302, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:16:38,626, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:16:40,081, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:16:40,082, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:16:41,641, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:16:41,662, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-14 11:16:41,663, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:16:43,092, 3356500986, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:16:43,094, 3356500986, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:16:43,095, 3356500986, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:16:43,096, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:16:45,371, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:16:45.371686', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:16:45,372, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-14 11:16:45,375, 3356500986, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:16:45,377, 3356500986, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:16:45,378, 3356500986, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:16:45,379, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:16:47,640, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:16:47.640617', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:16:47,655, 3356500986, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:16:47,763, 3356500986, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 11:16:47,764, 3356500986, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 11:16:49,826, 3356500986, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 11:16:49,836, 3356500986, INFO, Removing punctuations from text ]
[2024-12-14 11:16:49,837, 3356500986, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-14 11:16:49,838, 3413596454, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-14 11:17:36,336, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:17:36,338, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:17:36,341, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:17:36,343, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:17:36,692, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:17:38,286, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:17:38,287, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:17:39,928, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:17:39,947, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-14 11:17:39,948, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:17:41,234, 3200035017, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:17:41,246, 3200035017, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:17:41,247, 3200035017, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:17:41,248, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:17:43,509, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:17:43.509513', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:17:43,511, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-14 11:17:43,514, 3200035017, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:17:43,515, 3200035017, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:17:43,516, 3200035017, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:17:43,517, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:17:45,489, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:17:45.489555', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:17:45,504, 3200035017, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:17:45,594, 3200035017, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 11:17:45,595, 3200035017, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 11:17:46,429, 3200035017, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 11:17:46,434, 3200035017, INFO, Removing punctuations from text ]
[2024-12-14 11:17:46,435, 3200035017, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-14 11:17:46,435, 3413596454, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-14 11:18:21,127, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:18:21,128, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:18:21,130, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:18:21,131, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:18:21,484, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:18:23,146, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:18:23,147, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:18:24,757, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:18:24,777, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-14 11:18:24,779, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:18:26,160, 3601916054, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:18:26,162, 3601916054, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:18:26,163, 3601916054, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:18:26,164, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:18:28,509, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:18:28.509307', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:18:28,510, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-14 11:18:28,513, 3601916054, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:18:28,515, 3601916054, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:18:28,516, 3601916054, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:18:28,516, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:18:30,516, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:18:30.516964', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:18:30,532, 3601916054, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:18:30,627, 3601916054, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 11:18:30,628, 3601916054, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 11:18:32,617, 3601916054, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 11:18:32,624, 3601916054, INFO, Removing punctuations from text ]
[2024-12-14 11:18:32,625, 3601916054, INFO, Error in pre-processing the text: name 'word' is not defined ]
[2024-12-14 11:18:32,627, 3413596454, INFO, Error in initiating the data transformation pipeline name 'word' is not defined ]
[2024-12-14 11:19:53,457, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:19:53,458, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:19:53,460, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:19:53,461, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:19:53,789, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:19:55,411, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:19:55,412, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:19:56,867, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:19:56,888, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-14 11:19:56,890, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:19:58,254, 4106890872, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:19:58,256, 4106890872, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:19:58,257, 4106890872, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:19:58,257, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:20:00,535, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:20:00.535085', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:20:00,537, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-14 11:20:00,539, 4106890872, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:20:00,541, 4106890872, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:20:00,542, 4106890872, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:20:00,543, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:20:02,720, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:20:02.720719', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:20:02,736, 4106890872, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:20:02,737, 4106890872, INFO, Error in pre-processing the text: 'Series' object has no attribute 'lower' ]
[2024-12-14 11:20:02,739, 3413596454, INFO, Error in initiating the data transformation pipeline 'Series' object has no attribute 'lower' ]
[2024-12-14 11:22:20,731, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:22:20,733, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:22:20,734, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:22:20,735, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:22:21,121, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:22:22,756, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:22:22,757, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:22:24,196, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:22:24,218, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-14 11:22:24,219, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:22:25,535, 1953441227, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:22:25,537, 1953441227, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:22:25,537, 1953441227, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:22:25,538, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:22:27,821, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:22:27.821531', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:22:27,822, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-14 11:22:27,826, 1953441227, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:22:27,828, 1953441227, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:22:27,829, 1953441227, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:22:27,829, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:22:29,877, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:22:29.877036', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:22:29,893, 1953441227, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:22:29,894, 1953441227, INFO, Error in pre-processing the text: 'Series' object has no attribute 'lower' ]
[2024-12-14 11:22:29,895, 3413596454, INFO, Error in initiating the data transformation pipeline 'Series' object has no attribute 'lower' ]
[2024-12-14 11:22:56,279, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:22:56,280, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:22:56,282, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:22:56,283, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:22:56,649, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:22:58,371, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:22:58,372, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:22:59,840, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:22:59,860, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-14 11:22:59,862, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:23:01,227, 397639816, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:23:01,229, 397639816, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:23:01,230, 397639816, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:23:01,231, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:23:03,513, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:23:03.513239', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:23:03,514, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-14 11:23:03,517, 397639816, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:23:03,519, 397639816, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:23:03,520, 397639816, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:23:03,521, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:23:05,525, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:23:05.524876', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:23:05,540, 397639816, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:23:05,634, 397639816, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 11:23:05,636, 397639816, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 11:23:06,490, 397639816, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 11:23:06,495, 397639816, INFO, Removing punctuations from text ]
[2024-12-14 11:23:06,496, 397639816, INFO, Error in pre-processing the text: 'Series' object has no attribute 'translate' ]
[2024-12-14 11:23:06,497, 3413596454, INFO, Error in initiating the data transformation pipeline 'Series' object has no attribute 'translate' ]
[2024-12-14 11:24:15,425, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:24:15,427, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:24:15,428, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:24:15,429, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:24:15,803, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:24:17,559, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:24:17,561, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:24:19,022, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:24:19,044, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-14 11:24:19,046, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:24:20,437, 397639816, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:24:20,439, 397639816, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:24:20,440, 397639816, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:24:20,441, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:24:22,677, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:24:22.677899', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:24:22,679, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-14 11:24:22,681, 397639816, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:24:22,683, 397639816, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:24:22,684, 397639816, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:24:22,685, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:24:24,653, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:24:24.653200', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:24:24,669, 397639816, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:24:24,771, 397639816, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 11:24:24,773, 397639816, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 11:24:26,901, 397639816, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 11:24:26,905, 397639816, INFO, Removing punctuations from text ]
[2024-12-14 11:24:26,907, 397639816, INFO, Error in pre-processing the text: 'Series' object has no attribute 'translate' ]
[2024-12-14 11:24:26,907, 3413596454, INFO, Error in initiating the data transformation pipeline 'Series' object has no attribute 'translate' ]
[2024-12-14 11:25:06,711, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:25:06,713, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:25:06,714, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:25:06,715, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:25:07,042, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:25:08,778, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:25:08,780, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:25:10,298, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:25:10,318, 3413596454, INFO, Initiating the DataTransformation ]
[2024-12-14 11:25:10,321, 3413596454, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:25:11,647, 2398587094, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:25:11,649, 2398587094, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:25:11,649, 2398587094, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:25:11,651, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:25:13,999, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:25:13.999896', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:25:14,000, 3413596454, INFO, Numerical and text pipelines created ]
[2024-12-14 11:25:14,004, 2398587094, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:25:14,005, 2398587094, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:25:14,006, 2398587094, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:25:14,007, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:25:16,160, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:25:16.160916', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:25:16,176, 2398587094, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:25:16,267, 2398587094, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 11:25:16,268, 2398587094, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 11:25:17,193, 2398587094, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 11:25:17,198, 2398587094, INFO, Removing punctuations from text ]
[2024-12-14 11:25:17,327, 2398587094, INFO, Removing punctuations from text successful ]
[2024-12-14 11:25:17,328, 2398587094, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 11:25:17,362, 2398587094, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 11:25:17,363, 2398587094, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 11:25:22,654, 2398587094, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 11:25:22,655, 3413596454, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 11:28:54,532, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:28:54,534, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:28:54,535, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:28:54,537, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:28:54,871, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:28:56,496, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:28:56,497, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:28:58,257, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:28:58,279, 1674846216, INFO, Initiating the DataTransformation ]
[2024-12-14 11:28:58,281, 1674846216, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:28:59,831, 2398587094, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:28:59,833, 2398587094, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:28:59,834, 2398587094, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:28:59,835, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:29:02,165, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:29:02.165467', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:29:02,167, 1674846216, INFO, Numerical and text pipelines created ]
[2024-12-14 11:29:02,170, 2398587094, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:29:02,171, 2398587094, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:29:02,172, 2398587094, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:29:02,174, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:29:04,373, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:29:04.373556', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:29:04,389, 2398587094, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:29:04,481, 2398587094, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 11:29:04,482, 2398587094, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 11:29:05,345, 2398587094, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 11:29:05,350, 2398587094, INFO, Removing punctuations from text ]
[2024-12-14 11:29:05,470, 2398587094, INFO, Removing punctuations from text successful ]
[2024-12-14 11:29:05,471, 2398587094, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 11:29:05,502, 2398587094, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 11:29:05,504, 2398587094, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 11:29:05,505, 2398587094, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 11:29:05,508, 1674846216, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 11:32:51,821, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:32:51,823, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:32:51,825, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:32:51,826, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:32:52,156, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:32:53,897, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:32:53,898, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:32:55,441, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:32:55,463, 1674846216, INFO, Initiating the DataTransformation ]
[2024-12-14 11:32:55,464, 1674846216, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:32:56,836, 2398587094, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:32:56,837, 2398587094, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:32:56,838, 2398587094, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:32:56,839, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:32:59,117, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:32:59.117292', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:32:59,118, 1674846216, INFO, Numerical and text pipelines created ]
[2024-12-14 11:32:59,122, 2398587094, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:32:59,123, 2398587094, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:32:59,124, 2398587094, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:32:59,124, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:33:01,171, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:33:01.171435', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:33:01,187, 2398587094, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:33:01,283, 2398587094, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 11:33:01,284, 2398587094, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 11:33:02,153, 2398587094, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 11:33:02,159, 2398587094, INFO, Removing punctuations from text ]
[2024-12-14 11:33:02,276, 2398587094, INFO, Removing punctuations from text successful ]
[2024-12-14 11:33:02,277, 2398587094, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 11:33:02,307, 2398587094, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 11:33:02,308, 2398587094, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 11:33:02,310, 2398587094, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 11:33:02,312, 1674846216, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 11:36:25,722, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:36:25,725, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:36:25,726, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:36:25,728, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:36:26,111, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:36:27,864, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:36:27,867, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:36:29,358, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:36:29,379, 1674846216, INFO, Initiating the DataTransformation ]
[2024-12-14 11:36:29,380, 1674846216, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:36:30,835, 4271229514, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:36:30,837, 4271229514, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:36:30,838, 4271229514, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:36:30,839, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:36:33,069, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:36:33.069750', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:36:33,070, 1674846216, INFO, Numerical and text pipelines created ]
[2024-12-14 11:36:33,073, 4271229514, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:36:33,075, 4271229514, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:36:33,076, 4271229514, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:36:33,076, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:36:35,170, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:36:35.170134', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:36:35,192, 4271229514, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:36:35,320, 4271229514, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 11:36:35,321, 4271229514, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 11:36:36,857, 4271229514, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 11:36:36,861, 4271229514, INFO, Removing punctuations from text ]
[2024-12-14 11:36:36,978, 4271229514, INFO, Removing punctuations from text successful ]
[2024-12-14 11:36:36,979, 4271229514, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 11:36:37,013, 4271229514, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 11:36:37,014, 4271229514, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 11:36:37,016, 4271229514, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 11:36:37,017, 1674846216, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 11:58:24,428, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 11:58:24,431, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 11:58:24,433, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 11:58:24,435, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 11:58:24,809, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 11:58:26,229, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 11:58:26,231, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 11:58:27,708, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 11:58:27,727, 1674846216, INFO, Initiating the DataTransformation ]
[2024-12-14 11:58:27,729, 1674846216, INFO, Initiatig data transformation pipeline ]
[2024-12-14 11:58:29,137, 2169316, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:58:29,139, 2169316, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:58:29,141, 2169316, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:58:29,141, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:58:31,155, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:58:31.155364', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:58:31,156, 1674846216, INFO, Numerical and text pipelines created ]
[2024-12-14 11:58:31,159, 2169316, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 11:58:31,161, 2169316, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 11:58:31,162, 2169316, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 11:58:31,164, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 11:58:33,165, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T11:58:33.165969', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 11:58:33,183, 2169316, INFO, Transforming all the letters into lowercase ]
[2024-12-14 11:58:33,269, 2169316, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 11:58:33,271, 2169316, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 11:58:34,083, 2169316, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 11:58:34,085, 2169316, INFO, Removing punctuations from text ]
[2024-12-14 11:58:34,203, 2169316, INFO, Removing punctuations from text successful ]
[2024-12-14 11:58:34,204, 2169316, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 11:58:34,233, 2169316, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 11:58:34,235, 2169316, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 11:58:34,237, 2169316, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 11:58:34,239, 1674846216, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 12:00:31,884, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 12:00:31,885, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 12:00:31,887, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 12:00:31,889, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 12:00:32,264, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 12:00:33,872, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 12:00:33,874, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 12:00:35,357, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 12:00:35,374, 1674846216, INFO, Initiating the DataTransformation ]
[2024-12-14 12:00:35,375, 1674846216, INFO, Initiatig data transformation pipeline ]
[2024-12-14 12:00:36,674, 1339007772, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:00:36,676, 1339007772, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:00:36,677, 1339007772, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:00:36,678, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:00:38,739, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:00:38.739253', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:00:38,740, 1674846216, INFO, Numerical and text pipelines created ]
[2024-12-14 12:00:38,743, 1339007772, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:00:38,745, 1339007772, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:00:38,746, 1339007772, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:00:38,748, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:00:40,814, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:00:40.813754', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:00:40,830, 1339007772, INFO, Transforming all the letters into lowercase ]
[2024-12-14 12:00:40,937, 1339007772, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 12:00:40,938, 1339007772, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 12:00:42,099, 1339007772, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 12:00:42,100, 1339007772, INFO, Removing punctuations from text ]
[2024-12-14 12:00:42,213, 1339007772, INFO, Removing punctuations from text successful ]
[2024-12-14 12:00:42,215, 1339007772, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 12:00:42,256, 1339007772, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 12:00:42,258, 1339007772, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 12:00:42,261, 1339007772, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 12:00:42,262, 1674846216, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 12:04:25,999, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 12:04:26,001, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 12:04:26,003, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 12:04:26,004, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 12:04:26,314, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 12:04:27,945, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 12:04:27,947, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 12:04:29,438, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 12:04:29,455, 1920069468, INFO, Initiating the DataTransformation ]
[2024-12-14 12:04:29,458, 1920069468, INFO, Initiatig data transformation pipeline ]
[2024-12-14 12:04:30,824, 1339007772, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:04:30,826, 1339007772, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:04:30,827, 1339007772, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:04:30,828, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:04:33,075, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:04:33.075223', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:04:33,077, 1920069468, INFO, Numerical and text pipelines created ]
[2024-12-14 12:04:33,094, 1339007772, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:04:33,096, 1339007772, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:04:33,097, 1339007772, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:04:33,099, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:04:35,206, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:04:35.206890', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:04:35,233, 1339007772, INFO, Transforming all the letters into lowercase ]
[2024-12-14 12:04:35,322, 1339007772, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 12:04:35,324, 1339007772, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 12:04:36,154, 1339007772, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 12:04:36,156, 1339007772, INFO, Removing punctuations from text ]
[2024-12-14 12:04:36,273, 1339007772, INFO, Removing punctuations from text successful ]
[2024-12-14 12:04:36,274, 1339007772, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 12:04:36,302, 1339007772, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 12:04:36,305, 1339007772, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 12:04:36,307, 1339007772, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 12:04:36,307, 1920069468, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 12:08:39,696, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 12:08:39,698, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 12:08:39,700, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 12:08:39,701, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 12:08:40,050, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 12:08:41,626, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 12:08:41,627, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 12:08:43,082, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 12:08:43,103, 1920069468, INFO, Initiating the DataTransformation ]
[2024-12-14 12:08:43,105, 1920069468, INFO, Initiatig data transformation pipeline ]
[2024-12-14 12:08:44,436, 3136698187, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:08:44,438, 3136698187, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:08:44,439, 3136698187, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:08:44,439, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:08:46,898, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:08:46.898135', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:08:46,899, 1920069468, INFO, Numerical and text pipelines created ]
[2024-12-14 12:08:46,912, 3136698187, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:08:46,913, 3136698187, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:08:46,915, 3136698187, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:08:46,916, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:08:48,918, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:08:48.918734', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:08:48,935, 3136698187, INFO, Transforming all the letters into lowercase ]
[2024-12-14 12:08:49,023, 3136698187, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 12:08:49,024, 3136698187, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 12:08:50,090, 3136698187, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 12:08:50,091, 3136698187, INFO, Removing punctuations from text ]
[2024-12-14 12:08:50,204, 3136698187, INFO, Removing punctuations from text successful ]
[2024-12-14 12:08:50,205, 3136698187, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 12:08:50,238, 3136698187, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 12:08:50,240, 3136698187, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 12:08:50,241, 3136698187, INFO, Lemmatization successful ]
[2024-12-14 12:08:50,243, 3136698187, INFO, Generating embeddings for the text data ]
[2024-12-14 12:08:50,244, 3136698187, INFO, Successfully generated embeddings ]
[2024-12-14 12:08:50,245, 1920069468, INFO, Error in initiating the data transformation pipeline Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead. ]
[2024-12-14 12:13:27,658, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 12:13:27,660, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 12:13:27,662, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 12:13:27,662, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 12:13:28,032, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 12:13:29,663, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 12:13:29,664, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 12:13:31,304, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 12:13:31,320, 1920069468, INFO, Initiating the DataTransformation ]
[2024-12-14 12:13:31,323, 1920069468, INFO, Initiatig data transformation pipeline ]
[2024-12-14 12:13:32,656, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:13:32,658, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:13:32,659, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:13:32,660, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:13:34,869, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:13:34.869067', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:13:34,870, 1920069468, INFO, Numerical and text pipelines created ]
[2024-12-14 12:13:34,881, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:13:34,882, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:13:34,886, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:13:34,886, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:13:37,006, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:13:37.006240', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:13:37,025, 2457220914, INFO, Transforming all the letters into lowercase ]
[2024-12-14 12:13:37,118, 2457220914, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 12:13:37,119, 2457220914, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 12:13:38,221, 2457220914, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 12:13:38,223, 2457220914, INFO, Removing punctuations from text ]
[2024-12-14 12:13:38,337, 2457220914, INFO, Removing punctuations from text successful ]
[2024-12-14 12:13:38,338, 2457220914, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 12:13:38,368, 2457220914, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 12:13:38,370, 2457220914, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 12:13:38,371, 2457220914, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 12:13:38,372, 1920069468, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 12:16:00,207, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 12:16:00,208, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 12:16:00,210, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 12:16:00,211, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 12:16:00,518, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 12:16:04,238, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 12:16:04,239, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 12:16:05,707, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 12:16:05,724, 2331505436, INFO, Initiating the DataTransformation ]
[2024-12-14 12:16:05,724, 2331505436, INFO, Initiatig data transformation pipeline ]
[2024-12-14 12:16:07,026, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:16:07,027, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:16:07,028, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:16:07,030, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:16:09,441, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:16:09.441396', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:16:09,442, 2331505436, INFO, Numerical and text pipelines created ]
[2024-12-14 12:16:09,446, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:16:09,448, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:16:09,451, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:16:09,453, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:16:11,613, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:16:11.613301', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:16:11,636, 2457220914, INFO, Transforming all the letters into lowercase ]
[2024-12-14 12:16:11,729, 2457220914, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 12:16:11,731, 2457220914, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 12:16:12,689, 2457220914, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 12:16:12,691, 2457220914, INFO, Removing punctuations from text ]
[2024-12-14 12:16:12,828, 2457220914, INFO, Removing punctuations from text successful ]
[2024-12-14 12:16:12,828, 2457220914, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 12:16:12,858, 2457220914, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 12:16:12,859, 2457220914, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 12:16:12,860, 2457220914, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 12:16:12,862, 2331505436, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 12:17:10,088, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 12:17:10,091, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 12:17:10,092, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 12:17:10,093, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 12:17:10,408, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 12:17:11,994, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 12:17:11,995, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 12:17:15,120, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 12:17:15,141, 1644471381, INFO, Initiating the DataTransformation ]
[2024-12-14 12:17:15,142, 1644471381, INFO, Initiatig data transformation pipeline ]
[2024-12-14 12:17:16,523, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:17:16,525, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:17:16,526, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:17:16,527, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:17:18,658, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:17:18.658821', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:17:18,660, 1644471381, INFO, Numerical and text pipelines created ]
[2024-12-14 12:17:18,662, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:17:18,664, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:17:18,666, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:17:18,667, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:17:20,757, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:17:20.757480', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:17:20,766, 2457220914, INFO, Transforming all the letters into lowercase ]
[2024-12-14 12:17:20,878, 2457220914, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 12:17:20,879, 2457220914, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 12:17:22,133, 2457220914, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 12:17:22,135, 2457220914, INFO, Removing punctuations from text ]
[2024-12-14 12:17:22,254, 2457220914, INFO, Removing punctuations from text successful ]
[2024-12-14 12:17:22,255, 2457220914, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 12:17:22,282, 2457220914, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 12:17:22,284, 2457220914, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 12:17:22,286, 2457220914, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 12:17:22,288, 1644471381, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 12:18:48,125, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 12:18:48,127, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 12:18:48,129, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 12:18:48,131, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 12:18:48,505, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 12:18:49,963, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 12:18:49,965, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 12:18:51,445, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 12:18:51,461, 2331505436, INFO, Initiating the DataTransformation ]
[2024-12-14 12:18:51,463, 2331505436, INFO, Initiatig data transformation pipeline ]
[2024-12-14 12:18:52,773, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:18:52,774, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:18:52,775, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:18:52,778, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:18:54,964, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:18:54.964203', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:18:54,965, 2331505436, INFO, Numerical and text pipelines created ]
[2024-12-14 12:18:54,969, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:18:54,971, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:18:54,972, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:18:54,972, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:18:57,029, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:18:57.029682', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:18:57,049, 2457220914, INFO, Transforming all the letters into lowercase ]
[2024-12-14 12:18:57,136, 2457220914, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 12:18:57,137, 2457220914, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 12:18:57,969, 2457220914, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 12:18:57,970, 2457220914, INFO, Removing punctuations from text ]
[2024-12-14 12:18:58,083, 2457220914, INFO, Removing punctuations from text successful ]
[2024-12-14 12:18:58,084, 2457220914, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 12:18:58,113, 2457220914, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 12:18:58,115, 2457220914, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 12:18:58,117, 2457220914, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 12:18:58,118, 2331505436, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 12:36:08,482, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 12:36:08,483, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 12:36:08,485, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 12:36:08,487, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 12:36:08,803, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 12:36:10,547, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 12:36:10,548, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 12:36:12,279, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 12:36:12,299, 3532593754, INFO, Initiating the DataTransformation ]
[2024-12-14 12:36:12,301, 3532593754, INFO, Initiatig data transformation pipeline ]
[2024-12-14 12:36:13,686, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:36:13,688, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:36:13,690, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:36:13,690, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:36:15,787, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:36:15.787064', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:36:15,788, 3532593754, INFO, Numerical and text pipelines created ]
[2024-12-14 12:36:15,792, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 12:36:15,793, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 12:36:15,794, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 12:36:15,795, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 12:36:18,033, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T12:36:18.033869', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 12:36:18,053, 2457220914, INFO, Transforming all the letters into lowercase ]
[2024-12-14 12:36:18,155, 2457220914, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 12:36:18,156, 2457220914, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 12:36:19,454, 2457220914, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 12:36:19,456, 2457220914, INFO, Removing punctuations from text ]
[2024-12-14 12:36:19,570, 2457220914, INFO, Removing punctuations from text successful ]
[2024-12-14 12:36:19,571, 2457220914, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 12:36:19,598, 2457220914, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 12:36:19,600, 2457220914, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 12:36:19,602, 2457220914, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 12:36:19,604, 3532593754, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 13:10:29,464, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 13:10:29,466, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 13:10:29,467, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 13:10:29,469, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 13:10:29,774, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 13:10:31,302, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 13:10:31,303, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 13:10:32,996, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 13:10:33,012, 347725411, INFO, Initiating the DataTransformation ]
[2024-12-14 13:10:33,013, 347725411, INFO, Initiatig data transformation pipeline ]
[2024-12-14 13:10:34,313, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:10:34,315, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 13:10:34,315, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:10:34,317, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:10:36,367, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:10:36.367759', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:10:36,368, 347725411, INFO, Numerical and text pipelines created ]
[2024-12-14 13:10:36,373, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:10:36,375, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 13:10:36,376, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:10:36,377, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:10:38,451, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:10:38.451228', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:10:38,470, 2457220914, INFO, Transforming all the letters into lowercase ]
[2024-12-14 13:10:38,553, 2457220914, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 13:10:38,555, 2457220914, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 13:10:39,394, 2457220914, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 13:10:39,395, 2457220914, INFO, Removing punctuations from text ]
[2024-12-14 13:10:39,524, 2457220914, INFO, Removing punctuations from text successful ]
[2024-12-14 13:10:39,525, 2457220914, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 13:10:39,555, 2457220914, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 13:10:39,557, 2457220914, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 13:10:39,558, 2457220914, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 13:10:39,559, 347725411, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 13:14:09,440, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 13:14:09,442, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 13:14:09,445, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 13:14:09,446, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 13:14:09,820, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 13:15:02,900, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 13:15:02,901, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 13:15:02,903, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 13:15:02,905, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 13:15:03,242, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 13:15:05,075, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 13:15:05,077, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 13:15:06,762, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 13:15:06,797, 347725411, INFO, Initiating the DataTransformation ]
[2024-12-14 13:15:06,798, 347725411, INFO, Error initiating the DataTransformation : name 'DataColumns' is not defined ]
[2024-12-14 13:15:28,601, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 13:15:28,603, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 13:15:28,604, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 13:15:28,607, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 13:15:28,947, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 13:15:30,536, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 13:15:30,538, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 13:15:32,217, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 13:15:32,252, 2919385610, INFO, Initiating the DataTransformation ]
[2024-12-14 13:15:32,253, 2919385610, INFO, Initiatig data transformation pipeline ]
[2024-12-14 13:15:33,798, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:15:33,803, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 13:15:33,805, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:15:33,806, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:15:36,241, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:15:36.241048', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:15:36,242, 2919385610, INFO, Numerical and text pipelines created ]
[2024-12-14 13:15:36,245, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:15:36,247, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 13:15:36,248, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:15:36,249, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:15:38,351, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:15:38.351409', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:15:38,372, 2457220914, INFO, Transforming all the letters into lowercase ]
[2024-12-14 13:15:38,475, 2457220914, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 13:15:38,476, 2457220914, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 13:15:39,417, 2457220914, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 13:15:39,419, 2457220914, INFO, Removing punctuations from text ]
[2024-12-14 13:15:39,537, 2457220914, INFO, Removing punctuations from text successful ]
[2024-12-14 13:15:39,538, 2457220914, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 13:15:39,564, 2457220914, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 13:15:39,566, 2457220914, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 13:15:43,904, 2457220914, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 13:15:43,905, 2919385610, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 13:16:21,857, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 13:16:21,859, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 13:16:21,861, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 13:16:21,863, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 13:16:22,246, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 13:16:23,872, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 13:16:23,873, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 13:16:25,575, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 13:16:25,600, 2424228137, INFO, Initiating the DataTransformation ]
[2024-12-14 13:16:25,602, 2424228137, INFO, Initiatig data transformation pipeline ]
[2024-12-14 13:16:26,906, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:16:26,908, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 13:16:26,910, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:16:26,911, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:16:29,138, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:16:29.138100', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:16:29,139, 2424228137, INFO, Numerical and text pipelines created ]
[2024-12-14 13:16:29,144, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:16:29,147, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 13:16:29,148, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:16:29,150, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:16:31,547, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:16:31.547284', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:16:31,566, 2457220914, INFO, Transforming all the letters into lowercase ]
[2024-12-14 13:16:31,667, 2457220914, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 13:16:31,669, 2457220914, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 13:16:32,776, 2457220914, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 13:16:32,777, 2457220914, INFO, Removing punctuations from text ]
[2024-12-14 13:16:32,921, 2457220914, INFO, Removing punctuations from text successful ]
[2024-12-14 13:16:32,922, 2457220914, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 13:16:32,957, 2457220914, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 13:16:32,959, 2457220914, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 13:16:32,961, 2457220914, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 13:16:32,962, 2424228137, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 13:28:14,293, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 13:28:14,295, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 13:28:14,297, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 13:28:14,299, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 13:28:14,642, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 13:28:16,224, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 13:28:16,226, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 13:28:17,698, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 13:28:17,728, 2424228137, INFO, Initiating the DataTransformation ]
[2024-12-14 13:28:17,729, 2424228137, INFO, Initiatig data transformation pipeline ]
[2024-12-14 13:28:19,026, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:28:19,028, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 13:28:19,028, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:28:19,029, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:28:21,390, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:28:21.390429', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:28:21,391, 2424228137, INFO, Numerical and text pipelines created ]
[2024-12-14 13:28:21,395, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:28:21,397, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 13:28:21,398, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:28:21,398, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:28:23,842, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:28:23.842251', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:28:23,859, 2457220914, INFO, Transforming all the letters into lowercase ]
[2024-12-14 13:28:23,979, 2457220914, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 13:28:23,981, 2457220914, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 13:28:25,321, 2457220914, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 13:28:25,322, 2457220914, INFO, Removing punctuations from text ]
[2024-12-14 13:28:25,465, 2457220914, INFO, Removing punctuations from text successful ]
[2024-12-14 13:28:25,466, 2457220914, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 13:28:25,502, 2457220914, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 13:28:25,504, 2457220914, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 13:28:25,505, 2457220914, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 13:28:25,506, 2424228137, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 13:29:27,870, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 13:29:27,871, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 13:29:27,873, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 13:29:27,876, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 13:29:28,187, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 13:29:29,709, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 13:29:29,711, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 13:29:31,265, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 13:29:31,284, 2031253932, INFO, Initiating the DataTransformation ]
[2024-12-14 13:29:31,285, 2031253932, INFO, Initiating data transformation pipeline. ]
[2024-12-14 13:29:32,618, 2031253932, ERROR, Error in get_transformer_object: name 'RemoveStopWords' is not defined ]
[2024-12-14 13:29:32,619, 2031253932, ERROR, Error in data transformation pipeline: name 'RemoveStopWords' is not defined ]
[2024-12-14 13:37:30,225, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 13:37:30,228, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 13:37:30,230, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 13:37:30,231, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 13:37:30,564, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 13:37:32,197, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 13:37:32,199, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 13:37:33,839, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 13:37:33,877, 3962780592, INFO, Initiating the DataTransformation ]
[2024-12-14 13:37:33,878, 3962780592, INFO, Initiatig data transformation pipeline ]
[2024-12-14 13:37:35,410, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:37:35,415, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 13:37:35,416, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:37:35,417, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:37:37,785, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:37:37.785825', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:37:37,786, 3962780592, INFO, Numerical and text pipelines created ]
[2024-12-14 13:37:37,787, 3962780592, INFO, Error in initiating the data transformation pipeline __init__() got an unexpected keyword argument 'steps' ]
[2024-12-14 13:38:04,086, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 13:38:04,088, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 13:38:04,090, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 13:38:04,092, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 13:38:04,432, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 13:38:05,998, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 13:38:05,999, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 13:38:07,614, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 13:38:07,647, 155414716, INFO, Initiating the DataTransformation ]
[2024-12-14 13:38:07,648, 155414716, INFO, Initiatig data transformation pipeline ]
[2024-12-14 13:38:09,176, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:38:09,178, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 13:38:09,179, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:38:09,181, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:38:11,639, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:38:11.639245', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:38:11,640, 155414716, INFO, Numerical and text pipelines created ]
[2024-12-14 13:38:11,641, 155414716, INFO, Error in initiating the data transformation pipeline __init__() got an unexpected keyword argument 'steps' ]
[2024-12-14 13:38:33,497, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 13:38:33,499, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 13:38:33,500, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 13:38:33,501, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 13:38:33,823, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 13:38:35,739, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 13:38:35,745, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 13:38:38,777, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 13:38:38,802, 2405749325, INFO, Initiating the DataTransformation ]
[2024-12-14 13:38:38,803, 2405749325, INFO, Initiatig data transformation pipeline ]
[2024-12-14 13:38:40,083, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:38:40,085, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 13:38:40,086, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:38:40,087, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:38:42,471, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:38:42.471922', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:38:42,474, 2405749325, INFO, Numerical and text pipelines created ]
[2024-12-14 13:38:42,477, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:38:42,479, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 13:38:42,481, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:38:42,482, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:38:44,857, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:38:44.857392', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:38:44,877, 2457220914, INFO, Transforming all the letters into lowercase ]
[2024-12-14 13:38:45,006, 2457220914, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 13:38:45,007, 2457220914, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 13:38:46,103, 2457220914, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 13:38:46,104, 2457220914, INFO, Removing punctuations from text ]
[2024-12-14 13:38:46,221, 2457220914, INFO, Removing punctuations from text successful ]
[2024-12-14 13:38:46,223, 2457220914, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 13:38:46,254, 2457220914, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 13:38:46,256, 2457220914, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 13:38:50,748, 2457220914, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 13:38:50,749, 2405749325, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 13:41:39,028, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 13:41:39,030, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 13:41:39,032, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 13:41:39,033, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 13:41:39,378, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 13:41:40,969, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 13:41:40,970, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 13:41:42,433, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 13:41:42,457, 1754977927, INFO, Initiating the DataTransformation ]
[2024-12-14 13:41:42,458, 1754977927, INFO, Initiatig data transformation pipeline ]
[2024-12-14 13:41:43,948, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:41:43,950, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:41:43,951, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:41:46,458, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:41:46.458158', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:41:46,459, 1754977927, INFO, Numerical and text pipelines created ]
[2024-12-14 13:41:46,463, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:41:46,465, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:41:46,466, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:41:48,701, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:41:48.701904', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:41:48,720, 2457220914, INFO, Transforming all the letters into lowercase ]
[2024-12-14 13:41:48,832, 2457220914, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 13:41:48,833, 2457220914, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 13:41:50,036, 2457220914, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 13:41:50,037, 2457220914, INFO, Removing punctuations from text ]
[2024-12-14 13:41:50,194, 2457220914, INFO, Removing punctuations from text successful ]
[2024-12-14 13:41:50,196, 2457220914, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 13:41:50,233, 2457220914, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 13:41:50,236, 2457220914, INFO, Generating embeddings for the text data ]
[2024-12-14 13:41:50,337, 2457220914, INFO, Successfully generated embeddings ]
[2024-12-14 13:41:50,339, 1754977927, INFO, Error in initiating the data transformation pipeline all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 103304 and the array at index 1 has size 50 ]
[2024-12-14 13:46:14,314, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 13:46:14,316, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 13:46:14,318, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 13:46:14,320, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 13:46:14,655, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 13:46:16,414, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 13:46:16,416, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 13:46:18,218, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 13:46:18,248, 1754977927, INFO, Initiating the DataTransformation ]
[2024-12-14 13:46:18,249, 1754977927, INFO, Initiatig data transformation pipeline ]
[2024-12-14 13:46:19,786, 2912022246, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:46:19,788, 2912022246, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:46:19,789, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:46:22,349, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:46:22.348263', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:46:22,349, 1754977927, INFO, Numerical and text pipelines created ]
[2024-12-14 13:46:22,353, 2912022246, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:46:22,355, 2912022246, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:46:22,356, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:46:24,512, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:46:24.512868', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:46:24,531, 2912022246, INFO, Transforming all the letters into lowercase ]
[2024-12-14 13:46:24,648, 2912022246, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 13:46:24,650, 2912022246, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 13:46:26,023, 2912022246, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 13:46:26,024, 2912022246, INFO, Removing punctuations from text ]
[2024-12-14 13:46:26,163, 2912022246, INFO, Removing punctuations from text successful ]
[2024-12-14 13:46:26,165, 2912022246, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 13:46:26,201, 2912022246, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 13:46:26,202, 2912022246, INFO, Generating embeddings for the text data ]
[2024-12-14 13:46:26,203, 2912022246, ERROR, Error during transformation: 'Series' object has no attribute 'split' ]
[2024-12-14 13:46:26,204, 1754977927, INFO, Error in initiating the data transformation pipeline 'Series' object has no attribute 'split' ]
[2024-12-14 13:47:20,827, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 13:47:20,829, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 13:47:20,831, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 13:47:20,832, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 13:47:21,151, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 13:47:22,921, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 13:47:22,922, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 13:47:24,676, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 13:47:24,698, 1754977927, INFO, Initiating the DataTransformation ]
[2024-12-14 13:47:24,699, 1754977927, INFO, Initiatig data transformation pipeline ]
[2024-12-14 13:47:26,070, 2093553626, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:47:26,072, 2093553626, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:47:26,073, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:47:28,166, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:47:28.166819', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:47:28,167, 1754977927, INFO, Numerical and text pipelines created ]
[2024-12-14 13:47:28,172, 2093553626, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:47:28,175, 2093553626, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:47:28,176, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:47:30,311, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:47:30.311628', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:47:30,330, 2093553626, INFO, Transforming all the letters into lowercase ]
[2024-12-14 13:47:30,440, 2093553626, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 13:47:30,441, 2093553626, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 13:47:31,460, 2093553626, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 13:47:31,461, 2093553626, INFO, Removing punctuations from text ]
[2024-12-14 13:47:31,595, 2093553626, INFO, Removing punctuations from text successful ]
[2024-12-14 13:47:31,596, 2093553626, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 13:47:31,629, 2093553626, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 13:47:31,630, 2093553626, INFO, Generating embeddings for the text data ]
[2024-12-14 13:47:31,631, 2093553626, ERROR, Error during transformation: 'Series' object has no attribute 'split' ]
[2024-12-14 13:47:31,632, 1754977927, INFO, Error in initiating the data transformation pipeline 'Series' object has no attribute 'split' ]
[2024-12-14 13:48:50,856, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 13:48:50,858, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 13:48:50,859, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 13:48:50,861, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 13:48:51,191, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 13:48:52,818, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 13:48:52,819, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 13:48:54,331, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 13:48:54,361, 1754977927, INFO, Initiating the DataTransformation ]
[2024-12-14 13:48:54,362, 1754977927, INFO, Initiatig data transformation pipeline ]
[2024-12-14 13:48:55,921, 1383614726, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:48:55,923, 1383614726, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:48:55,924, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:48:58,328, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:48:58.328508', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:48:58,329, 1754977927, INFO, Numerical and text pipelines created ]
[2024-12-14 13:48:58,333, 1383614726, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 13:48:58,335, 1383614726, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 13:48:58,335, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 13:49:00,528, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T13:49:00.528629', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 13:49:00,547, 1383614726, INFO, Transforming all the letters into lowercase ]
[2024-12-14 13:49:00,649, 1383614726, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 13:49:00,651, 1383614726, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 13:49:01,878, 1383614726, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 13:49:01,879, 1383614726, INFO, Removing punctuations from text ]
[2024-12-14 13:49:02,001, 1383614726, INFO, Removing punctuations from text successful ]
[2024-12-14 13:49:02,002, 1383614726, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 13:49:02,032, 1383614726, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 13:49:02,034, 1383614726, INFO, Generating embeddings for the text data ]
[2024-12-14 13:49:02,035, 1383614726, INFO, Successfully generated embeddings ]
[2024-12-14 13:49:02,036, 1383614726, ERROR, Error during transformation: 'DataFrame' object has no attribute 'tolist' ]
[2024-12-14 13:49:02,037, 1754977927, INFO, Error in initiating the data transformation pipeline 'DataFrame' object has no attribute 'tolist' ]
[2024-12-14 14:14:03,621, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 14:14:03,623, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 14:14:03,625, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 14:14:03,627, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 14:14:03,952, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 14:14:05,494, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 14:14:05,495, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 14:14:07,030, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 14:14:07,048, 1754977927, INFO, Initiating the DataTransformation ]
[2024-12-14 14:14:07,049, 1754977927, INFO, Initiatig data transformation pipeline ]
[2024-12-14 14:14:08,353, 4217064066, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 14:14:08,355, 4217064066, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 14:14:08,355, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 14:14:10,654, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T14:14:10.654530', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 14:14:10,655, 1754977927, INFO, Numerical and text pipelines created ]
[2024-12-14 14:14:10,659, 4217064066, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 14:14:10,661, 4217064066, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 14:14:10,661, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 14:14:12,840, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T14:14:12.840291', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 14:14:12,858, 4217064066, INFO, Transforming all the letters into lowercase ]
[2024-12-14 14:14:12,948, 4217064066, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 14:14:12,949, 4217064066, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 14:14:13,894, 4217064066, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 14:14:13,896, 4217064066, INFO, Removing punctuations from text ]
[2024-12-14 14:14:14,038, 4217064066, INFO, Removing punctuations from text successful ]
[2024-12-14 14:14:14,039, 4217064066, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 14:14:14,077, 4217064066, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 14:14:14,079, 4217064066, INFO, Generating embeddings for the text data ]
[2024-12-14 14:14:14,081, 4217064066, INFO, Successfully generated embeddings ]
[2024-12-14 14:14:14,085, 1754977927, INFO, Error in initiating the data transformation pipeline The output of the 'Text_Pipeline' transformer should be 2D (numpy array, scipy sparse array, dataframe). ]
[2024-12-14 14:15:21,259, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 14:15:21,261, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 14:15:21,263, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 14:15:21,264, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 14:15:21,599, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 14:15:23,451, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 14:15:23,453, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 14:15:25,180, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 14:15:25,209, 1754977927, INFO, Initiating the DataTransformation ]
[2024-12-14 14:15:25,210, 1754977927, INFO, Initiatig data transformation pipeline ]
[2024-12-14 14:15:26,502, 3225407149, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 14:15:26,505, 3225407149, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 14:15:26,505, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 14:15:28,766, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T14:15:28.766068', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 14:15:28,767, 1754977927, INFO, Numerical and text pipelines created ]
[2024-12-14 14:15:28,771, 3225407149, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 14:15:28,773, 3225407149, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 14:15:28,774, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 14:15:32,102, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T14:15:32.102208', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 14:15:32,164, 3225407149, INFO, Transforming all the letters into lowercase ]
[2024-12-14 14:15:32,380, 3225407149, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 14:15:32,381, 3225407149, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 14:15:33,628, 3225407149, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 14:15:33,630, 3225407149, INFO, Removing punctuations from text ]
[2024-12-14 14:15:33,745, 3225407149, INFO, Removing punctuations from text successful ]
[2024-12-14 14:15:33,747, 3225407149, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 14:15:33,783, 3225407149, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 14:15:33,784, 3225407149, INFO, Generating embeddings for the text data ]
[2024-12-14 14:15:33,787, 3225407149, INFO, Successfully generated embeddings ]
[2024-12-14 14:15:33,791, 1754977927, INFO, Error in initiating the data transformation pipeline all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 103304 and the array at index 1 has size 1 ]
[2024-12-14 14:27:18,197, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 14:27:18,198, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 14:27:18,201, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 14:27:18,202, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 14:27:18,511, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 14:27:20,083, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 14:27:20,085, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 14:27:21,496, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 14:27:21,516, 2405749325, INFO, Initiating the DataTransformation ]
[2024-12-14 14:27:21,518, 2405749325, INFO, Initiatig data transformation pipeline ]
[2024-12-14 14:27:22,814, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 14:27:22,816, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 14:27:22,817, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 14:27:22,818, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 14:27:25,174, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T14:27:25.174068', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 14:27:25,175, 2405749325, INFO, Numerical and text pipelines created ]
[2024-12-14 14:27:25,179, 2457220914, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 14:27:25,181, 2457220914, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 14:27:25,183, 2457220914, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 14:27:25,184, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 14:27:27,312, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T14:27:27.312865', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 14:27:27,333, 2457220914, INFO, Transforming all the letters into lowercase ]
[2024-12-14 14:27:27,439, 2457220914, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 14:27:27,440, 2457220914, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 14:27:28,443, 2457220914, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 14:27:28,444, 2457220914, INFO, Removing punctuations from text ]
[2024-12-14 14:27:28,590, 2457220914, INFO, Removing punctuations from text successful ]
[2024-12-14 14:27:28,591, 2457220914, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 14:27:28,627, 2457220914, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 14:27:28,628, 2457220914, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 14:27:28,629, 2457220914, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 14:27:28,630, 2405749325, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 14:31:09,074, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 14:31:09,076, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 14:31:09,078, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 14:31:09,080, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 14:31:09,439, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 14:31:11,867, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 14:31:11,871, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 14:31:14,795, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 14:31:14,821, 2405749325, INFO, Initiating the DataTransformation ]
[2024-12-14 14:31:14,824, 2405749325, INFO, Initiatig data transformation pipeline ]
[2024-12-14 14:31:16,116, 956976421, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 14:31:16,118, 956976421, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 14:31:16,119, 956976421, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 14:31:16,119, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 14:31:18,427, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T14:31:18.427347', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 14:31:18,429, 2405749325, INFO, Numerical and text pipelines created ]
[2024-12-14 14:31:18,432, 956976421, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 14:31:18,434, 956976421, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 14:31:18,435, 956976421, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 14:31:18,436, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 14:31:20,730, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T14:31:20.730943', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 14:31:20,747, 956976421, INFO, Transforming all the letters into lowercase ]
[2024-12-14 14:31:20,851, 956976421, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 14:31:20,852, 956976421, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 14:31:22,146, 956976421, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 14:31:22,147, 956976421, INFO, Removing punctuations from text ]
[2024-12-14 14:31:22,280, 956976421, INFO, Removing punctuations from text successful ]
[2024-12-14 14:31:22,281, 956976421, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 14:31:22,317, 956976421, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 14:31:22,318, 956976421, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 14:31:22,319, 956976421, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 14:31:22,320, 2405749325, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 14:38:22,432, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 14:38:22,434, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 14:38:22,436, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 14:38:22,437, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 14:38:22,848, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 14:38:24,694, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 14:38:24,695, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 14:38:26,461, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 14:38:26,502, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 14:38:26,505, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 14:38:28,276, 1545973463, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 14:38:28,280, 1545973463, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 14:38:28,280, 1545973463, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 14:38:28,281, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 14:38:30,930, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T14:38:30.930083', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 14:38:30,932, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 14:38:30,935, 1545973463, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 14:38:30,937, 1545973463, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 14:38:30,938, 1545973463, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 14:38:30,939, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 14:38:33,435, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T14:38:33.435386', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 14:38:33,459, 1545973463, INFO, Transforming all the letters into lowercase ]
[2024-12-14 14:38:33,575, 1545973463, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 14:38:33,576, 1545973463, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 14:38:34,706, 1545973463, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 14:38:34,707, 1545973463, INFO, Removing punctuations from text ]
[2024-12-14 14:38:34,846, 1545973463, INFO, Removing punctuations from text successful ]
[2024-12-14 14:38:34,847, 1545973463, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 14:38:34,882, 1545973463, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 14:38:34,884, 1545973463, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 14:38:39,459, 1545973463, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 14:38:39,460, 3987913102, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 14:43:32,232, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 14:43:32,234, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 14:43:32,235, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 14:43:32,236, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 14:43:32,649, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 14:43:34,546, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 14:43:34,547, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 14:43:36,270, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 14:43:36,300, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 14:43:36,301, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 14:43:37,856, 3846616926, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 14:43:37,858, 3846616926, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 14:43:37,860, 3846616926, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 14:43:37,861, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 14:43:40,409, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T14:43:40.409047', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 14:43:40,410, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 14:43:40,414, 3846616926, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 14:43:40,414, 3846616926, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 14:43:40,415, 3846616926, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 14:43:40,416, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 14:43:43,029, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T14:43:43.029009', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 14:43:43,050, 3846616926, INFO, Transforming all the letters into lowercase ]
[2024-12-14 14:43:43,168, 3846616926, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 14:43:43,169, 3846616926, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 14:43:44,404, 3846616926, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 14:43:44,405, 3846616926, INFO, Removing punctuations from text ]
[2024-12-14 14:43:44,539, 3846616926, INFO, Removing punctuations from text successful ]
[2024-12-14 14:43:44,540, 3846616926, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 14:43:44,572, 3846616926, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 14:43:44,573, 3846616926, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 14:43:44,574, 3846616926, INFO, Error in lemmatization: 'Series' object has no attribute 'split' ]
[2024-12-14 14:43:44,575, 3987913102, INFO, Error in initiating the data transformation pipeline 'Series' object has no attribute 'split' ]
[2024-12-14 14:44:07,089, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 14:44:07,090, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 14:44:07,092, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 14:44:07,093, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 14:44:07,503, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 14:44:09,300, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 14:44:09,301, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 14:44:11,040, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 14:44:11,076, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 14:44:11,079, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 14:44:12,604, 601768826, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 14:44:12,606, 601768826, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 14:44:12,608, 601768826, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 14:44:12,609, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 14:44:15,060, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T14:44:15.060488', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 14:44:15,062, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 14:44:15,065, 601768826, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 14:44:15,067, 601768826, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 14:44:15,068, 601768826, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 14:44:15,068, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 14:44:17,427, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T14:44:17.427161', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 14:44:17,447, 601768826, INFO, Transforming all the letters into lowercase ]
[2024-12-14 14:44:17,566, 601768826, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 14:44:17,567, 601768826, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 14:44:18,901, 601768826, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 14:44:18,902, 601768826, INFO, Removing punctuations from text ]
[2024-12-14 14:44:19,034, 601768826, INFO, Removing punctuations from text successful ]
[2024-12-14 14:44:19,035, 601768826, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 14:44:19,071, 601768826, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 14:44:19,073, 601768826, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 14:44:19,074, 601768826, INFO, Error in lemmatization: 'float' object has no attribute 'endswith' ]
[2024-12-14 14:44:19,075, 3987913102, INFO, Error in initiating the data transformation pipeline 'float' object has no attribute 'endswith' ]
[2024-12-14 16:13:55,487, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:13:55,489, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:13:55,491, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:13:55,492, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:13:55,820, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:13:57,504, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:13:57,506, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:13:58,969, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:13:58,993, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 16:13:58,995, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:14:00,344, 3424631851, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:14:00,346, 3424631851, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:14:00,347, 3424631851, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:14:00,348, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:14:02,809, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:14:02.809202', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:14:02,810, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 16:14:02,813, 3424631851, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:14:02,815, 3424631851, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:14:02,816, 3424631851, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:14:02,817, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:14:04,823, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:14:04.823051', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:14:04,840, 3424631851, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:14:04,952, 3424631851, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:14:04,954, 3424631851, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:14:06,305, 3424631851, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:14:06,306, 3424631851, INFO, Removing punctuations from text ]
[2024-12-14 16:14:06,312, 3424631851, INFO, Error in pre-processing the text: 'StringMethods' object is not iterable ]
[2024-12-14 16:14:06,313, 3987913102, INFO, Error in initiating the data transformation pipeline 'StringMethods' object is not iterable ]
[2024-12-14 16:22:17,222, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:22:17,224, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:22:17,226, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:22:17,228, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:22:17,557, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:22:19,295, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:22:19,297, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:22:20,783, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:22:20,801, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 16:22:20,802, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:22:22,153, 4265192798, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:22:22,154, 4265192798, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:22:22,155, 4265192798, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:22:22,156, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:22:24,484, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:22:24.484520', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:22:24,485, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 16:22:24,488, 4265192798, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:22:24,490, 4265192798, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:22:24,490, 4265192798, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:22:24,492, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:22:26,617, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:22:26.617237', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:22:26,634, 4265192798, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:22:26,728, 4265192798, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:22:26,729, 4265192798, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:22:27,748, 4265192798, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:22:27,749, 4265192798, INFO, Removing punctuations from text ]
[2024-12-14 16:22:27,750, 4265192798, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-14 16:22:27,751, 3987913102, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-14 16:23:00,875, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:23:00,877, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:23:00,879, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:23:00,880, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:23:01,277, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:23:02,905, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:23:02,906, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:23:04,356, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:23:04,378, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 16:23:04,379, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:23:05,747, 2868195062, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:23:05,749, 2868195062, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:23:05,750, 2868195062, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:23:05,751, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:23:08,018, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:23:08.018486', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:23:08,020, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 16:23:08,023, 2868195062, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:23:08,025, 2868195062, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:23:08,026, 2868195062, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:23:08,027, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:23:10,101, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (201881, 50) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:23:10.101069', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:23:10,121, 2868195062, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:23:10,241, 2868195062, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:23:10,242, 2868195062, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:23:11,260, 2868195062, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:23:11,261, 2868195062, INFO, Removing punctuations from text ]
[2024-12-14 16:23:11,262, 2868195062, INFO, Error in pre-processing the text: 'DataFrame' object has no attribute 'str' ]
[2024-12-14 16:23:11,262, 3987913102, INFO, Error in initiating the data transformation pipeline 'DataFrame' object has no attribute 'str' ]
[2024-12-14 16:24:26,944, word2vec, INFO, collecting all words and their counts ]
[2024-12-14 16:24:26,946, word2vec, INFO, PROGRESS: at sentence #0, processed 0 words, keeping 0 word types ]
[2024-12-14 16:24:27,061, word2vec, INFO, PROGRESS: at sentence #10000, processed 408439 words, keeping 26554 word types ]
[2024-12-14 16:24:27,163, word2vec, INFO, PROGRESS: at sentence #20000, processed 809383 words, keeping 39092 word types ]
[2024-12-14 16:24:27,264, word2vec, INFO, PROGRESS: at sentence #30000, processed 1218278 words, keeping 49917 word types ]
[2024-12-14 16:24:27,377, word2vec, INFO, PROGRESS: at sentence #40000, processed 1623949 words, keeping 59450 word types ]
[2024-12-14 16:24:27,462, word2vec, INFO, PROGRESS: at sentence #50000, processed 2028560 words, keeping 67824 word types ]
[2024-12-14 16:24:27,564, word2vec, INFO, PROGRESS: at sentence #60000, processed 2431931 words, keeping 75714 word types ]
[2024-12-14 16:24:27,655, word2vec, INFO, PROGRESS: at sentence #70000, processed 2832678 words, keeping 83130 word types ]
[2024-12-14 16:24:27,753, word2vec, INFO, PROGRESS: at sentence #80000, processed 3245426 words, keeping 90629 word types ]
[2024-12-14 16:24:27,841, word2vec, INFO, PROGRESS: at sentence #90000, processed 3650408 words, keeping 97905 word types ]
[2024-12-14 16:24:27,928, word2vec, INFO, PROGRESS: at sentence #100000, processed 4047571 words, keeping 104455 word types ]
[2024-12-14 16:24:27,971, word2vec, INFO, collected 106574 word types from a corpus of 4176922 raw words and 103304 sentences ]
[2024-12-14 16:24:27,972, word2vec, INFO, Creating a fresh vocabulary ]
[2024-12-14 16:24:28,489, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 retains 106574 unique words (100.00% of original 106574, drops 0)', 'datetime': '2024-12-14T16:24:28.489497', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-14 16:24:28,490, utils, INFO, FastText lifecycle event {'msg': 'effective_min_count=1 leaves 4176922 word corpus (100.00% of original 4176922, drops 0)', 'datetime': '2024-12-14T16:24:28.490495', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-14 16:24:29,217, word2vec, INFO, deleting the raw counts dictionary of 106574 items ]
[2024-12-14 16:24:29,220, word2vec, INFO, sample=0.001 downsamples 35 most-common words ]
[2024-12-14 16:24:29,222, utils, INFO, FastText lifecycle event {'msg': 'downsampling leaves estimated 3726514.7489644596 word corpus (89.2%% of prior 4176922)', 'datetime': '2024-12-14T16:24:29.222538', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'} ]
[2024-12-14 16:24:31,349, fasttext, INFO, estimated required memory for 106574 words, 2000000 buckets and 25 dimensions: 297459020 bytes ]
[2024-12-14 16:24:31,352, word2vec, INFO, resetting layer weights ]
[2024-12-14 16:24:37,802, utils, INFO, FastText lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-12-14T16:24:37.802674', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'} ]
[2024-12-14 16:24:37,804, utils, INFO, FastText lifecycle event {'msg': 'training model with 8 workers on 106574 vocabulary and 25 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-12-14T16:24:37.804669', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'} ]
[2024-12-14 16:24:38,815, word2vec, INFO, EPOCH 0 - PROGRESS: at 6.16% examples, 230760 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:24:39,826, word2vec, INFO, EPOCH 0 - PROGRESS: at 13.31% examples, 247417 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:40,857, word2vec, INFO, EPOCH 0 - PROGRESS: at 21.17% examples, 259742 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:41,884, word2vec, INFO, EPOCH 0 - PROGRESS: at 27.52% examples, 253301 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:42,910, word2vec, INFO, EPOCH 0 - PROGRESS: at 34.37% examples, 252809 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:43,910, word2vec, INFO, EPOCH 0 - PROGRESS: at 41.18% examples, 253561 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:44,911, word2vec, INFO, EPOCH 0 - PROGRESS: at 49.24% examples, 259115 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:45,964, word2vec, INFO, EPOCH 0 - PROGRESS: at 57.01% examples, 261460 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:46,965, word2vec, INFO, EPOCH 0 - PROGRESS: at 64.31% examples, 261971 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:47,971, word2vec, INFO, EPOCH 0 - PROGRESS: at 71.59% examples, 263159 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:49,028, word2vec, INFO, EPOCH 0 - PROGRESS: at 79.09% examples, 263736 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:50,069, word2vec, INFO, EPOCH 0 - PROGRESS: at 86.73% examples, 264543 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:51,137, word2vec, INFO, EPOCH 0 - PROGRESS: at 94.45% examples, 264619 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:51,755, word2vec, INFO, EPOCH 0: training on 4176922 raw words (3726695 effective words) took 13.9s, 267315 effective words/s ]
[2024-12-14 16:24:52,775, word2vec, INFO, EPOCH 1 - PROGRESS: at 5.44% examples, 202600 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:53,807, word2vec, INFO, EPOCH 1 - PROGRESS: at 11.04% examples, 204570 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:54,817, word2vec, INFO, EPOCH 1 - PROGRESS: at 16.89% examples, 206733 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:24:55,825, word2vec, INFO, EPOCH 1 - PROGRESS: at 22.82% examples, 210007 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:56,852, word2vec, INFO, EPOCH 1 - PROGRESS: at 28.44% examples, 209562 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:24:57,890, word2vec, INFO, EPOCH 1 - PROGRESS: at 33.93% examples, 207413 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:58,947, word2vec, INFO, EPOCH 1 - PROGRESS: at 39.63% examples, 206558 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:24:59,999, word2vec, INFO, EPOCH 1 - PROGRESS: at 45.27% examples, 206035 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:01,001, word2vec, INFO, EPOCH 1 - PROGRESS: at 51.13% examples, 206689 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:02,006, word2vec, INFO, EPOCH 1 - PROGRESS: at 57.28% examples, 208914 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:25:03,012, word2vec, INFO, EPOCH 1 - PROGRESS: at 63.31% examples, 209951 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-14 16:25:04,021, word2vec, INFO, EPOCH 1 - PROGRESS: at 68.99% examples, 210090 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:05,024, word2vec, INFO, EPOCH 1 - PROGRESS: at 74.85% examples, 210963 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:25:06,026, word2vec, INFO, EPOCH 1 - PROGRESS: at 80.70% examples, 211733 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:07,143, word2vec, INFO, EPOCH 1 - PROGRESS: at 86.73% examples, 210793 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:08,180, word2vec, INFO, EPOCH 1 - PROGRESS: at 92.55% examples, 210444 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:09,185, word2vec, INFO, EPOCH 1 - PROGRESS: at 98.36% examples, 210535 words/s, in_qsize 7, out_qsize 1 ]
[2024-12-14 16:25:09,310, word2vec, INFO, EPOCH 1: training on 4176922 raw words (3726671 effective words) took 17.5s, 212401 effective words/s ]
[2024-12-14 16:25:10,370, word2vec, INFO, EPOCH 2 - PROGRESS: at 5.18% examples, 186610 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:11,391, word2vec, INFO, EPOCH 2 - PROGRESS: at 11.06% examples, 201933 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:12,445, word2vec, INFO, EPOCH 2 - PROGRESS: at 17.39% examples, 207610 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:13,457, word2vec, INFO, EPOCH 2 - PROGRESS: at 23.28% examples, 210492 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:14,621, word2vec, INFO, EPOCH 2 - PROGRESS: at 29.42% examples, 207857 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:15,630, word2vec, INFO, EPOCH 2 - PROGRESS: at 35.57% examples, 211163 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:16,674, word2vec, INFO, EPOCH 2 - PROGRESS: at 41.41% examples, 211409 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:17,779, word2vec, INFO, EPOCH 2 - PROGRESS: at 47.78% examples, 211101 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:18,783, word2vec, INFO, EPOCH 2 - PROGRESS: at 53.27% examples, 210156 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:19,795, word2vec, INFO, EPOCH 2 - PROGRESS: at 59.23% examples, 211023 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:20,902, word2vec, INFO, EPOCH 2 - PROGRESS: at 65.29% examples, 210001 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:21,953, word2vec, INFO, EPOCH 2 - PROGRESS: at 71.59% examples, 211568 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:22,969, word2vec, INFO, EPOCH 2 - PROGRESS: at 77.42% examples, 212113 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:23,972, word2vec, INFO, EPOCH 2 - PROGRESS: at 82.84% examples, 211541 words/s, in_qsize 14, out_qsize 1 ]
[2024-12-14 16:25:25,002, word2vec, INFO, EPOCH 2 - PROGRESS: at 88.94% examples, 211814 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:26,016, word2vec, INFO, EPOCH 2 - PROGRESS: at 95.17% examples, 212763 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:26,699, word2vec, INFO, EPOCH 2: training on 4176922 raw words (3726576 effective words) took 17.4s, 214451 effective words/s ]
[2024-12-14 16:25:27,730, word2vec, INFO, EPOCH 3 - PROGRESS: at 4.94% examples, 183203 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:28,829, word2vec, INFO, EPOCH 3 - PROGRESS: at 10.78% examples, 193092 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:29,842, word2vec, INFO, EPOCH 3 - PROGRESS: at 16.70% examples, 198744 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:30,843, word2vec, INFO, EPOCH 3 - PROGRESS: at 22.57% examples, 204237 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:31,865, word2vec, INFO, EPOCH 3 - PROGRESS: at 28.69% examples, 208598 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:32,883, word2vec, INFO, EPOCH 3 - PROGRESS: at 34.61% examples, 210145 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:33,920, word2vec, INFO, EPOCH 3 - PROGRESS: at 39.86% examples, 207003 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:34,965, word2vec, INFO, EPOCH 3 - PROGRESS: at 46.06% examples, 208739 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:25:35,968, word2vec, INFO, EPOCH 3 - PROGRESS: at 51.60% examples, 208135 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:36,997, word2vec, INFO, EPOCH 3 - PROGRESS: at 57.50% examples, 208843 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:38,069, word2vec, INFO, EPOCH 3 - PROGRESS: at 63.83% examples, 209445 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:39,135, word2vec, INFO, EPOCH 3 - PROGRESS: at 69.68% examples, 209379 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:25:40,226, word2vec, INFO, EPOCH 3 - PROGRESS: at 75.78% examples, 209607 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:41,291, word2vec, INFO, EPOCH 3 - PROGRESS: at 81.63% examples, 209533 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:42,307, word2vec, INFO, EPOCH 3 - PROGRESS: at 87.71% examples, 210121 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:43,376, word2vec, INFO, EPOCH 3 - PROGRESS: at 94.01% examples, 210469 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:44,234, word2vec, INFO, EPOCH 3: training on 4176922 raw words (3726260 effective words) took 17.5s, 212642 effective words/s ]
[2024-12-14 16:25:45,257, word2vec, INFO, EPOCH 4 - PROGRESS: at 4.44% examples, 167431 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:46,268, word2vec, INFO, EPOCH 4 - PROGRESS: at 10.56% examples, 197998 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:47,338, word2vec, INFO, EPOCH 4 - PROGRESS: at 16.65% examples, 201253 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:48,363, word2vec, INFO, EPOCH 4 - PROGRESS: at 22.59% examples, 205058 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:49,382, word2vec, INFO, EPOCH 4 - PROGRESS: at 28.44% examples, 207601 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:50,391, word2vec, INFO, EPOCH 4 - PROGRESS: at 34.39% examples, 209622 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:51,457, word2vec, INFO, EPOCH 4 - PROGRESS: at 40.27% examples, 209467 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:52,478, word2vec, INFO, EPOCH 4 - PROGRESS: at 46.55% examples, 211522 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:53,498, word2vec, INFO, EPOCH 4 - PROGRESS: at 52.79% examples, 213066 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:54,498, word2vec, INFO, EPOCH 4 - PROGRESS: at 57.99% examples, 211307 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:55,527, word2vec, INFO, EPOCH 4 - PROGRESS: at 63.81% examples, 210938 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:56,590, word2vec, INFO, EPOCH 4 - PROGRESS: at 69.92% examples, 211486 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:25:57,627, word2vec, INFO, EPOCH 4 - PROGRESS: at 75.77% examples, 211719 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:58,650, word2vec, INFO, EPOCH 4 - PROGRESS: at 81.84% examples, 212741 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:25:59,657, word2vec, INFO, EPOCH 4 - PROGRESS: at 87.68% examples, 212672 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:00,659, word2vec, INFO, EPOCH 4 - PROGRESS: at 93.54% examples, 212668 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-14 16:26:01,640, word2vec, INFO, EPOCH 4: training on 4176922 raw words (3726535 effective words) took 17.4s, 214256 effective words/s ]
[2024-12-14 16:26:02,712, word2vec, INFO, EPOCH 5 - PROGRESS: at 4.51% examples, 159024 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:03,748, word2vec, INFO, EPOCH 5 - PROGRESS: at 10.56% examples, 190729 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:04,806, word2vec, INFO, EPOCH 5 - PROGRESS: at 16.65% examples, 197184 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:05,822, word2vec, INFO, EPOCH 5 - PROGRESS: at 22.34% examples, 200200 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:06,850, word2vec, INFO, EPOCH 5 - PROGRESS: at 28.21% examples, 203413 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:07,865, word2vec, INFO, EPOCH 5 - PROGRESS: at 34.17% examples, 205881 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-14 16:26:08,898, word2vec, INFO, EPOCH 5 - PROGRESS: at 40.08% examples, 207225 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:09,906, word2vec, INFO, EPOCH 5 - PROGRESS: at 46.06% examples, 208773 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:10,925, word2vec, INFO, EPOCH 5 - PROGRESS: at 51.86% examples, 208742 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:11,924, word2vec, INFO, EPOCH 5 - PROGRESS: at 57.74% examples, 209985 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:13,012, word2vec, INFO, EPOCH 5 - PROGRESS: at 63.83% examples, 209423 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:14,059, word2vec, INFO, EPOCH 5 - PROGRESS: at 69.92% examples, 210386 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:15,090, word2vec, INFO, EPOCH 5 - PROGRESS: at 75.99% examples, 211445 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:16,120, word2vec, INFO, EPOCH 5 - PROGRESS: at 81.84% examples, 211755 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:17,181, word2vec, INFO, EPOCH 5 - PROGRESS: at 87.94% examples, 211583 words/s, in_qsize 16, out_qsize 1 ]
[2024-12-14 16:26:18,241, word2vec, INFO, EPOCH 5 - PROGRESS: at 93.99% examples, 211444 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:19,199, word2vec, INFO, EPOCH 5: training on 4176922 raw words (3726571 effective words) took 17.5s, 212361 effective words/s ]
[2024-12-14 16:26:20,258, word2vec, INFO, EPOCH 6 - PROGRESS: at 5.21% examples, 186831 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:21,295, word2vec, INFO, EPOCH 6 - PROGRESS: at 11.04% examples, 200540 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:22,339, word2vec, INFO, EPOCH 6 - PROGRESS: at 17.15% examples, 204545 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:23,376, word2vec, INFO, EPOCH 6 - PROGRESS: at 22.82% examples, 204696 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:26:24,382, word2vec, INFO, EPOCH 6 - PROGRESS: at 28.44% examples, 206135 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:26:25,401, word2vec, INFO, EPOCH 6 - PROGRESS: at 34.37% examples, 208116 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:26,404, word2vec, INFO, EPOCH 6 - PROGRESS: at 40.29% examples, 209929 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:27,408, word2vec, INFO, EPOCH 6 - PROGRESS: at 45.79% examples, 209155 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:28,423, word2vec, INFO, EPOCH 6 - PROGRESS: at 51.12% examples, 207256 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:29,508, word2vec, INFO, EPOCH 6 - PROGRESS: at 56.58% examples, 205195 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:30,517, word2vec, INFO, EPOCH 6 - PROGRESS: at 62.81% examples, 207290 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:31,541, word2vec, INFO, EPOCH 6 - PROGRESS: at 68.75% examples, 208090 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:32,549, word2vec, INFO, EPOCH 6 - PROGRESS: at 74.67% examples, 209033 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:33,602, word2vec, INFO, EPOCH 6 - PROGRESS: at 80.24% examples, 208578 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:34,606, word2vec, INFO, EPOCH 6 - PROGRESS: at 85.74% examples, 208253 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:35,617, word2vec, INFO, EPOCH 6 - PROGRESS: at 91.35% examples, 207876 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:36,620, word2vec, INFO, EPOCH 6 - PROGRESS: at 97.61% examples, 209132 words/s, in_qsize 10, out_qsize 0 ]
[2024-12-14 16:26:36,904, word2vec, INFO, EPOCH 6: training on 4176922 raw words (3726546 effective words) took 17.7s, 210619 effective words/s ]
[2024-12-14 16:26:37,932, word2vec, INFO, EPOCH 7 - PROGRESS: at 4.94% examples, 184016 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:38,933, word2vec, INFO, EPOCH 7 - PROGRESS: at 10.10% examples, 189661 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:39,981, word2vec, INFO, EPOCH 7 - PROGRESS: at 15.53% examples, 188471 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:41,011, word2vec, INFO, EPOCH 7 - PROGRESS: at 21.41% examples, 195215 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:42,092, word2vec, INFO, EPOCH 7 - PROGRESS: at 27.76% examples, 200841 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:43,126, word2vec, INFO, EPOCH 7 - PROGRESS: at 33.45% examples, 201788 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:44,161, word2vec, INFO, EPOCH 7 - PROGRESS: at 38.91% examples, 201086 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:26:45,161, word2vec, INFO, EPOCH 7 - PROGRESS: at 44.77% examples, 203611 words/s, in_qsize 13, out_qsize 2 ]
[2024-12-14 16:26:46,190, word2vec, INFO, EPOCH 7 - PROGRESS: at 51.36% examples, 206851 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:47,238, word2vec, INFO, EPOCH 7 - PROGRESS: at 57.01% examples, 206451 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:48,254, word2vec, INFO, EPOCH 7 - PROGRESS: at 63.05% examples, 207490 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:49,286, word2vec, INFO, EPOCH 7 - PROGRESS: at 68.78% examples, 207421 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:50,287, word2vec, INFO, EPOCH 7 - PROGRESS: at 74.61% examples, 208515 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:51,312, word2vec, INFO, EPOCH 7 - PROGRESS: at 80.24% examples, 208506 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:52,377, word2vec, INFO, EPOCH 7 - PROGRESS: at 86.26% examples, 208525 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:53,381, word2vec, INFO, EPOCH 7 - PROGRESS: at 91.81% examples, 208192 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:54,399, word2vec, INFO, EPOCH 7 - PROGRESS: at 97.63% examples, 208241 words/s, in_qsize 10, out_qsize 0 ]
[2024-12-14 16:26:54,688, word2vec, INFO, EPOCH 7: training on 4176922 raw words (3726795 effective words) took 17.8s, 209697 effective words/s ]
[2024-12-14 16:26:55,704, word2vec, INFO, EPOCH 8 - PROGRESS: at 4.74% examples, 176825 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:26:56,772, word2vec, INFO, EPOCH 8 - PROGRESS: at 10.78% examples, 197380 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:57,895, word2vec, INFO, EPOCH 8 - PROGRESS: at 16.65% examples, 194801 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:58,921, word2vec, INFO, EPOCH 8 - PROGRESS: at 22.34% examples, 197859 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:26:59,957, word2vec, INFO, EPOCH 8 - PROGRESS: at 28.21% examples, 201184 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:00,969, word2vec, INFO, EPOCH 8 - PROGRESS: at 34.14% examples, 204164 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:02,167, word2vec, INFO, EPOCH 8 - PROGRESS: at 40.29% examples, 202290 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:03,222, word2vec, INFO, EPOCH 8 - PROGRESS: at 46.55% examples, 204349 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:04,231, word2vec, INFO, EPOCH 8 - PROGRESS: at 52.57% examples, 205872 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:05,267, word2vec, INFO, EPOCH 8 - PROGRESS: at 58.74% examples, 207539 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:06,313, word2vec, INFO, EPOCH 8 - PROGRESS: at 64.79% examples, 207973 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:07,320, word2vec, INFO, EPOCH 8 - PROGRESS: at 70.41% examples, 208302 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:08,336, word2vec, INFO, EPOCH 8 - PROGRESS: at 76.01% examples, 208426 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:09,415, word2vec, INFO, EPOCH 8 - PROGRESS: at 81.84% examples, 208246 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:10,444, word2vec, INFO, EPOCH 8 - PROGRESS: at 87.94% examples, 208743 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:11,458, word2vec, INFO, EPOCH 8 - PROGRESS: at 94.01% examples, 209324 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:12,369, word2vec, INFO, EPOCH 8: training on 4176922 raw words (3726910 effective words) took 17.7s, 210924 effective words/s ]
[2024-12-14 16:27:13,395, word2vec, INFO, EPOCH 9 - PROGRESS: at 4.94% examples, 183782 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:14,397, word2vec, INFO, EPOCH 9 - PROGRESS: at 10.56% examples, 198167 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:15,430, word2vec, INFO, EPOCH 9 - PROGRESS: at 16.65% examples, 203895 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:16,444, word2vec, INFO, EPOCH 9 - PROGRESS: at 22.34% examples, 205423 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:17,473, word2vec, INFO, EPOCH 9 - PROGRESS: at 28.23% examples, 207514 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:18,474, word2vec, INFO, EPOCH 9 - PROGRESS: at 33.93% examples, 208371 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:27:19,499, word2vec, INFO, EPOCH 9 - PROGRESS: at 39.63% examples, 208319 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:20,513, word2vec, INFO, EPOCH 9 - PROGRESS: at 45.27% examples, 208567 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:21,518, word2vec, INFO, EPOCH 9 - PROGRESS: at 51.13% examples, 208899 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:22,533, word2vec, INFO, EPOCH 9 - PROGRESS: at 57.01% examples, 209825 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:27:23,542, word2vec, INFO, EPOCH 9 - PROGRESS: at 63.05% examples, 210736 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:27:24,560, word2vec, INFO, EPOCH 9 - PROGRESS: at 68.53% examples, 209890 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:25,563, word2vec, INFO, EPOCH 9 - PROGRESS: at 74.17% examples, 210097 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:26,616, word2vec, INFO, EPOCH 9 - PROGRESS: at 79.79% examples, 209556 words/s, in_qsize 16, out_qsize 0 ]
[2024-12-14 16:27:27,627, word2vec, INFO, EPOCH 9 - PROGRESS: at 85.50% examples, 209640 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:28,629, word2vec, INFO, EPOCH 9 - PROGRESS: at 91.35% examples, 209822 words/s, in_qsize 15, out_qsize 0 ]
[2024-12-14 16:27:29,644, word2vec, INFO, EPOCH 9 - PROGRESS: at 97.11% examples, 209802 words/s, in_qsize 12, out_qsize 0 ]
[2024-12-14 16:27:29,986, word2vec, INFO, EPOCH 9: training on 4176922 raw words (3725855 effective words) took 17.6s, 211615 effective words/s ]
[2024-12-14 16:27:29,987, utils, INFO, FastText lifecycle event {'msg': 'training on 41769220 raw words (37265414 effective words) took 172.2s, 216430 effective words/s', 'datetime': '2024-12-14T16:27:29.987945', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'} ]
[2024-12-14 16:27:34,467, utils, INFO, FastText lifecycle event {'params': 'FastText<vocab=106574, vector_size=25, alpha=0.025>', 'datetime': '2024-12-14T16:27:34.467439', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'} ]
[2024-12-14 16:27:34,476, keyedvectors, WARNING, destructive init_sims(replace=True) deprecated & no longer required for space-efficiency ]
[2024-12-14 16:27:34,571, keyedvectors, INFO, storing 106574x25 projection weights into ft_reviews_vectors.bin ]
[2024-12-14 16:27:42,577, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:27:43,820, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:27:43.820247', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:27:56,715, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:27:56,717, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:27:56,719, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:27:56,720, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:27:57,065, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:27:58,693, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:27:58,694, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:28:00,338, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:28:00,363, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 16:28:00,364, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:28:01,764, 1291398518, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:28:01,766, 1291398518, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:28:01,768, 1291398518, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:28:01,770, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:28:03,044, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:28:03.044157', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:28:03,045, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 16:28:03,048, 1291398518, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:28:03,050, 1291398518, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:28:03,051, 1291398518, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:28:03,052, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:28:04,255, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:28:04.255544', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:28:04,275, 1291398518, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:28:04,378, 1291398518, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:28:04,380, 1291398518, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:28:07,035, 1291398518, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:28:07,036, 1291398518, INFO, Removing punctuations from text ]
[2024-12-14 16:28:07,037, 1291398518, INFO, Error in pre-processing the text: 'list' object has no attribute 'str' ]
[2024-12-14 16:28:07,038, 3987913102, INFO, Error in initiating the data transformation pipeline 'list' object has no attribute 'str' ]
[2024-12-14 16:31:55,933, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:31:55,936, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:31:55,937, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:31:55,939, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:31:56,260, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:31:57,863, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:31:57,864, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:31:59,334, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:31:59,354, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 16:31:59,356, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:32:00,682, 3548401477, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:32:00,684, 3548401477, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:32:00,685, 3548401477, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:32:00,685, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:32:01,988, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:32:01.988736', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:32:01,989, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 16:32:01,992, 3548401477, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:32:01,994, 3548401477, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:32:01,995, 3548401477, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:32:01,996, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:32:03,149, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:32:03.149634', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:32:03,165, 3548401477, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:32:03,259, 3548401477, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:32:03,260, 3548401477, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:32:04,168, 3548401477, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:32:04,169, 3548401477, INFO, Removing punctuations from text ]
[2024-12-14 16:32:04,170, 3548401477, INFO, Error in pre-processing the text: 'DataFrame' object has no attribute 'self' ]
[2024-12-14 16:32:04,172, 3987913102, INFO, Error in initiating the data transformation pipeline 'DataFrame' object has no attribute 'self' ]
[2024-12-14 16:32:41,810, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:32:41,812, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:32:41,814, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:32:41,815, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:32:42,180, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:32:43,853, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:32:43,854, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:32:45,353, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:32:45,373, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 16:32:45,375, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:32:46,769, 764552505, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:32:46,770, 764552505, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:32:46,771, 764552505, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:32:46,772, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:32:48,109, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:32:48.109340', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:32:48,111, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 16:32:48,114, 764552505, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:32:48,116, 764552505, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:32:48,118, 764552505, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:32:48,119, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:32:49,385, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:32:49.385889', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:32:49,407, 764552505, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:32:49,525, 764552505, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:32:49,526, 764552505, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:32:50,479, 764552505, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:32:50,481, 764552505, INFO, Removing punctuations from text ]
[2024-12-14 16:32:50,483, 764552505, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-14 16:32:50,484, 3987913102, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-14 16:33:20,302, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:33:20,304, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:33:20,306, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:33:20,307, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:33:20,676, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:33:22,136, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:33:22,137, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:33:23,589, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:33:23,610, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 16:33:23,612, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:33:24,961, 3517424198, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:33:24,963, 3517424198, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:33:24,964, 3517424198, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:33:24,965, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:33:26,228, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:33:26.228902', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:33:26,230, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 16:33:26,233, 3517424198, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:33:26,235, 3517424198, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:33:26,236, 3517424198, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:33:26,237, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:33:27,353, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:33:27.353940', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:33:27,373, 3517424198, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:33:27,479, 3517424198, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:33:27,480, 3517424198, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:33:30,901, 3517424198, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:33:30,902, 3517424198, INFO, Removing punctuations from text ]
[2024-12-14 16:33:30,904, 3517424198, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-14 16:33:30,905, 3987913102, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-14 16:34:07,554, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:34:07,556, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:34:07,558, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:34:07,559, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:34:07,912, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:34:09,666, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:34:09,667, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:34:11,238, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:34:11,254, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 16:34:11,256, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:34:12,646, 610511674, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:34:12,648, 610511674, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:34:12,650, 610511674, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:34:12,651, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:34:13,931, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:34:13.931112', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:34:13,932, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 16:34:13,935, 610511674, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:34:13,937, 610511674, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:34:13,939, 610511674, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:34:13,940, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:34:15,072, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:34:15.072061', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:34:15,090, 610511674, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:34:15,186, 610511674, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:34:15,187, 610511674, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:34:16,265, 610511674, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:34:16,266, 610511674, INFO, Removing punctuations from text ]
[2024-12-14 16:34:16,267, 610511674, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-14 16:34:16,268, 3987913102, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-14 16:38:22,583, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:38:22,584, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:38:22,586, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:38:22,587, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:38:22,968, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:38:24,591, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:38:24,592, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:38:26,069, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:38:26,092, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 16:38:26,093, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:38:27,480, 3408856019, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:38:27,482, 3408856019, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:38:27,482, 3408856019, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:38:27,483, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:38:28,940, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:38:28.940518', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:38:28,941, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 16:38:28,944, 3408856019, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:38:28,946, 3408856019, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:38:28,947, 3408856019, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:38:28,948, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:38:30,126, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:38:30.125350', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:38:30,149, 3408856019, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:38:30,265, 3408856019, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:38:30,265, 3408856019, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:38:31,195, 3408856019, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:38:31,196, 3408856019, INFO, Removing punctuations from text ]
[2024-12-14 16:38:31,201, 3408856019, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-14 16:38:31,202, 3987913102, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-14 16:39:30,710, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:39:30,712, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:39:30,713, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:39:30,714, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:39:31,054, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:39:32,643, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:39:32,644, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:39:34,139, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:39:34,159, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 16:39:34,161, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:39:35,725, 31161083, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:39:35,727, 31161083, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:39:35,728, 31161083, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:39:35,729, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:39:37,075, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:39:37.075716', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:39:37,076, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 16:39:37,080, 31161083, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:39:37,082, 31161083, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:39:37,083, 31161083, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:39:37,083, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:39:38,241, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:39:38.241336', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:39:38,260, 31161083, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:39:38,368, 31161083, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:39:38,369, 31161083, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:39:39,311, 31161083, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:39:39,313, 31161083, INFO, Removing punctuations from text ]
[2024-12-14 16:39:39,314, 31161083, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-14 16:39:39,315, 3987913102, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-14 16:41:02,438, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:41:02,440, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:41:02,442, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:41:02,443, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:41:02,829, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:41:04,580, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:41:04,581, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:41:06,322, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:41:06,342, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 16:41:06,343, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:41:07,767, 31161083, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:41:07,769, 31161083, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:41:07,771, 31161083, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:41:07,772, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:41:09,091, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:41:09.091392', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:41:09,092, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 16:41:09,095, 31161083, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:41:09,097, 31161083, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:41:09,098, 31161083, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:41:09,099, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:41:10,170, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:41:10.170507', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:41:10,193, 31161083, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:41:10,299, 31161083, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:41:10,299, 31161083, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:41:11,259, 31161083, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:41:11,262, 31161083, INFO, Removing punctuations from text ]
[2024-12-14 16:41:11,263, 31161083, INFO, Error in pre-processing the text: expected string or buffer ]
[2024-12-14 16:41:11,264, 3987913102, INFO, Error in initiating the data transformation pipeline expected string or buffer ]
[2024-12-14 16:42:03,757, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:42:03,758, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:42:03,760, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:42:03,762, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:42:07,206, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:42:08,831, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:42:08,832, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:42:10,467, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:42:10,487, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 16:42:10,488, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:42:11,794, 2685266526, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:42:11,796, 2685266526, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:42:11,797, 2685266526, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:42:11,798, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:42:12,911, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:42:12.911377', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:42:12,913, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 16:42:12,916, 2685266526, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:42:12,917, 2685266526, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:42:12,918, 2685266526, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:42:12,919, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:42:14,074, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:42:14.074274', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:42:14,095, 2685266526, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:42:14,194, 2685266526, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:42:14,196, 2685266526, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:42:15,140, 2685266526, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:42:15,141, 2685266526, INFO, Removing punctuations from text ]
[2024-12-14 16:42:22,633, 2685266526, INFO, Removing punctuations from text successful ]
[2024-12-14 16:42:22,634, 2685266526, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 16:42:22,635, 2685266526, INFO, Error in pre-processing the text: unhashable type: 'list' ]
[2024-12-14 16:42:22,637, 3987913102, INFO, Error in initiating the data transformation pipeline unhashable type: 'list' ]
[2024-12-14 16:43:01,015, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:43:01,017, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:43:01,020, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:43:01,021, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:43:01,357, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:43:02,964, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:43:02,965, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:43:04,488, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:43:04,514, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 16:43:04,515, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:43:05,829, 632345916, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:43:05,831, 632345916, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:43:05,832, 632345916, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:43:05,833, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:43:07,110, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:43:07.110703', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:43:07,111, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 16:43:07,115, 632345916, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:43:07,116, 632345916, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:43:07,117, 632345916, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:43:07,118, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:43:08,400, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:43:08.400253', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:43:08,419, 632345916, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:43:08,518, 632345916, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:43:08,520, 632345916, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:43:09,574, 632345916, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:43:09,575, 632345916, INFO, Removing punctuations from text ]
[2024-12-14 16:43:16,240, 632345916, INFO, Removing punctuations from text successful ]
[2024-12-14 16:43:16,241, 632345916, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 16:43:19,004, 632345916, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 16:43:19,007, 632345916, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 16:43:19,009, 632345916, INFO, Error in lemmatization: unhashable type: 'list' ]
[2024-12-14 16:43:19,010, 3987913102, INFO, Error in initiating the data transformation pipeline unhashable type: 'list' ]
[2024-12-14 16:44:40,429, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:44:40,430, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:44:40,432, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:44:40,434, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:44:40,762, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:44:42,375, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:44:42,376, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:44:44,096, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:44:44,115, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 16:44:44,116, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:44:45,660, 516278899, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:44:45,662, 516278899, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:44:45,663, 516278899, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:44:45,664, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:44:47,000, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:44:47.000987', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:44:47,001, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 16:44:47,004, 516278899, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:44:47,006, 516278899, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:44:47,008, 516278899, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:44:47,009, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:44:48,385, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:44:48.385734', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:44:48,407, 516278899, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:44:48,510, 516278899, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:44:48,511, 516278899, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:44:49,516, 516278899, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:44:49,518, 516278899, INFO, Removing punctuations from text ]
[2024-12-14 16:44:58,277, 516278899, INFO, Removing punctuations from text successful ]
[2024-12-14 16:44:58,278, 516278899, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 16:44:59,686, 516278899, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 16:44:59,690, 516278899, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 16:45:24,055, 516278899, INFO, Lemmatization successful ]
[2024-12-14 16:45:24,059, 516278899, INFO, Generating embeddings for the text data ]
[2024-12-14 16:45:24,061, 516278899, ERROR, Error during transformation: unhashable type: 'list' ]
[2024-12-14 16:45:24,062, 3987913102, INFO, Error in initiating the data transformation pipeline unhashable type: 'list' ]
[2024-12-14 16:45:49,115, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:45:49,117, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:45:49,119, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:45:49,121, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:45:49,420, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:45:51,133, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:45:51,135, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:45:52,945, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:45:52,963, 3987913102, INFO, Initiating the DataTransformation ]
[2024-12-14 16:45:52,964, 3987913102, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:45:54,440, 3789801482, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:45:54,441, 3789801482, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:45:54,442, 3789801482, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:45:54,443, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:45:55,766, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:45:55.766135', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:45:55,767, 3987913102, INFO, Numerical and text pipelines created ]
[2024-12-14 16:45:55,771, 3789801482, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:45:55,773, 3789801482, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:45:55,774, 3789801482, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:45:55,774, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:45:56,902, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:45:56.902099', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:45:56,923, 3789801482, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:45:57,026, 3789801482, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:45:57,027, 3789801482, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:45:58,073, 3789801482, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:45:58,074, 3789801482, INFO, Removing punctuations from text ]
[2024-12-14 16:46:05,152, 3789801482, INFO, Removing punctuations from text successful ]
[2024-12-14 16:46:05,154, 3789801482, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 16:46:06,762, 3789801482, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 16:46:06,766, 3789801482, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 16:46:30,541, 3789801482, INFO, Lemmatization successful ]
[2024-12-14 16:46:30,546, 3789801482, INFO, Generating embeddings for the text data ]
[2024-12-14 16:47:02,980, 3789801482, INFO, Successfully generated embeddings ]
[2024-12-14 16:47:03,068, 3789801482, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:47:03,111, 3789801482, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:47:03,112, 3789801482, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:47:03,544, 3789801482, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:47:03,545, 3789801482, INFO, Removing punctuations from text ]
[2024-12-14 16:47:06,663, 3789801482, INFO, Removing punctuations from text successful ]
[2024-12-14 16:47:06,664, 3789801482, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 16:47:07,385, 3789801482, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 16:47:07,389, 3789801482, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 16:47:16,996, 3789801482, INFO, Lemmatization successful ]
[2024-12-14 16:47:17,136, 3789801482, INFO, Generating embeddings for the text data ]
[2024-12-14 16:47:31,029, 3789801482, INFO, Successfully generated embeddings ]
[2024-12-14 16:47:35,208, 3987913102, INFO, Error in initiating the data transformation pipeline 'DataTransformationConfig' object has no attribute 'preprocessor_obj_file_path' ]
[2024-12-14 16:48:37,850, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 16:48:37,853, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 16:48:37,854, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 16:48:37,856, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 16:48:38,209, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 16:48:39,952, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 16:48:39,953, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 16:48:41,606, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 16:48:41,624, 3057720041, INFO, Initiating the DataTransformation ]
[2024-12-14 16:48:41,625, 3057720041, INFO, Initiatig data transformation pipeline ]
[2024-12-14 16:48:42,921, 3789801482, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:48:42,923, 3789801482, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:48:42,924, 3789801482, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:48:42,925, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:48:44,101, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:48:44.101920', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:48:44,102, 3057720041, INFO, Numerical and text pipelines created ]
[2024-12-14 16:48:44,105, 3789801482, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 16:48:44,107, 3789801482, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 16:48:44,108, 3789801482, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 16:48:44,110, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 16:48:45,413, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T16:48:45.413415', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 16:48:45,433, 3789801482, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:48:45,534, 3789801482, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:48:45,535, 3789801482, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:48:46,653, 3789801482, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:48:46,654, 3789801482, INFO, Removing punctuations from text ]
[2024-12-14 16:48:57,180, 3789801482, INFO, Removing punctuations from text successful ]
[2024-12-14 16:48:57,182, 3789801482, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 16:48:58,669, 3789801482, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 16:48:58,673, 3789801482, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 16:49:21,832, 3789801482, INFO, Lemmatization successful ]
[2024-12-14 16:49:21,837, 3789801482, INFO, Generating embeddings for the text data ]
[2024-12-14 16:49:54,764, 3789801482, INFO, Successfully generated embeddings ]
[2024-12-14 16:49:54,859, 3789801482, INFO, Transforming all the letters into lowercase ]
[2024-12-14 16:49:54,897, 3789801482, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 16:49:54,900, 3789801482, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 16:49:55,319, 3789801482, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 16:49:55,320, 3789801482, INFO, Removing punctuations from text ]
[2024-12-14 16:49:58,544, 3789801482, INFO, Removing punctuations from text successful ]
[2024-12-14 16:49:58,546, 3789801482, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 16:49:59,156, 3789801482, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 16:49:59,161, 3789801482, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 16:50:08,763, 3789801482, INFO, Lemmatization successful ]
[2024-12-14 16:50:08,909, 3789801482, INFO, Generating embeddings for the text data ]
[2024-12-14 16:50:22,676, 3789801482, INFO, Successfully generated embeddings ]
[2024-12-14 16:50:26,804, 3057720041, INFO, Saved fitted preprocessor to artifacts\preprocessor.joblib ]
[2024-12-14 16:50:26,805, 3057720041, INFO, Returning the input train feature as an array and test feature as array respectively ]
[2024-12-14 18:56:43,229, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 18:56:43,230, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 18:56:43,232, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 18:56:43,234, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 18:56:43,670, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 18:59:10,507, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 18:59:10,509, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 18:59:10,511, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 18:59:10,512, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 18:59:10,934, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 18:59:12,695, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 18:59:12,697, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 18:59:14,446, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 18:59:14,479, 409849235, INFO, Initiating the DataTransformation ]
[2024-12-14 18:59:14,482, 409849235, INFO, Initiatig data transformation pipeline ]
[2024-12-14 18:59:16,014, 3789801482, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 18:59:16,017, 3789801482, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 18:59:16,018, 3789801482, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 18:59:16,019, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 18:59:17,277, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T18:59:17.276668', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 18:59:17,278, 409849235, INFO, Numerical and text pipelines created ]
[2024-12-14 18:59:17,282, 3789801482, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 18:59:17,283, 3789801482, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 18:59:17,286, 3789801482, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 18:59:17,287, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 18:59:18,590, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T18:59:18.590800', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 18:59:18,611, 3789801482, INFO, Transforming all the letters into lowercase ]
[2024-12-14 18:59:18,731, 3789801482, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 18:59:18,732, 3789801482, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 18:59:19,879, 3789801482, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 18:59:19,881, 3789801482, INFO, Removing punctuations from text ]
[2024-12-14 18:59:27,761, 3789801482, INFO, Removing punctuations from text successful ]
[2024-12-14 18:59:27,763, 3789801482, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 18:59:29,344, 3789801482, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 18:59:29,348, 3789801482, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 18:59:57,950, 3789801482, INFO, Lemmatization successful ]
[2024-12-14 18:59:57,954, 3789801482, INFO, Generating embeddings for the text data ]
[2024-12-14 19:00:32,471, 3789801482, INFO, Successfully generated embeddings ]
[2024-12-14 19:00:32,544, 3789801482, INFO, Transforming all the letters into lowercase ]
[2024-12-14 19:00:32,593, 3789801482, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 19:00:32,594, 3789801482, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 19:00:33,020, 3789801482, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 19:00:33,021, 3789801482, INFO, Removing punctuations from text ]
[2024-12-14 19:00:36,444, 3789801482, INFO, Removing punctuations from text successful ]
[2024-12-14 19:00:36,444, 3789801482, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 19:00:37,060, 3789801482, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 19:00:37,063, 3789801482, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 19:00:47,229, 3789801482, INFO, Lemmatization successful ]
[2024-12-14 19:00:47,330, 3789801482, INFO, Generating embeddings for the text data ]
[2024-12-14 19:01:01,674, 3789801482, INFO, Successfully generated embeddings ]
[2024-12-14 19:01:05,816, 409849235, INFO, Saved fitted preprocessor to artifacts\preprocessor.joblib ]
[2024-12-14 19:01:05,817, 409849235, INFO, Returning the input train feature as an array and test feature as array respectively ]
[2024-12-14 19:02:15,113, data_ingestion, INFO, Initiating data ingestion ]
[2024-12-14 19:02:15,115, data_ingestion, INFO, Establising Connection With SQL Database ]
[2024-12-14 19:02:15,116, data_ingestion, INFO, Successfully connected to the SQLite database. ]
[2024-12-14 19:02:15,117, data_ingestion, INFO, Reading New_Delhi_Reviews table  ]
[2024-12-14 19:02:15,496, data_ingestion, INFO, Successfully read the New_Delhi_Reviews as pandas dataframe ]
[2024-12-14 19:02:17,363, data_ingestion, INFO, succesfully ingested the raw data as a csv file into artifacts\raw_data.csv ]
[2024-12-14 19:02:17,364, data_ingestion, INFO, Initiating train test split ]
[2024-12-14 19:02:19,138, data_ingestion, INFO, train and test data split successful and stored respectively as csv files at artifacts\train_data.csv, artifacts\test_data.csv ]
[2024-12-14 19:02:19,163, 3157283571, INFO, Initiating the DataTransformation ]
[2024-12-14 19:02:19,165, 3157283571, INFO, Initiatig data transformation pipeline ]
[2024-12-14 19:02:20,751, 3789801482, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 19:02:20,753, 3789801482, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 19:02:20,754, 3789801482, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 19:02:20,754, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 19:02:22,064, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T19:02:22.064455', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 19:02:22,065, 3157283571, INFO, Numerical and text pipelines created ]
[2024-12-14 19:02:22,068, 3789801482, INFO, getting set of stopwords from NLTK from English language ]
[2024-12-14 19:02:22,071, 3789801482, INFO, WordNetLemmatizer from NLTK library is instantiated ]
[2024-12-14 19:02:22,073, 3789801482, INFO, Loading Gensim Word2Vec model for embedding generation ]
[2024-12-14 19:02:22,075, keyedvectors, INFO, loading projection weights from ft_reviews_vectors.bin ]
[2024-12-14 19:02:23,389, utils, INFO, KeyedVectors lifecycle event {'msg': 'loaded (106574, 25) matrix of type float32 from ft_reviews_vectors.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-12-14T19:02:23.389953', 'gensim': '4.3.3', 'python': '3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'} ]
[2024-12-14 19:02:23,410, 3789801482, INFO, Transforming all the letters into lowercase ]
[2024-12-14 19:02:23,520, 3789801482, INFO, Transforming all letters into lowercase is successful ]
[2024-12-14 19:02:23,521, 3789801482, INFO, Splitting the sentences into words (Tokenization) ]
[2024-12-14 19:02:24,505, 3789801482, INFO, Splitting the sentences into words is successful (Tokenization) ]
[2024-12-14 19:02:24,506, 3789801482, INFO, Removing punctuations from text ]
[2024-12-14 19:02:32,520, 3789801482, INFO, Removing punctuations from text successful ]
[2024-12-14 19:02:32,522, 3789801482, INFO, Removing the stopwords from the tokenized words ]
[2024-12-14 19:02:33,884, 3789801482, INFO, Removing the stopwords from the tokenized words is successful ]
[2024-12-14 19:02:33,887, 3789801482, INFO, Initiating the lemmatization of the remaining words after stopword removal ]
[2024-12-14 19:02:57,578, 3789801482, INFO, Lemmatization successful ]
[2024-12-14 19:02:57,581, 3789801482, INFO, Generating embeddings for the text data ]
[2024-12-14 19:03:32,010, 3789801482, INFO, Successfully generated embeddings ]
[2024-12-14 19:03:32,017, 3157283571, INFO, Error in initiating the data transformation pipeline setting an array element with a sequence. ]
